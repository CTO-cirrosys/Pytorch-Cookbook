{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operation\n",
    "- 가장 기본적인 Linear layer 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:34:28.992712Z",
     "start_time": "2019-08-12T14:34:26.808931Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module): # Pytorch 모듈 중 nn 상속받기(nn에 있는 기능 사용 가능)\n",
    "    \n",
    "    def __init__(self, input_size, output_size): # 초기화 함수\n",
    "        super(MyLinear, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size) # nn모듈에 있는 Linear함수 사용하기\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x) # x 연산하기(단순 linear)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:35:36.231292Z",
     "start_time": "2019-08-12T14:35:36.156333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3238,  0.1340],\n",
       "        [ 0.6058, -0.2532],\n",
       "        [-0.2654, -0.0579],\n",
       "        [-0.0620,  0.3863],\n",
       "        [ 0.1820, -0.1376],\n",
       "        [ 0.9729,  0.3226],\n",
       "        [-0.0715,  0.4932],\n",
       "        [-0.2115,  0.5417],\n",
       "        [ 0.8422,  0.4507],\n",
       "        [ 0.1206, -0.6053],\n",
       "        [-0.3932,  0.6591],\n",
       "        [ 0.2622,  0.4521],\n",
       "        [-0.8736,  0.2832],\n",
       "        [ 0.0854,  0.4254],\n",
       "        [-0.4006,  0.5478],\n",
       "        [ 0.1783,  0.1404],\n",
       "        [-0.4780,  0.6288],\n",
       "        [ 0.5967,  0.1730],\n",
       "        [ 0.6980,  0.9541],\n",
       "        [ 0.4969,  0.5406]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 2)\n",
    "\n",
    "x = torch.randn(20, 5)\n",
    "y = linear(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:35:38.941764Z",
     "start_time": "2019-08-12T14:35:38.933753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([2, 5]), torch.Size([2])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters 확인하기\n",
    "[p.size() for p in linear.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "- 회귀식을 예측하는 신경망 설계\n",
    "- y = 2x -> 기울기 '2' 예측하기\n",
    "- 예상 결과 : weight(기울기)는 2에 가깝고 bias(y 절편)는 0에 가깝다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:37:47.431377Z",
     "start_time": "2019-08-12T14:37:46.483917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e9b8747b00>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e9acee4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예상되는 결과\n",
    "x = torch.randn(100,1)\n",
    "y = 2*x\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:38:02.586720Z",
     "start_time": "2019-08-12T14:38:02.560735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.0495]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.0859], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 정의\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        #torch.nn.init.zeros_(self.linear.weight) # 가중치(weight)를 0으로 초기화하기\n",
    "        #torch.nn.init.zeros_(self.linear.bias) # bias를 0으로 초기화하기\n",
    "        #self.linear.weight.data.fill_(2) # 원하는 숫자로 초기화(기울기)\n",
    "        #self.linear.bias.data.fill_(0) # 원하는 숫자로 초기화(y절편)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y\n",
    "model = MyModel(1,1)\n",
    "list(model.parameters()) # parameter 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:38:18.618569Z",
     "start_time": "2019-08-12T14:38:18.612571Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정답 함수 정의\n",
    "def answer(x):\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:38:21.017198Z",
     "start_time": "2019-08-12T14:38:21.001208Z"
    }
   },
   "outputs": [],
   "source": [
    "# train 정의\n",
    "def train(model, x, y, optim):\n",
    "    optim.zero_grad() # module안에 있는 모든 parameters 초기화\n",
    "    \n",
    "    # feed-forward\n",
    "    y_hat = model(x)\n",
    "    \n",
    "    # 에러 계산하기\n",
    "    loss = ((y - y_hat).pow(2)).sum() / x.size(0)\n",
    "    \n",
    "    # 오차값에 대한 기울기 구하기\n",
    "    loss.backward()\n",
    "    \n",
    "    # 파라미터 갱신하기\n",
    "    optimizer.step()\n",
    "    \n",
    "    # loss값 출력\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:38:45.943965Z",
     "start_time": "2019-08-12T14:38:45.902988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.8654]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2420], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 하이퍼-파라미터 설정\n",
    "batch_size = 1\n",
    "iter_size = 10000\n",
    "epoch_size = 10000\n",
    "\n",
    "model = MyModel(1,1)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0001, momentum = 0.1)\n",
    "\n",
    "print(model, '\\n')\n",
    "[print(p) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:39:13.684144Z",
     "start_time": "2019-08-12T14:38:49.177120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18419.3711, grad_fn=<AddBackward0>) tensor([0.2000]) tensor([0.1980])\n",
      "tensor(192.9449, grad_fn=<AddBackward0>) tensor([0.2000]) tensor([0.1995])\n",
      "tensor(2.1390, grad_fn=<AddBackward0>) tensor([0.2000]) tensor([0.1999])\n",
      "tensor(0.0246, grad_fn=<AddBackward0>) tensor([0.2000]) tensor([0.2000])\n",
      "tensor(0.0004, grad_fn=<AddBackward0>) tensor([0.2000]) tensor([0.2000])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_size):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for i in range(iter_size):\n",
    "        \n",
    "        x = torch.randn(batch_size, 1)\n",
    "        y = answer(x)\n",
    "        \n",
    "        loss = train(model, x, y, optimizer)\n",
    "        \n",
    "        avg_loss += loss\n",
    "    avg_loss / iter_size\n",
    "    \n",
    "    x_valid = torch.FloatTensor([[.1]])\n",
    "    y_valid = answer(x_valid)\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat = model(x_valid)\n",
    "    model.train()\n",
    "    \n",
    "    print(avg_loss, y_valid.data[0], y_hat.data[0])\n",
    "    \n",
    "    if avg_loss < .001:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:39:17.871735Z",
     "start_time": "2019-08-12T14:39:17.857740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1.9999]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([3.2668e-06], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "- y = 3 * X1 + X2 - 2 * X3\n",
    "- 예상되는 결과 : weight = [3, 1, -2], bias = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:39:49.635597Z",
     "start_time": "2019-08-12T14:39:25.785216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters : \n",
      "Parameter containing:\n",
      "tensor([[-0.4648, -0.2206, -0.0597]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3831], requires_grad=True)\n",
      "\n",
      "Optimizer : \n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "\n",
      "epoch : [1/1000](1000/1000)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Train Loss : 4.30 tensor(-1.) tensor([-0.9340])\n",
      "epoch : [2/1000](1000/1000)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Train Loss : 0.06 tensor(-1.) tensor([-0.9991])\n",
      "epoch : [3/1000](1000/1000)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Train Loss : 0.00 tensor(-1.) tensor([-0.9986])\n",
      "epoch : [4/1000](1000/1000)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Train Loss : 0.00 tensor(-1.) tensor([-1.0000])\n",
      "\n",
      "\n",
      "The Parameters of model\n",
      "Parameter containing:\n",
      "tensor([[ 2.9989,  0.9995, -1.9992]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0002], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "    \n",
    "model = model(3,1)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "def generate_data(batch_size):\n",
    "    x = torch.randn(batch_size, 3)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def answer(x):\n",
    "    \n",
    "    return 3 * x[:,0] + x[:,1] - 2 * x[:,2]\n",
    "\n",
    "def loss_f(x):\n",
    "    \n",
    "    y = answer(x)\n",
    "    y_hat = model(x)\n",
    "    \n",
    "    loss = ((y.view(batch_size,1) - y_hat).pow(2)).sum() / x.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "batch_size = 3\n",
    "epoch_n = 1000\n",
    "iter_n = 1000\n",
    "\n",
    "print('Parameters : ')\n",
    "for p in model.parameters():\n",
    "    print(p)\n",
    "\n",
    "print('')\n",
    "print('Optimizer : ')\n",
    "print(optimizer)\n",
    "print('\\n')\n",
    "\n",
    "for epoch in range(1, epoch_n+1):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for i in range(1, iter_n+1):\n",
    "        x = torch.randn(batch_size, 3)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_f(x.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss\n",
    "        \n",
    "        print('\\repoch : [{}/{}]({}/{})'.format(epoch, epoch_n, i, iter_n), end = ' ')\n",
    "        \n",
    "    avg_loss = avg_loss / iter_n\n",
    "    \n",
    "    x_valid = torch.FloatTensor([[1,2,3]])\n",
    "    y_valid = answer(x_valid)\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat = model(x_valid)\n",
    "    model.train()\n",
    "    \n",
    "    print('Train Loss : %.2f' %avg_loss.item(), y_valid.data[0], y_hat.data[0])\n",
    "    \n",
    "    if avg_loss < 0.001:\n",
    "        print('\\n')\n",
    "        print('The Parameters of model')\n",
    "        for p in model.parameters():\n",
    "            print(p)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3\n",
    "- y = X1^2 + X2^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:40:21.891176Z",
     "start_time": "2019-08-12T14:40:15.472843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (linear1): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (linear2): Linear(in_features=10, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "tensor(7.5935, grad_fn=<DivBackward0>)\n",
      "tensor(2.1295, grad_fn=<DivBackward0>)\n",
      "tensor(1.7289, grad_fn=<DivBackward0>)\n",
      "tensor(0.6020, grad_fn=<DivBackward0>)\n",
      "tensor(0.3876, grad_fn=<DivBackward0>)\n",
      "tensor(0.2351, grad_fn=<DivBackward0>)\n",
      "tensor(0.2569, grad_fn=<DivBackward0>)\n",
      "tensor(0.1277, grad_fn=<DivBackward0>)\n",
      "tensor(0.1969, grad_fn=<DivBackward0>)\n",
      "tensor(0.2280, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e9b87775f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# y = X1^2 + X2^2\n",
    "def answer(x):\n",
    "    \n",
    "    y = x[:,0].pow(2) + x[:,1].pow(2)\n",
    "    \n",
    "    return y\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_size, 10)\n",
    "        self.linear2 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = F.relu(self.linear1(x))\n",
    "        y = F.relu(self.linear2(y))\n",
    "        \n",
    "        return y\n",
    "    \n",
    "model = Model(2,1)\n",
    "print(model, '\\n')\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "print(optimizer)\n",
    "print('')\n",
    "\n",
    "batch_size = 3\n",
    "epoch_n = 100\n",
    "iter_n = 100\n",
    "loss_list = []\n",
    "for epoch in range(epoch_n):\n",
    "    loss_avg = 0\n",
    "    for i in range(iter_n):\n",
    "        \n",
    "        x = torch.randn(batch_size, 2)\n",
    "        y_hat = model(x)\n",
    "        y = answer(x).view(y_hat.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_avg += loss\n",
    "        loss_list.append(loss_avg)\n",
    "    \n",
    "    loss_avg = loss_avg / iter_n\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(loss_avg)\n",
    "    \n",
    "    if loss_avg < 0.0001:\n",
    "        break\n",
    "        \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(loss_list, label = 'Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로 배운 것\n",
    "\n",
    "## 1. 서로 다른 사이즈의 두 Tensor의 size 맞춰주기\n",
    "- tensor1.view(tensor2.shape)\n",
    "- https://stackoverflow.com/questions/53569050/pytorch-how-can-i-make-same-size-of-tensor-modelx-and-answerx/53569303?noredirect=1#comment94007240_53569303\n",
    "\n",
    "## 2. Regression에서는 손실함수로 CrossEntropyLoss를 사용하지 않는다.\n",
    "- 대신 MSELoss나 L1loss를 사용한다.\n",
    "- https://stackoverflow.com/questions/53571621/pytorch-crossentropy-error-in-simple-example-of-nn/53571764?noredirect=1#comment94011455_53571764"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
