{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Pytorch Chapter 3 : Neural Networks\n",
    "https://9bow.github.io/PyTorch-tutorials-kr-0.3.1/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "- torch.nn 패키지를 이용한다.\n",
    "- nn은 모델을 정의하고 미분할 때 autograd를 사용한다.\n",
    "- 숫자 이미지를 분류하는 신경망을 예제로 실습한다.\n",
    "![nn_example](image/nn_example.png)\n",
    "- feed-forward-network(입력을 받아 여러 계층을 차례로 전달한 후 최종 출력하는 과정)\n",
    "\n",
    "## Process of train neural network\n",
    "1. 학습 가능한 매개변수(or 가중치)를 갖는 신경망을 정의\n",
    "2. 데이터셋 입력을 반복\n",
    "3. 입력을 신경망에서 처리(계산)\n",
    "4. 손실(loss, 정답과 얼마나 다른지)을 계산\n",
    "5. 변화도(gradiant, 기울기)를 신경망의 매개변수들에게 역으로 전파(역전파)\n",
    "6. 신경망의 가중치 갱신\n",
    "![weight_formula](image/weight_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Neural Network\n",
    "1. nn.Conv2d()\n",
    " ![conv2d](image/conv2d_explain.png)\n",
    " - 입력값의 채널 수는 filter의 개수와 같다.(ex. RGB(3개) = filter 3개)\n",
    " - in_channels : 입력값의 채널 수(= filter의 개수)\n",
    " - out_chnnels : 출력값의 채널 수(= filter 묶음(입력값의 채널 수)의 개수) \n",
    " \n",
    "2. nn.Linear()\n",
    " ![linear](image/linear_explain.png)\n",
    " - Kears의 dense와 같은 역할\n",
    " - flatten을 해줘야 적용이 가능함(1차원으로 펴버리기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:56:08.657333Z",
     "start_time": "2019-08-12T14:56:08.121636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input, 6 output, 5x5 filter\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # max pooling 사이즈가 정사각형이면, single number 입력 가능\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # 배치 크기만 제외한 나머지 차원 (1,2,3,4) -> (2,3,4)\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- forward 함수만 정의하면 backward(변화도를 계산하는 함수)는 autograd를 사용하여 자동으로 정의된다. forward 함수에서는 어떠한 Tensor연산을 사용해도 된다.\n",
    "\n",
    "### 모델의 학습 가능한 매개변수들 확인\n",
    "- 매 학습마다 갱신되는 매개변수들(가중치)\n",
    "- 필터의 사이즈, 개수 등\n",
    "- channel의 개수\n",
    "- linear의 노드 개수 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:56:12.736061Z",
     "start_time": "2019-08-12T14:56:12.721070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1의 가중치(필터의 가중치)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "- torch.nn은 미니 배치만 지원한다. 하나의 샘플이 아닌 미니배치만 받는다.\n",
    "- nnConv2D인 경우 4차원 Tensor(nSamples x nChannels x Height x Width)을 입력으로 해야된다.\n",
    "- 하나의 샘플만 있다면, input.unsqueeze(0)을 사용해 가짜 차원을 추가해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T14:56:42.480773Z",
     "start_time": "2019-08-12T14:56:42.463781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0036, -0.0523,  0.0209,  0.0290, -0.0409, -0.0249,  0.0209, -0.1373,\n",
      "          0.1564, -0.0951]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_x = torch.randn(1,1,32,32) # 미니배치로 만든 후 입력(이미지 size = 32x32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실함수(Loss Function)\n",
    "- 입력값이 정답과 얼마나 떨어져 있는지 추정하는 방법\n",
    "- nn패키지에는 여러 손실함수가 있음(ex. 평균제곱오차(mean-squared error) > nn.MSEloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T15:01:48.458582Z",
     "start_time": "2019-08-12T15:01:48.387624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  tensor(38.6575, grad_fn=<MseLossBackward>)\n",
      "conv1.bias.grad before backward\n",
      "tensor([-0.0324, -0.0157, -0.1070, -0.0273,  0.0748,  0.1471])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0487, -0.0236, -0.1604, -0.0409,  0.1122,  0.2206])\n"
     ]
    }
   ],
   "source": [
    "output = net(input_x)\n",
    "target = torch.arange(1, 11, dtype = torch.float)\n",
    "target = target.view(1, -1) # output이랑 같은 shape 만들어주기\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print('Loss : ', loss)\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)\n",
    "#print(net.conv1.weight.grad) # conv1 가중치값의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T15:02:02.527126Z",
     "start_time": "2019-08-12T15:02:02.510128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000015A1365C588>\n",
      "<AddmmBackward object at 0x0000015A0A14FEF0>\n",
      "<AccumulateGrad object at 0x0000015A0A14F400>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn) # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0]) # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파\n",
    "- 오차를 역전파하기 위해서는 loss.backward()가 전부이다.\n",
    "- 기존 변화도를 지우는 작업이 필요하다.(변화도가 기존의 것에 누적된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가중치 갱신\n",
    "- 가중치의 갱신하여 정확도를 올린다.\n",
    "- 가장 단순한 규칙은 확률적 경사하강법(SGD)<br>\n",
    "가중치(weight) = 가중치(weight) - 학습율(learning rage) * 변화도(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T15:02:07.810849Z",
     "start_time": "2019-08-12T15:02:07.801852Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그러나 SGD, Nesterov-SGD, Adam, RMSProp 등의 다양한 갱신 규칙이 있다.\n",
    "- torch.optim 패키지가 이러한 규칙들을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T15:02:11.333477Z",
     "start_time": "2019-08-12T15:02:11.309493Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01) # optimizer 생성\n",
    "\n",
    "optimizer.zero_grad() # 0으로 초기화\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # optimizer 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "- zero_grad()을 이용하여 수동으로 변화도 버퍼를 0으로 설정해야 한다.\n",
    "- 변화도가 누적되는 것을 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "### 1. what is super()?\n",
    "- 클래스가 여러 클래스들에 대해 서로서로 상속을 받은 상태일 때,<br>\n",
    "최상위 클라스의 생성자가 각각의 클래스에 대해 중복해서 출력되기 때문에<br>\n",
    "이를 방지하기 위해 최상단 부모 클래스를 한 번만 호출하도록 하는 함수\n",
    "- 참고http://bluese05.tistory.com/5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
