{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with Faster R-CNN\n",
    "- Faster R-CNN을 이용해 물체인식 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:26.544587Z",
     "start_time": "2019-12-15T12:15:23.542274Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bbox 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:26.635501Z",
     "start_time": "2019-12-15T12:15:26.549549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 800, 800])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.zeros((1,3,800,800))\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:26.697465Z",
     "start_time": "2019-12-15T12:15:26.641496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.,  30., 400., 500.],\n",
       "        [300., 400., 500., 600.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]])\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:26.718455Z",
     "start_time": "2019-12-15T12:15:26.702462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.,  30., 400., 500.],\n",
       "       [300., 400., 500., 600.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:27.020281Z",
     "start_time": "2019-12-15T12:15:26.733445Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Rectangle at 0x28fe59e46a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor = image\n",
    "tensor = tensor.squeeze()\n",
    "tensor = tensor.permute(1,2,0)\n",
    "img = np.array(tensor)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "rect1 = patches.Rectangle((20,30),380,470, facecolor='none', edgecolor='r')\n",
    "rect2 = patches.Rectangle((300,400),100,200, facecolor='none', edgecolor='r')\n",
    "\n",
    "ax.add_patch(rect1)\n",
    "ax.add_patch(rect2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone -> VGG16\n",
    "- inpput size == 800 \n",
    "- output size == 800//16 = 50\n",
    "- input과 output의 size를 위와 같도록 model 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:27.041269Z",
     "start_time": "2019-12-15T12:15:27.028275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 800, 800])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인을 위해 dummy image 생성\n",
    "dummy_img = torch.zeros((1,3,800,800)).float()\n",
    "dummy_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:30.358369Z",
     "start_time": "2019-12-15T12:15:27.046266Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG16 모델 아키텍처 보기\n",
    "import torchvision\n",
    "\n",
    "model_vgg16 = torchvision.models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:30.378360Z",
     "start_time": "2019-12-15T12:15:30.363368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_list = list(model_vgg16.features)\n",
    "layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:30.405344Z",
     "start_time": "2019-12-15T12:15:30.390353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 800, 800])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:30.775133Z",
     "start_time": "2019-12-15T12:15:30.413340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 800, 800])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_list[0](dummy_img).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:44.113504Z",
     "start_time": "2019-12-15T12:15:30.781129Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# output_size가 50이 될때까지 필요한 layer \n",
    "require_layers = []\n",
    "for layer in layer_list:\n",
    "    dummy_img = layer(dummy_img)\n",
    "    if dummy_img.size()[2] < 800//16:\n",
    "        break\n",
    "    require_layers.append(layer)\n",
    "    output_channel = dummy_img.size()[1]\n",
    "    \n",
    "print(output_channel)\n",
    "print(len(require_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:44.136493Z",
     "start_time": "2019-12-15T12:15:44.121499Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "faster_rcnn_feature_extractor = nn.Sequential(*require_layers)\n",
    "faster_rcnn_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:59.028974Z",
     "start_time": "2019-12-15T12:15:44.141488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "output_feature = faster_rcnn_feature_extractor(image)\n",
    "print(output_feature.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Anchor box(방법 확인, 실제 만드는 건 뒤에)\n",
    "- 각 비율, 크기마다 다른 anchor box 생성 -> 0.5, 1, 2 / 8, 16, 32\n",
    "- 각 box는 x1,y1,x2,y2를 가지고 있음 -> size == (9,4)\n",
    "- 1개의 feature map에 있는 1개의 픽셀에 대해 생성\n",
    "> Now every pixel in the output feature map maps to corresponding 16 * 16 pixels in the image. This is shown in the below image<br>\n",
    "-> 800x800에서 50x50으로 축소했으니 원본에서 16x16사이즈의 anchor box가 결국 feature map에서의 1개의 픽셀이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:59.187883Z",
     "start_time": "2019-12-15T12:15:59.042965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = [0.5, 1, 2]\n",
    "anchor_scales = [8,16,32]\n",
    "\n",
    "anchor_base = np.zeros((len(ratio) * len(anchor_scales), 4))\n",
    "anchor_base # feature map 1개의 픽셀에 대해 anchor box가 가질 수 있는 경우 9가지(비율3 x 크기3, x1 y1 x2 y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:59.469725Z",
     "start_time": "2019-12-15T12:15:59.217865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.50966799187809 181.01933598375618\n",
      "0\n",
      "181.01933598375618 362.03867196751236\n",
      "1\n",
      "362.03867196751236 724.0773439350247\n",
      "2\n",
      "128.0 128.0\n",
      "3\n",
      "256.0 256.0\n",
      "4\n",
      "512.0 512.0\n",
      "5\n",
      "181.01933598375618 90.50966799187809\n",
      "6\n",
      "362.03867196751236 181.01933598375618\n",
      "7\n",
      "724.0773439350247 362.03867196751236\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -37.254834  ,  -82.50966799,   53.254834  ,   98.50966799],\n",
       "       [ -82.50966799, -173.01933598,   98.50966799,  189.01933598],\n",
       "       [-173.01933598, -354.03867197,  189.01933598,  370.03867197],\n",
       "       [ -56.        ,  -56.        ,   72.        ,   72.        ],\n",
       "       [-120.        , -120.        ,  136.        ,  136.        ],\n",
       "       [-248.        , -248.        ,  264.        ,  264.        ],\n",
       "       [ -82.50966799,  -37.254834  ,   98.50966799,   53.254834  ],\n",
       "       [-173.01933598,  -82.50966799,  189.01933598,   98.50966799],\n",
       "       [-354.03867197, -173.01933598,  370.03867197,  189.01933598]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchor base 채우기\n",
    "sub_sample = 16\n",
    "ctr_x = sub_sample / 2\n",
    "ctr_y = sub_sample / 2\n",
    "\n",
    "for i in range(len(ratio)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "        h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "        w = sub_sample * anchor_scales[j] * np.sqrt(1/ratio[i])\n",
    "        print(h,w)\n",
    "        \n",
    "        index = i * len(anchor_scales) + j\n",
    "        print(index)\n",
    "        \n",
    "        anchor_base[index, 0] = ctr_y - h / 2\n",
    "        anchor_base[index, 1] = ctr_x - w / 2\n",
    "        anchor_base[index, 2] = ctr_y + h / 2\n",
    "        anchor_base[index, 3] = ctr_x + w / 2\n",
    "        \n",
    "anchor_base\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위 작업은 1개의 feature map에 대하여 생성한 anchor box**\n",
    "- image 사이즈에서 벗어나거나 큰 anchor box는 negaitve values로 취급, 나중에 loss계산할 때 빼준다(-1로 바꿔줌)\n",
    "- feature map이 50x50임으로 각 픽셀에 대해 anchor box 생성하면 -> 17500(50x50x9)<br>\n",
    "(1개의 픽셀에 9가지의 anchor box 생성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature map에 있는 모든 pixel에 대하여 anchor box 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 픽셀에 대한 센터값 모음 생성(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:15:59.536684Z",
     "start_time": "2019-12-15T12:15:59.476718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 픽셀에 대해 센터값(ctr_x, ctr_y) 생성\n",
    "\n",
    "feature_size = 800//16\n",
    "ctr_x = np.arange(16, (feature_size+1)*16, 16) # image 원본에서의 센터값x\n",
    "ctr_y = np.arange(16, (feature_size+1)*16, 16) # image 원본에서의 센터값y\n",
    "\n",
    "index = 0\n",
    "ctr = np.zeros((len(ctr_x) * len(ctr_y), 2))\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        ctr[index, 1] = ctr_x[x] - 8\n",
    "        ctr[index, 0] = ctr_y[y] - 8\n",
    "        index += 1\n",
    "        \n",
    "ctr.shape # 1개의 image에 대한 모든 anchor box의 중심점의 모음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 센터값에 대당하는 anchor box 생성(위와 다르게 실제로 생성)\n",
    "- 1개의 feature map에 해당하는 모든 anchor box 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:00.580087Z",
     "start_time": "2019-12-15T12:15:59.559670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 4)\n"
     ]
    }
   ],
   "source": [
    "anchors = np.zeros((feature_size * feature_size * 9, 4)) # 각 anchor box에 대한 y1, x1, y2, x2\n",
    "sub_sample = 16\n",
    "index = 0\n",
    "for c in ctr: # y,x\n",
    "    ctr_y, ctr_x = c\n",
    "    for i in range(len(ratio)):\n",
    "        for j in range(len(anchor_scales)):\n",
    "            h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "            w = sub_sample * anchor_scales[j] * np.sqrt(1/ratio[i])\n",
    "            \n",
    "            anchors[index, 0] = ctr_y - h/2 # y1\n",
    "            anchors[index, 1] = ctr_x - w/2 # x1\n",
    "            anchors[index, 2] = ctr_y + h/2 # y2\n",
    "            anchors[index, 3] = ctr_x + w/2 # x2\n",
    "            index += 1\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 Anchor box에 Labels과 location 할당하기\n",
    "**두 종류의 Anchor에는 'Positive label'을 할당**\n",
    "1. 정답(Ground-Truth)과 비교했을 때 IOU(Intersection-over-Union)값이 가장 큰 Anchor/Anchors\n",
    "2. 정답(Ground-Truth)과 비교했을 때 IOU(Intersection-over-Union)값이 **0.7** 이상일 때\n",
    "> **Object가 1개에 대하여 여러 Anchor box에 Positive label을 할당하는 경우가 있다.**\n",
    "\n",
    "**아래와 같은 Anchor에는 'Negative label'을 할당**\n",
    "1. 정답(Ground-Truth)과 비교했을 때 IOU(Intersection-over-Union)값이 **0.3**보다 작을 때\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:00.614067Z",
     "start_time": "2019-12-15T12:16:00.596079Z"
    }
   },
   "outputs": [],
   "source": [
    "# 예시 Ground-Truth값(정답값 2개 objects)\n",
    "bbox = np.asarray([[20, 30, 400, 500], [300, 400, 500, 600]], dtype=np.float32) # y1, x1, y2, x2\n",
    "labels = np.asarray([6, 8], dtype=np.int8) # 0값은 배경을 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유효한(valid) Anchor box의 index 찾기\n",
    "- Anchor box가 image보다 크거나 범위에서 벗어나면 유효하지 않음\n",
    "- 즉, Anchor box의 x1 y1 x2 y2 값들이 모두 0~800 사이에 있어야 유효한 box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:00.688027Z",
     "start_time": "2019-12-15T12:16:00.639053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[ 13.49033201  10.745166   194.50966799 101.254834  ]\n"
     ]
    }
   ],
   "source": [
    "index_inside = np.where((anchors[:,0] >= 0) &\n",
    "                        (anchors[:,1] >= 0) &\n",
    "                        (anchors[:,2] <= 800) &\n",
    "                        (anchors[:,3] <= 800))[0]\n",
    "print(index_inside.shape)\n",
    "print(anchors[index_inside[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label 행렬 만들기\n",
    "- 여기서 label은 물체가 있는지 없는지(objectness)만 판별\n",
    "- 따라서 1또는 -1로 표시(1은 물체가 있고 -1은 background)\n",
    "- 각 anchor box별로 물체 유무에 따라 1 or -1\n",
    "> **유효한 Anchor box 개수 = label 행렬 크기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:00.716012Z",
     "start_time": "2019-12-15T12:16:00.696021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.empty_like(index_inside)\n",
    "label.fill(-1)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유효한 Anchor box 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:00.762983Z",
     "start_time": "2019-12-15T12:16:00.735998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_anchor_boxes = anchors[index_inside]\n",
    "valid_anchor_boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU 계산\n",
    "- 위에서 임의로 정의한 bbox를 정답(Ground-Truth)이라고 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.277545Z",
     "start_time": "2019-12-15T12:16:00.768980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ious = np.zeros((len(valid_anchor_boxes), 2)) # 각 Anchor box와 Ground-Truth와의 IOU 값\n",
    "\n",
    "for num1, i in enumerate(valid_anchor_boxes):\n",
    "    ya1, xa1, ya2, xa2 = i\n",
    "    anchor_area = (ya2-ya1) * (xa2-xa1)\n",
    "    for num2, j in enumerate(bbox):\n",
    "        yb1, xb1, yb2, xb2 = j\n",
    "        box_area = (yb2-yb1) * (xb2-xb1)\n",
    "        \n",
    "        inter_x1 = max([xa1, xb1])\n",
    "        inter_y1 = max([ya1, yb1])\n",
    "        inter_x2 = min([xa2, xb2])\n",
    "        inter_y2 = min([ya2, yb2])\n",
    "        \n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            inter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)\n",
    "            iou = inter_area/(box_area + anchor_area - inter_area) # inter_area가 반복됨으로 한 번 빼준다.\n",
    "            \n",
    "        else:\n",
    "            iou = 0\n",
    "            \n",
    "        ious[num1, num2] = iou # 각각의 Anchor box에 대한 2 objects의 iou 값\n",
    "        \n",
    "ious.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조건에 만족하는 IOU값 및 그 값에 해당하는 Anchor box 선별\n",
    "1. 2개의 Ground-Truth box에 대하여 가장 큰 IOU값과 그 값(2개의 Ground-Truth box)에 해당하는 Anchor box\n",
    "2. 각각의 Anchor box 에서 가장 큰 IOU값과 그 값에 해당하는 Ground-Truth box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 각 Object에 대해 가장 큰 IOU 값과 각 해당하는 Anchor box index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.331513Z",
     "start_time": "2019-12-15T12:16:03.286541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2262, 5620], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_argmax_ious = ious.argmax(axis = 0)\n",
    "gt_argmax_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.381485Z",
     "start_time": "2019-12-15T12:16:03.359497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68130493, 0.08628624],\n",
       "       [0.10757449, 0.61035156]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ious[gt_argmax_ious]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.466437Z",
     "start_time": "2019-12-15T12:16:03.424460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68130493, 0.61035156])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])] # (0,0) , (1,1)\n",
    "gt_max_ious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  각 Object(2개)에 대한 Anchor box(2개) 중 IOU가 큰 Anchor box(2 중 하나)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.571376Z",
     "start_time": "2019-12-15T12:16:03.473432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "argmax_ious = ious.argmax(axis = 1)\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious) # 2개 중 1개의 index가 나오겟죠? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.635341Z",
     "start_time": "2019-12-15T12:16:03.585369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# index_inside == 유효한 Anchro box의 index\n",
    "max_ious = ious[np.arange(len(index_inside)), argmax_ious] # 유효한 Anchor box 중 IOU 값이 큰 box(2중 더 큰 값)\n",
    "print(max_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가장 큰 IOU값을 가지고 있는 Anchor box 찾기\n",
    "- 저 결과값들은 Anchor box들 중 IOU가 가장 큰 Anchor box들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.684312Z",
     "start_time": "2019-12-15T12:16:03.643336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
      " 6358 6366 6374 6382]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
    "print(gt_argmax_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 우리는 3가지의 결과를 얻었다.\n",
    "1. argmax_ious : 각 Anchor 중 어느 Object에 대한 IOU가 큰 값인지 나타낸 index(0 or 1)\n",
    "2. max_ious : 각 Anchro에 대하여 두 Ojbect 중 IOU가 더 큰 Object에 해당하는 IOU\n",
    "3. gt_argmax_ious : 가장 큰 IOU값을 지니고 있는 Anchor box들의 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.751276Z",
     "start_time": "2019-12-15T12:16:03.690309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.795250Z",
     "start_time": "2019-12-15T12:16:03.764266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06811669, 0.07083762, 0.07083762, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.834226Z",
     "start_time": "2019-12-15T12:16:03.806243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
       "       6120, 6128, 6136, 6358, 6366, 6374, 6382], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_argmax_ious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임계값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.932172Z",
     "start_time": "2019-12-15T12:16:03.917178Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_iou_threshold = 0.7 # IOU값이 0.7를 넘으면 positive\n",
    "neg_iou_threshold = 0.3 # IOU값이 0.3 아래면 negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:03.989137Z",
     "start_time": "2019-12-15T12:16:03.945162Z"
    }
   },
   "outputs": [],
   "source": [
    "label[max_ious < neg_iou_threshold] = 0 # Negative label에 0 설정\n",
    "label[gt_argmax_ious] = 1 # Ojbect와 비교했을 때 IOU가 가장 높은 Anchor box에 1 할당\n",
    "label[max_ious >= pos_iou_threshold] = 1 # IOU가 0.7 이상인 Anchor box 1 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPN(Regions Proposal Network) 학습을 위한 Target 만들기\n",
    "각 싱글 이미지로부터 나온 Mini-Batch(pos와 neg anchor를 포함한)를 이용하여 Target읆 만든다.\n",
    "- 256개의 Anchor box를 랜덤하게 샘플링한다 -> mini batch의 Loss를 계산할 때 사용\n",
    "- pos와 neg의 비율은 1:1이다.\n",
    "- **결과로 만들어진 Target이 예측값이고, 정답과 비교해서 loss를 계산한다 <- 학습의 목표**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.094077Z",
     "start_time": "2019-12-15T12:16:04.003130Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_ratio = 0.5\n",
    "n_sample = 256\n",
    "\n",
    "n_pos = pos_ratio * n_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### positive label에서 n_pos 랜덤하게 샘플링\n",
    "- 만약 n_pos개보다 적게 샘플링한다면 negative samples를 랜덤하게 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.161040Z",
     "start_time": "2019-12-15T12:16:04.102073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
       "       6120, 6128, 6136, 6358, 6366, 6374, 6382], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index = np.where(label == 1)[0]\n",
    "pos_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Positive Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.191022Z",
     "start_time": "2019-12-15T12:16:04.167037Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.294962Z",
     "start_time": "2019-12-15T12:16:04.198019Z"
    }
   },
   "outputs": [],
   "source": [
    "n_neg = n_sample * np.sum(label == 1)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function 정의\n",
    "Bounding-Box Regression을 이용하여 손실함수 정의<br>\n",
    "![사진-벡터로 변환하는](https://i.imgur.com/1jTnrMG.png)\n",
    "- x,y,w,h는 센터(x,y)와  가로, 세로\n",
    "- x_a, y_a, h_a, w_a는 Anchor box의 센터(x,y)와 가로, 세로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.319949Z",
     "start_time": "2019-12-15T12:16:04.303957Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       ...,\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iou_bbox = bbox[argmax_ious]\n",
    "max_iou_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.351932Z",
     "start_time": "2019-12-15T12:16:04.329943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13.49033201,  10.745166  , 194.50966799, 101.254834  ],\n",
       "       [ 29.49033201,  10.745166  , 210.50966799, 101.254834  ],\n",
       "       [ 45.49033201,  10.745166  , 226.50966799, 101.254834  ],\n",
       "       ...,\n",
       "       [573.49033201, 698.745166  , 754.50966799, 789.254834  ],\n",
       "       [589.49033201, 698.745166  , 770.50966799, 789.254834  ],\n",
       "       [605.49033201, 698.745166  , 786.50966799, 789.254834  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_anchor_boxes # y1, x1, y2, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유효한 Anchor box들의 좌표를 '중앙값(x,y)과 가로, 세로'로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.396904Z",
     "start_time": "2019-12-15T12:16:04.360925Z"
    }
   },
   "outputs": [],
   "source": [
    "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:,0] # y2 - y1\n",
    "width = valid_anchor_boxes[:,3] - valid_anchor_boxes[:,1] # x2 - x1\n",
    "ctr_y = valid_anchor_boxes[:, 0] + 0.5*height # y의 중앙값\n",
    "ctr_x = valid_anchor_boxes[:, 1] + 0.5*width # x의 중앙값\n",
    "\n",
    "# 2개의 Object 중 각 Anchor box와의 IOU값이 더 큰 Object의 box == max_iou_bbox\n",
    "base_height = max_iou_bbox[:,2] - max_iou_bbox[:,0]\n",
    "base_width = max_iou_bbox[:,3] - max_iou_bbox[:,1]\n",
    "base_ctr_y = max_iou_bbox[:,0] + 0.5*base_height\n",
    "base_ctr_x = max_iou_bbox[:,1] + 0.5*base_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.440879Z",
     "start_time": "2019-12-15T12:16:04.417892Z"
    }
   },
   "outputs": [],
   "source": [
    "eps = np.finfo(height.dtype).eps # finfo : float에 대한 정보, eps : 표현 가능한 가장 작은 수\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.495848Z",
     "start_time": "2019-12-15T12:16:04.448874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5855728 ,  2.30914558,  0.7415674 ,  1.64727602],\n",
       "       [ 0.49718446,  2.30914558,  0.7415674 ,  1.64727602],\n",
       "       [ 0.40879611,  2.30914558,  0.7415674 ,  1.64727602],\n",
       "       ...,\n",
       "       [-2.50801936, -5.29225232,  0.7415674 ,  1.64727602],\n",
       "       [-2.59640771, -5.29225232,  0.7415674 ,  1.64727602],\n",
       "       [-2.68479606, -5.29225232,  0.7415674 ,  1.64727602]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose() # y, x, h, w\n",
    "anchor_locs # 유효한 Anchors box의 좌료를 중심+가로+세로 좌표로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 Labels\n",
    "1. **index_inside** : IOU상관 없이 object 안에 들어가 있는 Anchor (8940개)\n",
    "\n",
    "\n",
    "2. **anchor_labels** : 만들어진 모든 anchors박스에 대한 label\n",
    " - object 와 하나도 안 겹치는 부분은 배경으로 간주, -1\n",
    " - IOU가 0.3 이하인 Anchor는 -1 \n",
    " - IOU가 0.7 이상이거나 가장 큰 anchor는 1\n",
    " - 둘 다 아닌 anchor는 0 -> 무시\n",
    "\n",
    " \n",
    "3. **anchor_labels[index_inside]** : 1또는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.526830Z",
     "start_time": "2019-12-15T12:16:04.503844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_labels = np.empty((len(anchors)), dtype = label.dtype) # \n",
    "anchor_labels.fill(-1)\n",
    "anchor_labels[index_inside] = label\n",
    "anchor_labels # [22500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 Anchor box의 Location\n",
    "위에 최종 Labels와 비슷한 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.569805Z",
     "start_time": "2019-12-15T12:16:04.533827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_locations = np.empty(anchors.shape, dtype=anchor_locs.dtype)\n",
    "anchor_locations.fill(0)\n",
    "anchor_locations[index_inside, :] = anchor_locs\n",
    "anchor_locations  # [22500, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위에 만들어진 최종 Location과 Labels는 RPN network의 Target으로 쓰인다<br>\n",
    "**Target을 정답과 비교해 알맞게 바꾸는 Transform을 찾아내는 것이 학습의 목표!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Proposal Network 만들기\n",
    "과거의 모델들은 Selective search, CPMC, MCG 등의 알고리즘을 통해 Region Proposal을 생성했다.<br>\n",
    "Faster R-CNN부터는 이 과정을 deep learning으로 만들었다.\n",
    "- Backbone이었던 VGG16모델을 거친 마지막 feature map을 사용(50x50 size)\n",
    "- nxn size의 Fliter가 slide하면서 각 pixel마다 9개의 region proposals을 예측(여기서는 n=3)\n",
    "- 가로:세로 비율이 (0.5:1, 1:1, 1:0.5)\n",
    "- 1:1기준으로 region propsoal의 크기는 16x16\n",
    "- 50x50 size feature map의 1픽셀 당 원본크기는 16x16(원본 800x800에서 50x50으로 작아졌기 때문에 16:1)\n",
    "- 50x50 size feature map은 512 features, RPN의 결과는 256 features\n",
    "- 2개의 Layer로 찢어진다\n",
    " - Box Regression Layer : 박스를 예측하는 layer\n",
    " - Box Classification Layer : 박스 안에 물체가 있는지 없는지(물체인지 배경인지, -1 또는 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide Window, Regression Layer, Classification Layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.708726Z",
     "start_time": "2019-12-15T12:16:04.581798Z"
    }
   },
   "outputs": [],
   "source": [
    "## n=3인 slide window 이용\n",
    "import torch.nn as nn\n",
    "mid_channels = 256\n",
    "in_channels = 512 # vgg16 결과가 512\n",
    "n_anchor = 9 # 각 location마다 생성되는 anchor의 개수\n",
    "conv1 = nn.Conv2d(in_channels, mid_channels, 3, stride = 1, padding = 1)\n",
    "reg_layer = nn.Conv2d(mid_channels, n_anchor * 4, 1, stride = 1, padding = 0) # 1d Conv2d\n",
    "cls_layer = nn.Conv2d(mid_channels, n_anchor * 2, 1, stride = 1, padding = 0) # SoftMax함수를 이용할 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에 의하면 conv레이어의 가중치를 zero mean과 0.01 standard deviation로 했다고 되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:04.860639Z",
     "start_time": "2019-12-15T12:16:04.715722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 512, 3, 3])\n",
      "torch.Size([36, 256, 1, 1])\n",
      "torch.Size([18, 256, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Slide Window layer\n",
    "conv1.weight.data.normal_(0, 0.01)\n",
    "conv1.bias.data.zero_()\n",
    "\n",
    "# Regression layer\n",
    "reg_layer.weight.data.normal_(0, 0.01)\n",
    "reg_layer.bias.data.zero_()\n",
    "\n",
    "# Classification layer\n",
    "cls_layer.weight.data.normal_(0, 0.01)\n",
    "cls_layer.bias.data.zero_()\n",
    "\n",
    "for lay in [conv1, reg_layer, cls_layer]:\n",
    "    print(lay.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vgg16 결과 전달\n",
    "- Backbone의 결과 feature map을 RPN Network로 전달(output_feature)\n",
    "- 이후 각각 reg, cls layer을 거쳐서 box와 objectness 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:16:05.580229Z",
     "start_time": "2019-12-15T12:16:04.872634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 50, 50]) torch.Size([1, 18, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(output_feature)\n",
    "pred_anchor_locs = reg_layer(x)\n",
    "pred_cls_scores = cls_layer(x)\n",
    "\n",
    "print(pred_anchor_locs.shape, pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RPN Network & ROI Network\n",
    "1. RPN Network\n",
    " - Pred_cls_scores\n",
    " - Pred_anchor_locs\n",
    "\n",
    "2. ROI Network(Proposal layer)\n",
    " - Pred_cls_scores\n",
    " - objectness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:50:09.648287Z",
     "start_time": "2019-12-15T12:50:09.583325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 4])\n",
      "torch.Size([1, 50, 50, 18])\n",
      "torch.Size([1, 22500])\n",
      "torch.Size([1, 22500, 2])\n"
     ]
    }
   ],
   "source": [
    "# contiguous는 텐서를 메모리상에 일렬로 정렬해주는 역할\n",
    "pred_anchor_locs = pred_anchor_locs.permute(0,2,3,1).contiguous().view(1, -1, 4)\n",
    "print(pred_anchor_locs.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.permute(0,2,3,1).contiguous()\n",
    "print(pred_cls_scores.shape)\n",
    "\n",
    "objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:,:,:,:,1].contiguous().view(1, -1)\n",
    "print(objectness_score.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.view(1, -1, 2)\n",
    "print(pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposals 생성하기\n",
    "여러 ratio(0.5:1, 1:1, 1:0.5)로 생성된 proposal들은 겹치는 부분이 많다.<br>\n",
    "따라서 NMS(Non-Maximum Supression)을 이용해 반복되는 proposal을 제거해준다.\n",
    "- cls score을 기준으로 NMS 적용\n",
    "- NMS에서 사용할 IOU의 threshold는 0.7로 고정 -> 1개의 image당 약 2000개의 proposal 생성\n",
    "- NMS의 결과 중 top-N 랭크된 결과들만 detection에 사용한다.\n",
    "- testing을 한 대는 약 300개의 proposal들이 사용된다.(논문에 많은 실험을 통해 저 수치가 적당...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T12:50:10.423423Z",
     "start_time": "2019-12-15T12:50:10.414427Z"
    }
   },
   "outputs": [],
   "source": [
    "nms_thresh = 0.7 # IOU 0.7이상인 것은 제거\n",
    "n_train_pre_nms = 12000\n",
    "n_train_post_nms = 2000\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300\n",
    "min_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposals 만들어지는 과정\n",
    "1. RPN Network의 결과인 predicted box를 bbox(y1, x1, y2, x2)로 변환\n",
    "2. Predicted box를 image에 clip\n",
    "3. Height또는 Width가 Threshold(min_size, 16)보다 작으면 해당 predicted box 제거\n",
    "4. 모든 (Proposal, score) 쌍을 score을 기준으로 내림차순으로 정렬\n",
    " - 여기서 score는 objectness의 점수\n",
    "5. 상위 N개의 Proposal만 취한다.\n",
    " - Training 시 12000개(n_train_pre_nms)\n",
    " - Testing 시 300개(n_test_post_nms)\n",
    "6. IOU의 threshold(0.7)을 적용\n",
    " - 가장 높은 Score을 가진 Proposal 1개와 나머지 Proposal을 전부 비교\n",
    " - 그 중 IOU값이 0.7이상 나오는 box들은 top score Proposal과 같은 물체로 판단\n",
    " - 따라서 0.7이상 나오는 box들은 전부 제거\n",
    "7. 6번을 통해 나온 결과 중 상위 N개의 Proposal만 취한다.\n",
    " - Training 시 2000개(n_train_post_nms)\n",
    " - Testing 시 300개(n_test_post_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RPN Network의 결과인 Predicted box 변환\n",
    "(y_cen, x_cen, h, w) -> (y1, x1, y2, x2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "343px",
    "left": "1005px",
    "right": "20px",
    "top": "120px",
    "width": "341px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
