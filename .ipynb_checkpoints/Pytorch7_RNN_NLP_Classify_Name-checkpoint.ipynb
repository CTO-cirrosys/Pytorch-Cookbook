{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자 단위 RNN으로 이름 분류하기\n",
    "- 문자 하나(ex. a, b,....,z)를 하나의 one-hot벡터로 표현하여 예측 실시\n",
    "- 한 문자의 벡터 길이는 alphabet의 길이(26)이다.\n",
    "- 18개 언어로 된 수천 개의 성을 훈련시킨 후, 철자에 따라 이름이 어떤 언어인지 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DataLoad\n",
    "- data/name 디렉토리에 18개 텍스트 파일이 포함되어 있다.\n",
    "- 각 파일에는 한 줄에 하나의 이름이 포함되어 있다.(로마자)\n",
    "- ASCII로 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.706368Z",
     "start_time": "2018-12-02T12:55:32.692893Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names\\\\Arabic.txt', 'data/names\\\\Chinese.txt', 'data/names\\\\Czech.txt', 'data/names\\\\Dutch.txt', 'data/names\\\\English.txt', 'data/names\\\\French.txt', 'data/names\\\\German.txt', 'data/names\\\\Greek.txt', 'data/names\\\\Irish.txt', 'data/names\\\\Italian.txt', 'data/names\\\\Japanese.txt', 'data/names\\\\Korean.txt', 'data/names\\\\Polish.txt', 'data/names\\\\Portuguese.txt', 'data/names\\\\Russian.txt', 'data/names\\\\Scottish.txt', 'data/names\\\\Spanish.txt', 'data/names\\\\Vietnamese.txt']\n",
      "\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# data 보기\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "path = 'data/names/'\n",
    "filenames = glob.glob(path + '*.txt')\n",
    "print(filenames)\n",
    "print('')\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.739803Z",
     "start_time": "2018-12-02T12:55:32.711856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefABCDEF\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      " \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string # 모든 알파벳을 출력하기 위해 import\n",
    "\n",
    "print(string.hexdigits) # 16진수 표현하는 문자들\n",
    "print(string.punctuation) # 특수문자, 특수기호\n",
    "print(string.whitespace) # 공백문자\n",
    "print(string.printable) # 모든 문자 + 기호\n",
    "\n",
    "all_letters = string.ascii_letters + ' .,;' # 알파벳(대 + 소) + 공백 + ,.;\n",
    "all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.763260Z",
     "start_time": "2018-12-02T12:55:32.744796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "# 유니코드 문자열을 일반 ASCII로 변환\n",
    "# 한 단어를 문자 하나하나로 쪼개서 각각을 ascii로 변환\n",
    "# 또한 변환된 단어의 분류가 'Mn'이 아니고 all_letters에 포함되어 있으면 출력\n",
    "def Unicode_to_Ascii(s):\n",
    "    word = ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "           if unicodedata.category(c) != 'Mn' # Nonspacing Mark, 특정 언어에서 사용되는 기호\n",
    "            and c in all_letters) # c가 all_letter에 포함되어 있는 것\n",
    "    \n",
    "    return word\n",
    "\n",
    "print(Unicode_to_Ascii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.809674Z",
     "start_time": "2018-12-02T12:55:32.768750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# 각 파일로부터 이름 불러오기\n",
    "def readline(filename):\n",
    "    lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    names = [name for name in lines]\n",
    "    \n",
    "    return names\n",
    "\n",
    "lan_list = []\n",
    "lan_name_list = {}\n",
    "\n",
    "# 국가별 이름 목록사전 만들기{lan : [name1, name2...]}\n",
    "for filename in filenames:\n",
    "    lan = os.path.splitext(os.path.basename(filename))[0]\n",
    "    lan_list.append(lan)\n",
    "    name = readline(filename)\n",
    "    lan_name_list[lan] = name\n",
    "    \n",
    "lan_n = len(lan_name_list)\n",
    "print(lan_name_list_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 설명\n",
    "- lan_list : 국가 목록\n",
    "- lan_name_list : 국가별 이름 목록\n",
    "- lan_name_list_n : 국가 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이름을 Tensor로 변환\n",
    "- 하나의 문자(ex. a)를 표현하기 위해서는 size가 1xn_letter인 One-hot 벡터를 사용한다.\n",
    "- a : Tensor[[1,0,0,0......,0]]\n",
    "- b : Tensor[[0,1,0,0.......0]]\n",
    "- z : Tensor[[0,0,0,0.......1]]\n",
    "<br><br>\n",
    "- 단어를 만들어 주기 위해 2차원 행렬(len_of_word x 1 x n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.846606Z",
     "start_time": "2018-12-02T12:55:32.813666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n",
      "torch.Size([6, 1, 56])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 한 letter의 index값을 출력\n",
    "def Letter_to_Index(letter):\n",
    "    letter_index = all_letters.find(letter) \n",
    "     \n",
    "    return letter_index\n",
    "\n",
    "# 각 letter별 index사전 만들기(one-hot 벡터)\n",
    "def Letter_to_Tensor(letter):\n",
    "    letter_tensor = torch.zeros(1, len(all_letters))\n",
    "    letter_tensor[0][Letter_to_Index(letter)] = 1\n",
    "    \n",
    "    return letter_tensor\n",
    "\n",
    "def Name_to_Tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, len(all_letters))\n",
    "    for i, c in enumerate(name):\n",
    "        tensor[i][0][Letter_to_Index(c)] = 1\n",
    "        \n",
    "    return tensor\n",
    "\n",
    "print(Letter_to_Tensor('j'))\n",
    "print(Name_to_Tensor('justin').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 생성\n",
    "- input layer와 hidden layer가 합쳐져 output layer(i2o)를 형성\n",
    "- input layer와 hideen layer가 합쳐져 다음 hidden layer(i2h)를 형성\n",
    "- i2o인 경우 sofrmax 함수를 이용해 확률값 출력하고 정답label과 오차값 계산\n",
    "- i2h인 경우 두 번째 h2로 \n",
    "넘어간다.\n",
    "\n",
    "# 진행 과정\n",
    "1. 이름 하나를 구성하는 각각의 letter들이 한 글자씩 input으로 들어간다.\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.925460Z",
     "start_time": "2018-12-02T12:55:32.856091Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        combined = torch.cat((input, hidden), 1) # 열로 붙이기\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "hidden_n = 128\n",
    "letter_n = len(all_letters)\n",
    "lan_n = len(lan_name_list)\n",
    "\n",
    "\n",
    "rnn = RNN(letter_n, hidden_n, lan_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.957398Z",
     "start_time": "2018-12-02T12:55:32.930949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8790, -2.9147, -2.9150, -2.9073, -2.9154, -3.0303, -2.9035, -2.7867,\n",
      "         -2.8104, -2.8394, -2.9078, -2.9421, -2.8714, -2.9415, -2.9674, -2.8837,\n",
      "         -2.8965, -2.7512]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input = Letter_to_Tensor('a')\n",
    "    hidden = torch.zeros(1, hidden_n)\n",
    "\n",
    "    output, hidden = rnn(input, hidden)\n",
    "    print(output) # 출력은 국가 중 하나이고, 값이 높을수록 가능성이 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:32.989840Z",
     "start_time": "2018-12-02T12:55:32.963389Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9676, -2.9481, -2.8606, -2.9606, -2.9689, -2.8968, -2.9463, -2.7975,\n",
      "         -2.8467, -2.8596, -2.8648, -2.9560, -2.8441, -2.8501, -2.8478, -2.9167,\n",
      "         -2.9189, -2.8033]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input = Name_to_Tensor('justin')\n",
    "    hidden = torch.zeros(1, hidden_n)\n",
    "    output, hidden = rnn(input[0], hidden)\n",
    "    \n",
    "    print(output) # 출력은 국가 중 하나이고, 값이 높을수록 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하기 전 준비과정\n",
    "도움되는 함수 몇 가지가 필요하다.\n",
    " 1. output 결과로부터 가장 큰 값이 무엇인지 출력하기(가장 가능성이 큰 국가 출력)\n",
    " 2. 학습 예시를 출력해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:59:22.353515Z",
     "start_time": "2018-12-02T12:59:22.340038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Greek', 7)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LanfromOutput(output):\n",
    "    top_val, top_i = output.topk(1) # Tensor내에 최대값의 value와 index 찾기(input값으로 개수 선택)\n",
    "    lan_i = top_i[0].item()\n",
    "    \n",
    "    return lan_list[lan_i], lan_i\n",
    "\n",
    "LanfromOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:55:33.073683Z",
     "start_time": "2018-12-02T12:55:33.023776Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langauge : Irish / name = Sullivan\n",
      "Langauge : French / name = Denis\n",
      "Langauge : Vietnamese / name = Quyen\n",
      "Langauge : Arabic / name = Bazzi\n",
      "Langauge : German / name = Wendell\n",
      "Langauge : Vietnamese / name = Duong\n",
      "Langauge : Spanish / name = Del bosque\n",
      "Langauge : Irish / name = Brady\n",
      "Langauge : Arabic / name = Wasem\n",
      "Langauge : Portuguese / name = Rios\n"
     ]
    }
   ],
   "source": [
    "# 학습 예시(이름과 언어) 얻는 빠른 방법도 필요하다.\n",
    "import random\n",
    "\n",
    "def RandomChoice(l):\n",
    "    lan_random = l[random.randint(0, len(l) - 1)]\n",
    "    \n",
    "    return lan_random\n",
    "\n",
    "def RandomTrainingExample():\n",
    "    lan_random = RandomChoice(lan_list) # 랜덤 국가 선택\n",
    "    name = RandomChoice(lan_name_list[lan_random]) # 선택된 국가 중 랜덤 이름 선택\n",
    "    lan_tensor = torch.tensor([lan_list.index(lan_random)], dtype = torch.long) # 국가 index의 tensor\n",
    "    name_tensor = Name_to_Tensor(name) # 이름을 tensor로\n",
    "    \n",
    "    return lan_random, name, lan_tensor, name_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    lan, name, lan_tensor, name_tensor = RandomTrainingExample()\n",
    "    print('Langauge : %s / name = %s' %(lan, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 과정\n",
    "1. input과 target의 Tensor 생성\n",
    "2. 0으로 초기화 된 hidden layer 생성\n",
    "3. 각 문자 읽기 - 다음 문자를 위한 은닉 상태 유지\n",
    "4. output과 target 비교하여 오차 계산\n",
    "5. 오차 역전파\n",
    "6. output과 loss 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:02:37.899131Z",
     "start_time": "2018-12-02T13:02:37.877652Z"
    }
   },
   "outputs": [],
   "source": [
    "# 일단 optimizer를 사용 안하고 그냥 했는데... 일단 그냥 해봄\n",
    "# import torch.optim as optim\n",
    "# optimizer = optim.SGD(rnn.parameters(), lr = 0.005)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "\n",
    "def train(lan_tensor, name_tensor):\n",
    "    \n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(name_tensor.size(0)):\n",
    "        output, hidden = rnn(name_tensor[i], hidden)\n",
    "        \n",
    "    loss = loss_function(output, lan_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "        \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:08:16.972787Z",
     "start_time": "2018-12-02T13:04:29.868622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (0m 10s) 1.4001 Than / Vietnamese ✓\n",
      "10000 10% (0m 21s) 2.3506 Allard / Japanese ✗ (French)\n",
      "15000 15% (0m 33s) 1.3489 Almeida / Portuguese ✓\n",
      "20000 20% (0m 43s) 2.1541 Fabron / English ✗ (French)\n",
      "25000 25% (0m 54s) 0.4109 Antonini / Italian ✓\n",
      "30000 30% (1m 5s) 2.1287 Cerney / Dutch ✗ (Czech)\n",
      "35000 35% (1m 16s) 2.4284 Greenwood / Scottish ✗ (English)\n",
      "40000 40% (1m 27s) 1.8618 Fabian / Arabic ✗ (French)\n",
      "45000 45% (1m 39s) 2.6074 Alsop / Scottish ✗ (English)\n",
      "50000 50% (1m 50s) 2.1932 Ferro / Portuguese ✗ (Italian)\n",
      "55000 55% (2m 1s) 1.8700 Awad / Chinese ✗ (Arabic)\n",
      "60000 60% (2m 14s) 1.8602 Renaud / German ✗ (French)\n",
      "65000 65% (2m 26s) 1.3831 Nestrojil / Czech ✓\n",
      "70000 70% (2m 38s) 2.0325 Monet / German ✗ (French)\n",
      "75000 75% (2m 50s) 2.0827 Reyer / German ✗ (French)\n",
      "80000 80% (3m 3s) 0.0812 Morrison / Scottish ✓\n",
      "85000 85% (3m 14s) 1.0953 Rodriquez / Spanish ✓\n",
      "90000 90% (3m 25s) 1.9062 Roosevelt / French ✗ (Dutch)\n",
      "95000 95% (3m 36s) 2.6587 Kim / Korean ✗ (Vietnamese)\n",
      "100000 100% (3m 47s) 0.1425 Ocaskova / Czech ✓\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "iter_n = 100000\n",
    "\n",
    "loss_avg = 0\n",
    "loss_list = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for i in range(1, iter_n + 1):\n",
    "    lan, name, lan_tensor, name_tensor = RandomTrainingExample()\n",
    "    output, loss = train(lan_tensor, name_tensor)\n",
    "    loss_avg += loss\n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    if i % 5000 == 0:\n",
    "        guess, guess_i = LanfromOutput(output)\n",
    "        correct = '✓' if guess == lan else  '✗ (%s)' % lan\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (i, i / iter_n * 100, timeSince(start), loss, name, guess, correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나만의 방식으로 재도전\n",
    "- 문서에 나와있는 방식은 너무 복잡하다.\n",
    "- 좀 더 간단하게 구현 시도!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T18:26:03.364119Z",
     "start_time": "2018-12-02T18:26:03.352643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names\\\\Arabic.txt', 'data/names\\\\Chinese.txt', 'data/names\\\\Czech.txt', 'data/names\\\\Dutch.txt', 'data/names\\\\English.txt', 'data/names\\\\French.txt', 'data/names\\\\German.txt', 'data/names\\\\Greek.txt', 'data/names\\\\Irish.txt', 'data/names\\\\Italian.txt', 'data/names\\\\Japanese.txt', 'data/names\\\\Korean.txt', 'data/names\\\\Polish.txt', 'data/names\\\\Portuguese.txt', 'data/names\\\\Russian.txt', 'data/names\\\\Scottish.txt', 'data/names\\\\Spanish.txt', 'data/names\\\\Vietnamese.txt']\n",
      "Number of Language : 18\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from io import open\n",
    "\n",
    "path = 'data/names/'\n",
    "filenames = glob.glob(path + '*.txt')\n",
    "print(filenames)\n",
    "print('Number of Language : %d' %len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 국가별 이름 사전 만들기\n",
    "- {국가1 : [이름1, 이름2...], 국가2 : [이름1, 이름2...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T18:28:51.831103Z",
     "start_time": "2018-12-02T18:28:51.820123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', '.txt')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.path.splitext(os.path.basename('a.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T18:58:55.803454Z",
     "start_time": "2018-12-02T18:58:55.794990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vietnamese', '.txt')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(os.path.basename(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T19:05:42.047303Z",
     "start_time": "2018-12-02T19:05:42.041793Z"
    }
   },
   "outputs": [],
   "source": [
    "lan = [os.path.splitext(os.path.basename(filename))[0] for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
