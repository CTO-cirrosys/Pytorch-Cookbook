{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing remove.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile remove.py\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vgg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile vgg.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class myVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, class_num=10, init_weights=True):\n",
    "        super(myVGG, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, padding=0, ceil_mode = True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, self.class_num)\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        skip = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2_1(skip))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)        \n",
    "        \n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.avgpool(x)        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        skip_flatten = torch.flatten(skip, 1)\n",
    "        skip_input = x + skip_flatten.repeat(1,2)\n",
    "        \n",
    "        x = F.relu(self.fc1(skip_input))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc3(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000 // 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from vgg import myVGG\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch myVGG16 Training')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.001, type=float, help='initial learning rate')\n",
    "parser.add_argument('--mm', '--momentum', default=0.9, type=float, help='momentum rate')\n",
    "parser.add_argument('--batch', '--batch-size', default=256, type=int, help='mini-batch size (default: 128)')\n",
    "parser.add_argument('--epochs', default=30, type=int, help='number of total epochs to run')\n",
    "\n",
    "args = parser.parse_get()\n",
    "\n",
    "def train(trainloader, model, loss_func, optimizer, epoch, device):\n",
    "    \n",
    "    model.train()  \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_func(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i % 20 == 0) or (i == 50000 // args.batch):\n",
    "            print('Train Epoch : {} [{}/{} ({:.0f}%)]\\tLoss : {:.6f}'.format(\n",
    "                epoch, i * len(images), len(trainloader.dataset),\n",
    "                100 * i / len(trainloader), loss.item()))\n",
    "\n",
    "def val(valloader, model, loss_func, device):  \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in valloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += loss_func(output, labels)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        \n",
    "        \n",
    "    val_loss = val_loss / len(valloader.dataset)\n",
    "    \n",
    "    val_accuracy = (100 * val_correct) / len(valloader.dataset)\n",
    "    print('\\nVal set : Average loss: {:.4f}, Val_Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, val_correct, len(valloader.dataset), val_accuracy))\n",
    "          \n",
    "    return val_correct\n",
    "                 \n",
    "def main():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('GPU로 학습합니다.')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('CPU로 학습합니다.')\n",
    "        \n",
    "        \n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0], [1])\n",
    "        ])\n",
    "\n",
    "    train_val_set = torchvision.datasets.MNIST(root = './data', train = True,\n",
    "                                          download = True, transform=transform)\n",
    "    \n",
    "    trainset, valset = torch.utils.data.random_split(train_val_set, [50000,10000])\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = args.batch,\n",
    "                                              shuffle = True, num_workers=1)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size = args.batch,\n",
    "                                              shuffle = False, num_workers=1)\n",
    "    \n",
    "    model = myVGG().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.mm)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    epoch = args.epochs\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(1, epoch+1):\n",
    "        train(trainloader, model, loss_func, optimizer, epoch, device)\n",
    "        accuracy = val(valloader, model, loss_func, device)\n",
    "        scheduler.step()            \n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "                          \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from vgg import myVGG\n",
    "\n",
    "def test(testloader, model, loss_func, device):  \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            test_loss += loss_func(output, labels)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        \n",
    "        \n",
    "    test_loss = test_loss / len(testloader.dataset)\n",
    "    \n",
    "    accuracy = (100 * correct) / len(testloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testloader.dataset), accuracy))\n",
    "    print('이 모델의 정확도는 약 98%입니다. 감사합니다.')\n",
    "       \n",
    "          \n",
    "def main():\n",
    "    print('안녕하세요! 사공용협입니다. 사전과제 제출하겠습니다.')\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('GPU 사용 중.......')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('CPU 사용 중')\n",
    "        \n",
    "        \n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0], [1])\n",
    "        ])    \n",
    "    testset = torchvision.datasets.MNIST(root = './data', train = False,\n",
    "                                         download = True, transform=transform)    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "                                             shuffle = True, num_workers=1)    \n",
    "\n",
    "    \n",
    "    model = myVGG().to(device)\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    test(testloader, model, loss_func, device)\n",
    "                         \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "class myVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, class_num=10, init_weights=True):\n",
    "        super(myVGG, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, padding=0, ceil_mode = True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, self.class_num)\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        skip = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2_1(skip))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)        \n",
    "        \n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.avgpool(x)        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        skip_flatten = torch.flatten(skip, 1)\n",
    "        skip_input = x + skip_flatten.repeat(1,2)\n",
    "        \n",
    "        x = F.relu(self.fc1(skip_input))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc3(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "                \n",
    "def train(trainloader, model, loss_func, optimizer, epoch, device):\n",
    "    \n",
    "    model.train()  \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_func(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(images), len(trainloader.dataset),\n",
    "                100 * i / len(trainloader), loss.item()))\n",
    "\n",
    "def val(valloader, model, loss_func, device):  \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in valloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += loss_func(output, labels)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        \n",
    "        \n",
    "    val_loss = val_loss / len(valloader.dataset)\n",
    "    \n",
    "    val_accuracy = (100 * val_correct) / len(valloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Val_Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, val_correct, len(valloader.dataset), val_accuracy))\n",
    "          \n",
    "    return val_correct\n",
    "\n",
    "def test(testloader, model, loss_func, device):  \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            test_loss += loss_func(output, labels)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        \n",
    "        \n",
    "    test_loss = test_loss / len(testloader.dataset)\n",
    "    \n",
    "    accuracy = (100 * correct) / len(testloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testloader.dataset), accuracy))\n",
    "       \n",
    "          \n",
    "def main():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('GPU로 학습합니다.')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('CPU로 학습합니다.')\n",
    "        \n",
    "        \n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0], [1])\n",
    "        ])\n",
    "\n",
    "    train_val_set = torchvision.datasets.MNIST(root = './data', train = True,\n",
    "                                          download = True, transform=transform)\n",
    "    trainset, valset = torch.utils.data.random_split(train_val_set, [50000,10000])\n",
    "    \n",
    "    testset = torchvision.datasets.MNIST(root = './data', train = False,\n",
    "                                         download = True, transform=transform)    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = 256,\n",
    "                                              shuffle = True, num_workers=1)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size = 256,\n",
    "                                              shuffle = False, num_workers=1)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "                                             shuffle = True, num_workers=1)    \n",
    "\n",
    "    \n",
    "    model = myVGG().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    epoch = 20\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    best_accuracy = 0\n",
    "    print(args.test)\n",
    "    for epoch in range(1, epoch+1):\n",
    "        if args.test:\n",
    "            test(testloader, model, loss_func, device)\n",
    "        else:\n",
    "            train(trainloader, model, loss_func, optimizer, epoch, device)\n",
    "            accuracy = val(valloader, model, loss_func, device)\n",
    "            scheduler.step()            \n",
    "            if best_accuracy < accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(model, 'best_model.pth')\n",
    "                          \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, class_num=10, init_weights=True):\n",
    "        super(myVGG, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, padding=0, ceil_mode = True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, self.class_num)\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        skip = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2_1(skip))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)        \n",
    "        \n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.avgpool(x)        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc3(x)\n",
    "        \n",
    "        return skip_flatten\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델에 대한 간단한 정리\n",
    "- MNIST 데이터가 28x28인데 그냥 돌리면 나중에 사이즈가 0이 되어 사라짐<br>\n",
    "그래서 maxpool layer에 celi_mode = True을 통해 홀수가 나왔을 때 올림으로서 0이 되는 것을 방지함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
