{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c68780",
   "metadata": {},
   "source": [
    "# GPU DataParallel\n",
    "- 데이터의 Batch를 Parallel하게 학습하는 방법\n",
    "- Batch size가 256이고 4개의 GPU가 있을 때, 각 GPU마다 64 batch size로 학습하는 테크닉\n",
    "- 여러 GPU를 이용해 batch size를 높여 학습시간을 단축할 수 있음\n",
    "\n",
    "- DataParallel 방법은 총 4가지가 있음\n",
    " - pytorch의 nn.DataParallel\n",
    " - pytorch 외부 패키지 pytorch-encoding\n",
    " - pytorch의 nn.DistributedDataParallel\n",
    " - Nvidia의 Apex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abb5c9",
   "metadata": {},
   "source": [
    "![gpu image](https://miro.medium.com/max/1400/1*F6SXjBp6BCoFTZ26RKnz9A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a86046",
   "metadata": {},
   "source": [
    "## 0. 준비물\n",
    "- Environment : 4개의 GPU 서버\n",
    "- Dataset : MNIST\n",
    "- Model : VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db47c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc0424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU :  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=490, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset & DataLoader\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0], [1])\n",
    "])\n",
    "\n",
    "data_path = os.path.join(os.getenv('HOME'), 'data')\n",
    "train_batch = 2048\n",
    "test_batch = 128\n",
    "trainset = torchvision.datasets.MNIST(root = data_path, train = True,\n",
    "                                      download = True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = train_batch,\n",
    "                                          shuffle = True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root = data_path, train = False,\n",
    "                                     download = True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = test_batch,\n",
    "                                         shuffle = True, num_workers=4)\n",
    "\n",
    "# GPU set\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus >= 1:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Number of GPU : ', num_gpus)   \n",
    "\n",
    "# Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(10 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # 28 28\n",
    "        x = self.pool(x)          # 14 14\n",
    "        x = F.relu(self.conv2(x)) # 14 14\n",
    "        x = self.pool(x)          # 7 7\n",
    "        x = x.view(-1, 10 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "# loss & oiptimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33ebb6",
   "metadata": {},
   "source": [
    "## 1. Pytorch의 DataParallel\n",
    "- 가장 간단한 방법\n",
    "- 하지만 데이터를 scatter하고 gather하는 과정에서 1개의 GPU에 메모리가 몰리는 단점이 있음\n",
    " - output의 GPU를 다른 GPU로 할당하면 조금이나마 메모리 분산이 가능함\n",
    " - 하지만 이것도 문제해결을 위한 방법은 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8462493a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (fc1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "    \n",
    "model_parallel = nn.DataParallel(model)\n",
    "model_parallel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0455aea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2]-----[29/117] LOSS : 62.476------ Time : 18\n",
      "\n",
      "[2/2]-----[29/117] LOSS : 43.534------ Time : 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "import time\n",
    "\n",
    "EPOCH = 2\n",
    "for e in range(1, EPOCH+1):\n",
    "    model_parallel.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_parallel(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss\n",
    "        now = time.time()\n",
    "        print('\\r[%d/%d]-----[%d/%d] LOSS : %.3f------ Time : %d' \n",
    "              %(e, EPOCH, i, 60000/512, running_loss, now - start_time), end = '')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d477f5",
   "metadata": {},
   "source": [
    "## 1-1. Outputs을 다른 GPU에 할당하기\n",
    "- batch 분배, loss 계산, output 등이 모두 0번 GPU에 몰려있어서 다른 GPU로 분산시키기\n",
    "- 효과는 매우 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4014eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
    "model_parallel = nn.DataParallel(model, output_device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151455a",
   "metadata": {},
   "source": [
    "## 2. Custom된 dataparallel(외부 패키지)\n",
    "- loss 계산을 1개의 GPU가 아닌 각 GPU로 분산시키는 방법\n",
    "- 1개의 GPU에 메모리가 몰리는 문제를 해결할 수 있음\n",
    "- 1-1의 방법보다는 상대적으로 메모리 분배가 잘됨\n",
    "\n",
    "> 외부패키지인 Pytorch-Encoding 패키지에서 parallel.py 파일을 불러와야함\n",
    "<br>\n",
    "\n",
    "##### 적용 방법\n",
    "- https://github.com/zhanghang1989/PyTorch-Encoding 에서 encoding/parallel.py 다운로드\n",
    "- model에 DataParallelModel 적용\n",
    "- loss function에 DataParallelCriterion 적용\n",
    "\n",
    "##### 현재 사용 x -> 에러뜸\n",
    "- https://github.com/zhanghang1989/PyTorch-Encoding/issues/361\n",
    "- 이걸 만든 사람도 이제 이거 쓰지 말고 pytorch의 DDP 쓰라고함\n",
    "- 이거 업그레이드 안 할 듯..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb1481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "model_parallel2 = DataParallelModel(model).to(device)\n",
    "loss_func2 = DataParallelCriterion(loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "import time\n",
    "\n",
    "EPOCH = 2\n",
    "for e in range(1, EPOCH+1):\n",
    "    model_parallel2.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_parallel2(images)\n",
    "        loss = loss_func2(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss\n",
    "        now = time.time()\n",
    "        print('\\r[%d/%d]-----[%d/%d] LOSS : %.3f------ Time : %d' \n",
    "              %(e, EPOCH, i, 60000/512, running_loss, now - start_time), end = '')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9b905",
   "metadata": {},
   "source": [
    "## 3. Pytorch의 Distributed Data Parallel\n",
    "- Pytorch에서 제공해주는 DDP 사용\n",
    "- Batch 뿐만 아니라 여러 컴퓨터(머신)에 대해서도 Parallel연산이 가능함\n",
    "- Multi processor를 사용해야하기 때문에 약간 복잡함(설정이 필요함)\n",
    " - 학습을 진행시키는 코드를 함수로 작성(main_worker)\n",
    "   - GPU 분산 학습을 위해 main_worker 초기화(init_process_group)\n",
    "   - dataloader 분산처리를 위해 sampler 설정\n",
    "   - model 분산처리를 위해 DDP 적용\n",
    " - 해당 함수를 multi-processor로 실행\n",
    " \n",
    "> Jupyter Notebook에서는 Multi-processor가 작동하지 않음<br>\n",
    "해결 방법은 있는데 뭔가 복잡해보임\n",
    "https://discuss.pytorch.org/t/multi-gpu-ddp-in-jupyter-notebook/104302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97fe6f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ddp_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp_example.py\n",
    "# py파일로 저장 후 실행\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(10 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # 28 28\n",
    "        x = self.pool(x)          # 14 14\n",
    "        x = F.relu(self.conv2(x)) # 14 14\n",
    "        x = self.pool(x)          # 7 7\n",
    "        x = x.view(-1, 10 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "def main_worker(rank, world_size):\n",
    "    # Init DDP\n",
    "    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "    # DataLoader\n",
    "    transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0], [1])\n",
    "    ])\n",
    "\n",
    "    data_path = os.path.join(os.getenv('HOME'), 'data')\n",
    "    train_batch = 2048\n",
    "    test_batch = 128\n",
    "    trainset = torchvision.datasets.MNIST(root = data_path, train = True,\n",
    "                                          download = True, transform=transform)\n",
    "    train_sampler = DistributedSampler(trainset)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = train_batch,\n",
    "                                              num_workers=4, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(root = data_path, train = False,\n",
    "                                         download = True, transform=transform)\n",
    "    test_sampler = DistributedSampler(testset)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = test_batch,\n",
    "                                             num_workers=4, pin_memory=True, sampler=test_sampler)    \n",
    "    # Model\n",
    "    model = Net()\n",
    "    model_ddp = DDP(model.to(rank), device_ids=[rank])\n",
    "    \n",
    "    # Optimizer\n",
    "    loss_func = nn.CrossEntropyLoss().to(rank)\n",
    "    optimizer = optim.SGD(model_ddp.parameters(), lr = 0.1)\n",
    "    \n",
    "    # train\n",
    "    EPOCH = 2\n",
    "    for e in range(1, EPOCH+1):\n",
    "        train_sampler.set_epoch(e)\n",
    "        model_ddp.train()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(rank), labels.to(rank)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "            now = time.time()\n",
    "            print('\\r[%d/%d]-----[%d/%d] LOSS : %.3f------ Time : %d' \n",
    "                  %(e, EPOCH, i, 60000/512, running_loss, now - start_time), end = '')\n",
    "        print('\\n')\n",
    "\n",
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(main_worker,\n",
    "            args=(world_size,),\n",
    "            nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140bc91",
   "metadata": {},
   "source": [
    "## 4. Apex 이용하기\n",
    "- 3번 Example인 DDP랑 비슷하지만 Multi-processor를 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b808f102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ddp_example2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp_example2.py\n",
    "# py파일로 저장 후 실행\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from apex import amp\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(10 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # 28 28\n",
    "        x = self.pool(x)          # 14 14\n",
    "        x = F.relu(self.conv2(x)) # 14 14\n",
    "        x = self.pool(x)          # 7 7\n",
    "        x = x.view(-1, 10 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "def main():\n",
    "    # parser\n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--local_rank\", default=1, type=int)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Init DDP\n",
    "    args.world_size = 1\n",
    "    dist.init_process_group(backend='nccl')\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    # DataLoader\n",
    "    transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0], [1])\n",
    "    ])\n",
    "\n",
    "    data_path = os.path.join(os.getenv('HOME'), 'data')\n",
    "    train_batch = 128\n",
    "    test_batch = 128\n",
    "    trainset = torchvision.datasets.MNIST(root = data_path, train = True,\n",
    "                                          download = True, transform=transform)\n",
    "    train_sampler = DistributedSampler(trainset)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = train_batch,\n",
    "                                              num_workers=4, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(root = data_path, train = False,\n",
    "                                         download = True, transform=transform)\n",
    "    test_sampler = DistributedSampler(testset)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = test_batch,\n",
    "                                             num_workers=4, pin_memory=True, sampler=test_sampler)    \n",
    "    # Model\n",
    "    model = Net().cuda()\n",
    "    # Optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "    \n",
    "    model_ddp = DDP(model)\n",
    "    \n",
    "    # train\n",
    "    EPOCH = 5\n",
    "    for e in range(1, EPOCH+1):\n",
    "        train_sampler.set_epoch(e)\n",
    "        model_ddp.train()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_ddp(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "            now = time.time()\n",
    "            print('\\r[%d/%d]-----[%d/%d] LOSS : %.3f------ Time : %d' \n",
    "                  %(e, EPOCH, i, 60000/512, running_loss, now - start_time), end = '')\n",
    "        print('\\n')\n",
    "        \n",
    "    if local_rank == 0:\n",
    "        print('final loss : ')\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b5ca5",
   "metadata": {},
   "source": [
    "## Reference codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "145c8866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ddp_example3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp_example3.py\n",
    "import torch\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
    "\n",
    "def set_random_seeds(random_seed=0):\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "def evaluate(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def main():\n",
    "\n",
    "    num_epochs_default = 2\n",
    "    batch_size_default = 256 # 1024\n",
    "    learning_rate_default = 0.1\n",
    "    random_seed_default = 0\n",
    "    model_dir_default = \"saved_models\"\n",
    "    model_filename_default = \"resnet_distributed.pth\"\n",
    "\n",
    "    # Each process runs on 1 GPU device specified by the local_rank argument.\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\"--local_rank\", type=int, help=\"Local rank. Necessary for using the torch.distributed.launch utility.\")\n",
    "    parser.add_argument(\"--num_epochs\", type=int, help=\"Number of training epochs.\", default=num_epochs_default)\n",
    "    parser.add_argument(\"--batch_size\", type=int, help=\"Training batch size for one process.\", default=batch_size_default)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, help=\"Learning rate.\", default=learning_rate_default)\n",
    "    parser.add_argument(\"--random_seed\", type=int, help=\"Random seed.\", default=random_seed_default)\n",
    "    parser.add_argument(\"--model_dir\", type=str, help=\"Directory for saving models.\", default=model_dir_default)\n",
    "    parser.add_argument(\"--model_filename\", type=str, help=\"Model filename.\", default=model_filename_default)\n",
    "    parser.add_argument(\"--resume\", action=\"store_true\", help=\"Resume training from saved checkpoint.\")\n",
    "    argv = parser.parse_args()\n",
    "\n",
    "    local_rank = argv.local_rank\n",
    "    num_epochs = argv.num_epochs\n",
    "    batch_size = argv.batch_size\n",
    "    learning_rate = argv.learning_rate\n",
    "    random_seed = argv.random_seed\n",
    "    model_dir = argv.model_dir\n",
    "    model_filename = argv.model_filename\n",
    "    resume = argv.resume\n",
    "    \n",
    "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    # Create directories outside the PyTorch program\n",
    "    # Do not create directory here because it is not multiprocess safe\n",
    "    '''\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    '''\n",
    "\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    # We need to use seeds to make sure that the models initialized in different processes are the same\n",
    "    set_random_seeds(random_seed=random_seed)\n",
    "\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    # torch.distributed.init_process_group(backend=\"gloo\")\n",
    "\n",
    "    # Encapsulate the model on the GPU assigned to the current process\n",
    "    model = torchvision.models.resnet18(pretrained=False)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "    device = torch.device(\"cuda:{}\".format(local_rank))\n",
    "    model = model.to(device)\n",
    "    ddp_model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], output_device=local_rank)\n",
    "\n",
    "    # We only save the model who uses device \"cuda:0\"\n",
    "    # To resume, the device for the saved model would also be \"cuda:0\"\n",
    "    if resume == True:\n",
    "        map_location = {\"cuda:0\": \"cuda:{}\".format(local_rank)}\n",
    "        ddp_model.load_state_dict(torch.load(model_filepath, map_location=map_location))\n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914), (0.2023)),\n",
    "    ])\n",
    "\n",
    "    # Data should be prefetched\n",
    "    # Download should be set to be False, because it is not multiprocess safe\n",
    "    data_path = os.path.join(os.getenv('HOME'), 'data')\n",
    "    train_set = torchvision.datasets.MNIST(root=data_path, train=True, download=False, transform=transform) \n",
    "    test_set = torchvision.datasets.MNIST(root=data_path, train=False, download=False, transform=transform)\n",
    "\n",
    "    # Restricts data loading to a subset of the dataset exclusive to the current process\n",
    "    train_sampler = DistributedSampler(dataset=train_set)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=batch_size, sampler=train_sampler, num_workers=8)\n",
    "    # Test loader does not have to follow distributed sampling strategy\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "    # Loop over the dataset multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(\"Local Rank: {}, Epoch: {}, Training ...\".format(local_rank, epoch))\n",
    "        \n",
    "        # Save and evaluate model routinely\n",
    "        if epoch % 10 == 0:\n",
    "            if local_rank == 0:\n",
    "                accuracy = evaluate(model=ddp_model, device=device, test_loader=test_loader)\n",
    "                torch.save(ddp_model.state_dict(), model_filepath)\n",
    "                print(\"-\" * 75)\n",
    "                print(\"Epoch: {}, Accuracy: {}\".format(epoch, accuracy))\n",
    "                print(\"-\" * 75)\n",
    "\n",
    "        ddp_model.train()\n",
    "\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ddp_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
