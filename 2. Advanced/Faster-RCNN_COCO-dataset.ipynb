{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import torch\r\n",
    "from torch.utils.data import DataLoader, Dataset\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\r\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\r\n",
    "from torchinfo import summary\r\n",
    "\r\n",
    "import time\r\n",
    "from PIL import Image\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from PythonFiles.cocodataset import myCocoDetection, coco_show\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "import os\r\n",
    "\r\n",
    "import torch\r\n",
    "from torchvision.datasets import CocoDetection\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.patches as patches\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "   \r\n",
    "class myCocoDetection(CocoDetection):\r\n",
    "    def __init__(\r\n",
    "        self, root, annFile, remove_invalid_data, transform):\r\n",
    "        super(myCocoDetection, self).__init__(root, annFile)\r\n",
    "        \r\n",
    "        if remove_invalid_data:\r\n",
    "            ids = []\r\n",
    "            for img_id in self.ids:\r\n",
    "                ann_ids = self.coco.getAnnIds(imgIds=img_id)\r\n",
    "                anno = self.coco.loadAnns(ann_ids)\r\n",
    "                if self.is_valid_data(anno):\r\n",
    "                    ids.append(img_id)\r\n",
    "            self.ids = ids\r\n",
    "            \r\n",
    "        self.transform = transform\r\n",
    "        \r\n",
    "    def is_valid_data(self, anno):\r\n",
    "        if len(anno) == 0:\r\n",
    "            return False\r\n",
    "        for obj in anno:\r\n",
    "            for o in obj['bbox'][2:]:\r\n",
    "                if o <= 1:\r\n",
    "                    return False\r\n",
    "        return True\r\n",
    "    \r\n",
    "    def _load_image(self, idx: int):\r\n",
    "        path = self.coco.loadImgs(idx)[0][\"file_name\"]\r\n",
    "        return Image.open(os.path.join(self.root, path)).convert(\"RGB\")\r\n",
    "    \r\n",
    "    def _load_target(self, idx):\r\n",
    "        return self.coco.loadAnns(self.coco.getAnnIds(idx))\r\n",
    "    \r\n",
    "    def __getitem__(self, index: int):\r\n",
    "        idx = self.ids[index]\r\n",
    "        image = self._load_image(idx)\r\n",
    "        target = self._load_target(idx)\r\n",
    "        \r\n",
    "        bboxes, labels = [], []\r\n",
    "        for obj in target:\r\n",
    "            bbox = [obj['bbox'][0],\r\n",
    "                    obj['bbox'][1],\r\n",
    "                    obj['bbox'][0] + obj['bbox'][2],\r\n",
    "                    obj['bbox'][1] + obj['bbox'][3]]\r\n",
    "            bboxes.append(bbox)\r\n",
    "            \r\n",
    "            labels.append(obj['category_id'])\r\n",
    "        \r\n",
    "        if self.transform:\r\n",
    "            image = self.transform(image)\r\n",
    "            bboxes = self.transform(np.array(bboxes)).reshape(-1, 4)\r\n",
    "            \r\n",
    "            targets ={}\r\n",
    "            labels = torch.tensor(labels).type(torch.int64)\r\n",
    "            bboxes = bboxes.type(torch.FloatTensor)\r\n",
    "            targets['boxes'] = bboxes\r\n",
    "            targets['labels'] = labels\r\n",
    "            \r\n",
    "            return image, targets, idx        \r\n",
    "            \r\n",
    "        return image, bboxes, labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "TRAIN_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 2\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9\n",
    "EPOCHS = 50\n",
    "\n",
    "np.random.seed(40)\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed(40)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "train_path = '../../data/COCO/train2017'\n",
    "train_ann = '../../data/COCO/annotations/instances_train2017.json'\n",
    "test_path = '../../data/COCO/val2017'\n",
    "test_ann = '../../data/COCO/annotations/instances_val2017.json'\n",
    "\n",
    "trainset = myCocoDetection(root=train_path, annFile=train_ann,\n",
    "                           remove_invalid_data=True,\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.87s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.64s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "coco_show(train_loader, figsize=(2,2))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=True)\n",
    "summary(model, (TRAIN_BATCH_SIZE, 3, 224, 224))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "FasterRCNN                                              --                        --\n",
       "├─BackboneWithFPN: 1                                    --                        --\n",
       "│    └─FeaturePyramidNetwork: 2                         --                        --\n",
       "│    │    └─ModuleList: 3-1                             --                        984,064\n",
       "│    │    └─ModuleList: 3-2                             --                        2,360,320\n",
       "├─GeneralizedRCNNTransform: 1-1                         --                        --\n",
       "├─BackboneWithFPN: 1-2                                  [2, 256, 13, 13]          --\n",
       "│    └─IntermediateLayerGetter: 2-1                     [2, 2048, 25, 25]         --\n",
       "│    │    └─Conv2d: 3-3                                 [2, 64, 400, 400]         (9,408)\n",
       "│    │    └─FrozenBatchNorm2d: 3-4                      [2, 64, 400, 400]         --\n",
       "│    │    └─ReLU: 3-5                                   [2, 64, 400, 400]         --\n",
       "│    │    └─MaxPool2d: 3-6                              [2, 64, 200, 200]         --\n",
       "│    │    └─Sequential: 3-7                             [2, 256, 200, 200]        (212,992)\n",
       "│    │    └─Sequential: 3-8                             [2, 512, 100, 100]        1,212,416\n",
       "│    │    └─Sequential: 3-9                             [2, 1024, 50, 50]         7,077,888\n",
       "│    │    └─Sequential: 3-10                            [2, 2048, 25, 25]         14,942,208\n",
       "│    └─FeaturePyramidNetwork: 2-2                       [2, 256, 13, 13]          --\n",
       "│    │    └─LastLevelMaxPool: 3-11                      [2, 256, 200, 200]        --\n",
       "├─RegionProposalNetwork: 1-3                            [1000, 4]                 --\n",
       "│    └─RPNHead: 2-3                                     [2, 3, 200, 200]          --\n",
       "│    │    └─Conv2d: 3-12                                [2, 256, 200, 200]        590,080\n",
       "│    │    └─Conv2d: 3-13                                [2, 3, 200, 200]          771\n",
       "│    │    └─Conv2d: 3-14                                [2, 12, 200, 200]         3,084\n",
       "│    │    └─Conv2d: 3-15                                [2, 256, 100, 100]        (recursive)\n",
       "│    │    └─Conv2d: 3-16                                [2, 3, 100, 100]          (recursive)\n",
       "│    │    └─Conv2d: 3-17                                [2, 12, 100, 100]         (recursive)\n",
       "│    │    └─Conv2d: 3-18                                [2, 256, 50, 50]          (recursive)\n",
       "│    │    └─Conv2d: 3-19                                [2, 3, 50, 50]            (recursive)\n",
       "│    │    └─Conv2d: 3-20                                [2, 12, 50, 50]           (recursive)\n",
       "│    │    └─Conv2d: 3-21                                [2, 256, 25, 25]          (recursive)\n",
       "│    │    └─Conv2d: 3-22                                [2, 3, 25, 25]            (recursive)\n",
       "│    │    └─Conv2d: 3-23                                [2, 12, 25, 25]           (recursive)\n",
       "│    │    └─Conv2d: 3-24                                [2, 256, 13, 13]          (recursive)\n",
       "│    │    └─Conv2d: 3-25                                [2, 3, 13, 13]            (recursive)\n",
       "│    │    └─Conv2d: 3-26                                [2, 12, 13, 13]           (recursive)\n",
       "│    └─AnchorGenerator: 2-4                             [159882, 4]               --\n",
       "├─RoIHeads: 1-4                                         --                        --\n",
       "│    └─MultiScaleRoIAlign: 2-5                          [2000, 256, 7, 7]         --\n",
       "│    └─TwoMLPHead: 2-6                                  [2000, 1024]              --\n",
       "│    │    └─Linear: 3-27                                [2000, 1024]              12,846,080\n",
       "│    │    └─Linear: 3-28                                [2000, 1024]              1,049,600\n",
       "│    └─FastRCNNPredictor: 2-7                           [2000, 91]                --\n",
       "│    │    └─Linear: 3-29                                [2000, 91]                93,275\n",
       "│    │    └─Linear: 3-30                                [2000, 364]               373,100\n",
       "=========================================================================================================\n",
       "Total params: 41,755,286\n",
       "Trainable params: 41,532,886\n",
       "Non-trainable params: 222,400\n",
       "Total mult-adds (G): 268.85\n",
       "=========================================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 2916.85\n",
       "Params size (MB): 167.02\n",
       "Estimated Total Size (MB): 3085.07\n",
       "========================================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CUDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "import torch.optim as optim\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "train_loss_per_epoch_list = []\n",
    "train_loss_per_iter_list = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k:v.to(device) for k,v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(v for v in loss_dict.values())\n",
    "        train_loss_per_iter_list.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        end = time.time()\n",
    "        if i % 10000 == 0:\n",
    "            print('EPOCH : [%d/%d] ---- Iter : [%d/%d] ---- Loss : %0.3f --- Time : %0.3f'\n",
    "                 % (e+1, EPOCHS, i, len(train_loader), loss, (end-start)*10))\n",
    "            \n",
    "    train_loss_per_epoch_list.append(loss)        \n",
    "    print('EPOCH : [%d/%d] ---- Iter : [%d/%d] ---- Loss : %0.3f --- Time : %0.3f \\n'\n",
    "            % (e+1, EPOCHS, i, len(train_loader), loss, end-start))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EPOCH : [1/50] ---- Iter : [0/58610] ---- Loss : 5.297 --- Time : 2.850\n",
      "EPOCH : [1/50] ---- Iter : [10000/58610] ---- Loss : 0.662 --- Time : 3.907\n",
      "EPOCH : [1/50] ---- Iter : [20000/58610] ---- Loss : 0.328 --- Time : 3.640\n",
      "EPOCH : [1/50] ---- Iter : [30000/58610] ---- Loss : 0.783 --- Time : 3.610\n",
      "EPOCH : [1/50] ---- Iter : [40000/58610] ---- Loss : 1.070 --- Time : 3.140\n",
      "EPOCH : [1/50] ---- Iter : [50000/58610] ---- Loss : 0.579 --- Time : 3.410\n",
      "EPOCH : [1/50] ---- Iter : [58609/58610] ---- Loss : 1.786 --- Time : 0.305 \n",
      "\n",
      "EPOCH : [2/50] ---- Iter : [0/58610] ---- Loss : 0.727 --- Time : 2.220\n",
      "EPOCH : [2/50] ---- Iter : [10000/58610] ---- Loss : 1.179 --- Time : 3.300\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-52810271dbef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtrain_loss_per_iter_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, features, targets)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mobjectness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_bbox_deltas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0mnum_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, image_list, feature_maps)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0m\u001b[0;32m    147\u001b[0m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0m\u001b[0;32m    147\u001b[0m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "plt.plot(train_loss_per_iter_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c1b4758550>]"
      ]
     },
     "metadata": {},
     "execution_count": 55
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k:v.to(device) for k,v in t.items()} for t in targets]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2476"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[ 13.9173, 169.2791, 152.0880, 264.3464],\n",
       "          [290.5632, 220.2540, 365.9714, 319.8913],\n",
       "          [375.6467, 219.5141, 436.9750, 317.3343],\n",
       "          [167.7168, 234.5339, 185.1007, 266.8392],\n",
       "          [242.9561, 199.1936, 252.6799, 212.1202],\n",
       "          [422.9874, 156.7433, 464.5556, 292.0966],\n",
       "          [231.2694, 173.1474, 265.0164, 213.6947],\n",
       "          [549.3356, 299.4295, 584.4786, 398.7417],\n",
       "          [364.9716, 237.8581, 387.6946, 318.6771],\n",
       "          [ 44.5235, 212.8998,  62.0872, 240.2783],\n",
       "          [360.3722, 220.6347, 399.4546, 316.3260],\n",
       "          [295.7929, 212.0438, 454.9058, 318.7934],\n",
       "          [571.0668, 214.1096, 640.0000, 284.6765],\n",
       "          [441.7148, 339.4715, 640.0000, 419.6519],\n",
       "          [309.4498, 215.7685, 437.7561, 318.5243],\n",
       "          [360.7522, 215.2521, 373.7773, 229.8957],\n",
       "          [361.5108, 193.1484, 461.2982, 310.9829],\n",
       "          [412.0486, 219.8548, 438.3160, 291.9263],\n",
       "          [331.9007, 180.4617, 366.7711, 223.0104],\n",
       "          [457.8784, 158.9357, 468.0208, 168.4670],\n",
       "          [348.1795, 177.3089, 368.0567, 229.4073],\n",
       "          [397.2507, 193.8358, 447.3959, 303.9599],\n",
       "          [218.6096, 229.0474, 300.7772, 314.5127],\n",
       "          [212.7678, 167.8556, 272.7552, 213.7506],\n",
       "          [447.6295, 121.4177, 460.7825, 142.7201],\n",
       "          [383.1700, 172.0723, 407.6346, 212.3502],\n",
       "          [332.4728, 184.9810, 351.5658, 217.3104],\n",
       "          [483.2607, 169.4948, 515.3010, 282.9042],\n",
       "          [549.5540, 293.2831, 584.1675, 401.7367],\n",
       "          [438.0688, 169.5867, 532.7783, 293.0397],\n",
       "          [261.7533, 344.7587, 632.3845, 424.2533],\n",
       "          [331.3275, 238.9483, 357.8715, 315.6096],\n",
       "          [428.4551, 221.7417, 445.7173, 306.2102],\n",
       "          [472.2436, 375.5432, 640.0000, 421.5951],\n",
       "          [381.8400, 222.8833, 415.9651, 275.3961],\n",
       "          [375.9955, 162.6700, 466.5955, 299.0845],\n",
       "          [324.5291, 214.1230, 376.6518, 316.2780],\n",
       "          [313.2587, 180.3420, 379.3288, 228.2514],\n",
       "          [292.0117, 219.3471, 330.1319, 311.0919],\n",
       "          [ 12.2684, 321.7914, 640.0000, 418.9495],\n",
       "          [296.3999, 216.9514, 352.3848, 235.4340],\n",
       "          [318.1750, 219.1782, 383.6006, 317.0198],\n",
       "          [259.5706, 188.7163, 469.9082, 318.8192],\n",
       "          [427.8975, 156.7014, 450.1735, 206.9678],\n",
       "          [366.9567, 234.1231, 388.3995, 247.4679],\n",
       "          [358.8570, 212.3763, 374.9272, 230.0200],\n",
       "          [461.8820, 166.9855, 505.7375, 290.2655],\n",
       "          [334.1492, 187.3866, 342.5764, 212.3225],\n",
       "          [335.5997, 200.7006, 348.7952, 215.4359],\n",
       "          [461.9145, 397.7212, 640.0000, 423.6940],\n",
       "          [241.2133, 197.1520, 248.6592, 211.4368],\n",
       "          [ 52.5147, 215.2067,  63.2197, 239.7732],\n",
       "          [306.9021, 219.4033, 342.7892, 230.7300],\n",
       "          [290.6448, 216.0570, 375.2423, 231.6509],\n",
       "          [415.4674, 202.1102, 437.7663, 268.6593],\n",
       "          [138.4206, 278.8443, 205.0067, 298.9365],\n",
       "          [313.1198, 190.5991, 324.9963, 213.5002],\n",
       "          [295.7463, 219.6731, 403.5143, 281.1652],\n",
       "          [605.1705, 302.7597, 639.7827, 356.5833],\n",
       "          [582.8945, 220.9621, 637.2896, 275.8900],\n",
       "          [  9.4236, 222.9644, 453.5018, 353.0808],\n",
       "          [ 64.1559, 355.1690, 505.9547, 421.2896],\n",
       "          [235.0650, 184.6476, 262.9271, 213.7785],\n",
       "          [343.4378, 195.2162, 374.9530, 229.1129],\n",
       "          [358.1263, 232.3764, 379.2500, 314.5309],\n",
       "          [451.8101, 171.2726, 483.1947, 225.7145],\n",
       "          [239.2455, 217.8928, 393.6725, 322.0871],\n",
       "          [167.4582, 233.2090, 185.4600, 266.9716],\n",
       "          [361.4210, 216.4931, 373.5103, 229.8510],\n",
       "          [277.9182, 215.9596, 421.0941, 250.2192],\n",
       "          [355.1596, 224.1045, 404.6853, 316.0058],\n",
       "          [293.3750, 217.2338, 363.7049, 241.9696],\n",
       "          [341.5681, 220.5238, 450.8800, 273.3398],\n",
       "          [350.7072, 219.0967, 362.9973, 229.5640],\n",
       "          [362.7128, 238.6715, 390.4901, 315.0581],\n",
       "          [211.9619, 206.6939, 498.1362, 330.4022],\n",
       "          [209.3420, 300.3763, 257.7346, 329.2160],\n",
       "          [226.6965, 217.7975, 354.0070, 320.5602],\n",
       "          [396.9802, 201.2071, 409.0468, 216.7164],\n",
       "          [404.8773, 160.9493, 452.2536, 291.8087],\n",
       "          [407.5091, 173.1052, 506.8029, 295.5553],\n",
       "          [449.4839, 168.3659, 483.5242, 218.1742],\n",
       "          [338.3942, 218.7994, 354.0602, 228.6914],\n",
       "          [544.8417, 280.7100, 596.8281, 405.1714],\n",
       "          [469.8840, 374.3112, 632.7110, 423.6480],\n",
       "          [367.2823, 242.1028, 385.8654, 252.0880],\n",
       "          [334.4079, 187.8097, 342.3123, 211.3134],\n",
       "          [ 66.7440,  64.7994,  73.9031, 100.8239],\n",
       "          [314.8615, 192.2010, 324.3178, 213.1607],\n",
       "          [  0.0000, 317.3247, 616.5953, 423.4625],\n",
       "          [282.0108, 266.3967, 640.0000, 420.8873]], device='cuda:0'),\n",
       "  'labels': tensor([72, 62, 62, 86, 86,  1, 64, 86, 62,  1, 62, 67, 72, 67, 62, 86, 62, 62,\n",
       "          64,  1, 64, 62, 62, 64, 85,  1, 64, 82, 44, 82, 67, 62, 62, 67, 62,  1,\n",
       "          62, 64, 62, 67, 62, 67, 62,  1, 62, 64, 82, 64, 86, 67, 86,  1, 62, 67,\n",
       "          62, 84, 86, 67, 84,  1, 67, 67, 86, 64, 62, 62, 67, 47, 47, 67, 67, 67,\n",
       "          62, 86, 67, 67, 31, 62,  1,  1, 62, 67, 62, 64, 84, 62, 86,  1,  1, 65,\n",
       "          67], device='cuda:0'),\n",
       "  'scores': tensor([0.9755, 0.9603, 0.9342, 0.9162, 0.9142, 0.9021, 0.8463, 0.7611, 0.6941,\n",
       "          0.5838, 0.5476, 0.5043, 0.4934, 0.4824, 0.4740, 0.4711, 0.4662, 0.4380,\n",
       "          0.4357, 0.4188, 0.3715, 0.3654, 0.3631, 0.3388, 0.3213, 0.3091, 0.3006,\n",
       "          0.3005, 0.2681, 0.2439, 0.2260, 0.2166, 0.1965, 0.1951, 0.1902, 0.1883,\n",
       "          0.1766, 0.1681, 0.1439, 0.1379, 0.1313, 0.1289, 0.1249, 0.1245, 0.1231,\n",
       "          0.1153, 0.1149, 0.1138, 0.1102, 0.1069, 0.1051, 0.1046, 0.1041, 0.1008,\n",
       "          0.1001, 0.0936, 0.0910, 0.0890, 0.0874, 0.0872, 0.0860, 0.0824, 0.0817,\n",
       "          0.0802, 0.0802, 0.0790, 0.0735, 0.0723, 0.0717, 0.0687, 0.0685, 0.0673,\n",
       "          0.0669, 0.0669, 0.0660, 0.0648, 0.0646, 0.0641, 0.0629, 0.0600, 0.0589,\n",
       "          0.0589, 0.0586, 0.0558, 0.0552, 0.0540, 0.0538, 0.0528, 0.0524, 0.0506,\n",
       "          0.0501], device='cuda:0')},\n",
       " {'boxes': tensor([[ 18.4782,  55.2244, 586.0000, 637.3215],\n",
       "          [ 46.0828,  63.2733, 498.8417, 284.2656],\n",
       "          [ 13.0659,  76.8218, 569.6243, 627.7181],\n",
       "          [  0.0000,  51.3024, 585.0500, 640.0000],\n",
       "          [  5.9149,  94.2260, 310.0089, 609.9020],\n",
       "          [ 33.1262,  65.1524, 575.8247, 615.7454]], device='cuda:0'),\n",
       "  'labels': tensor([23, 23, 18, 21, 23, 20], device='cuda:0'),\n",
       "  'scores': tensor([0.8013, 0.1344, 0.0680, 0.0638, 0.0624, 0.0570], device='cuda:0')}]"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "testset = myCocoDetection(root=test_path, annFile=test_ann,\n",
    "                          remove_invalid_data=True,\n",
    "                          transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(testset, batch_size=TEST_BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.62s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "iter(test_loader).next()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((tensor([[[0.6667, 0.6784, 0.6863,  ..., 0.2706, 0.2667, 0.2745],\n",
       "           [0.6745, 0.6902, 0.6941,  ..., 0.2706, 0.2824, 0.2784],\n",
       "           [0.6863, 0.6941, 0.6980,  ..., 0.2745, 0.2706, 0.2784],\n",
       "           ...,\n",
       "           [0.7373, 0.7176, 0.7569,  ..., 0.7294, 0.7294, 0.7333],\n",
       "           [0.7294, 0.7333, 0.7294,  ..., 0.7765, 0.7647, 0.7294],\n",
       "           [0.7294, 0.7333, 0.7294,  ..., 0.5059, 0.4941, 0.4196]],\n",
       "  \n",
       "          [[0.5333, 0.5569, 0.5647,  ..., 0.2980, 0.2980, 0.2784],\n",
       "           [0.5529, 0.5686, 0.5725,  ..., 0.3020, 0.3137, 0.2941],\n",
       "           [0.5647, 0.5725, 0.5765,  ..., 0.3059, 0.3020, 0.2941],\n",
       "           ...,\n",
       "           [0.7412, 0.7176, 0.7333,  ..., 0.6157, 0.6157, 0.6118],\n",
       "           [0.7176, 0.7216, 0.7176,  ..., 0.5255, 0.4706, 0.3451],\n",
       "           [0.7176, 0.7216, 0.7176,  ..., 0.2353, 0.2235, 0.1608]],\n",
       "  \n",
       "          [[0.2863, 0.3020, 0.3098,  ..., 0.1647, 0.1529, 0.1451],\n",
       "           [0.3020, 0.3137, 0.3176,  ..., 0.1569, 0.1686, 0.1569],\n",
       "           [0.3098, 0.3176, 0.3137,  ..., 0.1529, 0.1569, 0.1569],\n",
       "           ...,\n",
       "           [0.6157, 0.5843, 0.6000,  ..., 0.6000, 0.6000, 0.6039],\n",
       "           [0.5961, 0.6000, 0.5961,  ..., 0.5255, 0.4863, 0.3961],\n",
       "           [0.5882, 0.5922, 0.5961,  ..., 0.2471, 0.2353, 0.1765]]]),\n",
       "  tensor([[[0.3176, 0.2431, 0.2000,  ..., 0.7020, 0.7098, 0.6824],\n",
       "           [0.4118, 0.4667, 0.2863,  ..., 0.8078, 0.7647, 0.7569],\n",
       "           [0.2157, 0.4824, 0.5647,  ..., 0.7098, 0.7020, 0.7843],\n",
       "           ...,\n",
       "           [0.3098, 0.3922, 0.4078,  ..., 0.2000, 0.1373, 0.1569],\n",
       "           [0.3725, 0.4118, 0.4078,  ..., 0.1961, 0.1725, 0.1686],\n",
       "           [0.3922, 0.3882, 0.4392,  ..., 0.1922, 0.1725, 0.1490]],\n",
       "  \n",
       "          [[0.5373, 0.4588, 0.4196,  ..., 0.7137, 0.7137, 0.7020],\n",
       "           [0.6157, 0.6392, 0.4706,  ..., 0.7608, 0.7333, 0.7373],\n",
       "           [0.4039, 0.6431, 0.7216,  ..., 0.6510, 0.6667, 0.7529],\n",
       "           ...,\n",
       "           [0.1922, 0.2784, 0.3137,  ..., 0.1098, 0.0392, 0.0588],\n",
       "           [0.2627, 0.3137, 0.3176,  ..., 0.1098, 0.0549, 0.0510],\n",
       "           [0.2980, 0.2902, 0.3412,  ..., 0.1098, 0.0824, 0.0588]],\n",
       "  \n",
       "          [[0.2431, 0.1412, 0.0627,  ..., 0.4118, 0.4471, 0.4392],\n",
       "           [0.2941, 0.3294, 0.1569,  ..., 0.4706, 0.4784, 0.4784],\n",
       "           [0.0745, 0.3451, 0.4431,  ..., 0.3804, 0.4118, 0.4980],\n",
       "           ...,\n",
       "           [0.0588, 0.1451, 0.1647,  ..., 0.0392, 0.0118, 0.0314],\n",
       "           [0.1098, 0.1569, 0.1569,  ..., 0.0275, 0.0235, 0.0196],\n",
       "           [0.1255, 0.1294, 0.1804,  ..., 0.0275, 0.0118, 0.0000]]])),\n",
       " ({'boxes': tensor([[236.9800, 142.5100, 261.6800, 212.0100],\n",
       "           [  7.0300, 167.7600, 156.3500, 262.6300],\n",
       "           [557.2100, 209.1900, 638.5600, 287.9200],\n",
       "           [358.9800, 218.0500, 414.9800, 320.8800],\n",
       "           [290.6900, 218.0000, 352.5200, 316.4800],\n",
       "           [413.2000, 223.0100, 443.3700, 304.3700],\n",
       "           [317.4000, 219.2400, 338.9800, 230.8300],\n",
       "           [412.8000, 157.6100, 465.8500, 295.6200],\n",
       "           [384.4300, 172.2100, 399.5500, 207.9500],\n",
       "           [512.2200, 205.7500, 526.9600, 221.7200],\n",
       "           [493.1000, 174.3400, 513.3900, 282.6500],\n",
       "           [604.7700, 305.8900, 619.1100, 351.6000],\n",
       "           [613.2400, 308.2400, 626.1200, 354.6800],\n",
       "           [447.7700, 121.1200, 461.7400, 143.0000],\n",
       "           [549.0600, 309.4300, 585.7400, 399.1000],\n",
       "           [350.7600, 208.8400, 362.1300, 231.3900],\n",
       "           [412.2500, 219.0200, 421.8800, 231.5400],\n",
       "           [241.2400, 194.9900, 255.4600, 212.6200],\n",
       "           [336.7900, 199.5000, 346.5200, 216.2300],\n",
       "           [321.2100, 231.2200, 446.7700, 320.1500]]),\n",
       "   'labels': tensor([64, 72, 72, 62, 62, 62, 62,  1,  1, 78, 82, 84, 84, 85, 86, 86, 62, 86,\n",
       "           86, 67])},\n",
       "  {'boxes': tensor([[  1.4300,  68.8100, 586.0000, 632.7500]]),\n",
       "   'labels': tensor([23])}),\n",
       " (139, 285))"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "images, targets, idx = iter(test_loader).next()\n",
    "images = [img.to(device) for img in images]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "idx"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(139, 285)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, (images, targets) in enumerate(test_loader):\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}