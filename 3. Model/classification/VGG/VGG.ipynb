{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d89010e",
   "metadata": {},
   "source": [
    "# VGG 모델 만들기\n",
    "- 모델의 구조를 보면 MaxPool를 기준으로 block단위로 나눠져있음\n",
    "- block형태를 활용해서 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb8785",
   "metadata": {},
   "source": [
    "![VGG](vgg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27f4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050d91b",
   "metadata": {},
   "source": [
    "# 단순한 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28789978",
   "metadata": {},
   "source": [
    "### 1 block 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c81c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_block(\n",
    "    in_channel=3,\n",
    "    out_channel=64,\n",
    "    num_cnn=3\n",
    "):\n",
    "    layers = []\n",
    "    for n in range(num_cnn):\n",
    "        layers.append(nn.Conv2d(in_channel, out_channel, 3, padding=1))\n",
    "        in_channel = out_channel\n",
    "    \n",
    "    layers.append(nn.MaxPool2d(2))\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a3bd8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = build_feature_block()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd95983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 16, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.rand(1,3,32,32)\n",
    "model = nn.Sequential(*features)\n",
    "output = model(img)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f2ba6d",
   "metadata": {},
   "source": [
    "### VGG-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f4618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg11(\n",
    "    in_channel=3,\n",
    "    num_cnn_list=[1,1,2,2,2],\n",
    "    channel_list=[64,128,256,512,512],\n",
    "    num_classes=10\n",
    "):\n",
    "    features = []\n",
    "    for num_cnn, channel in zip(num_cnn_list, channel_list):\n",
    "        \n",
    "        features += build_feature_block(\n",
    "            in_channel=in_channel,\n",
    "            out_channel=channel,\n",
    "            num_cnn=num_cnn)\n",
    "        \n",
    "        in_channel = channel\n",
    "    \n",
    "    flatten = [nn.Flatten()]\n",
    "    \n",
    "    classifier = []\n",
    "    classifier += [nn.Linear(512*7*7, 4096)]\n",
    "    classifier += [nn.Linear(4096, 4096)]\n",
    "    classifier += [nn.Linear(4096, 1000)]\n",
    "    \n",
    "    layers = features + flatten + classifier\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bc50c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  (14): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (15): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (16): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vgg11()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef49c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "         MaxPool2d-2         [-1, 64, 112, 112]               0\n",
      "            Conv2d-3        [-1, 128, 112, 112]          73,856\n",
      "         MaxPool2d-4          [-1, 128, 56, 56]               0\n",
      "            Conv2d-5          [-1, 256, 56, 56]         295,168\n",
      "            Conv2d-6          [-1, 256, 56, 56]         590,080\n",
      "         MaxPool2d-7          [-1, 256, 28, 28]               0\n",
      "            Conv2d-8          [-1, 512, 28, 28]       1,180,160\n",
      "            Conv2d-9          [-1, 512, 28, 28]       2,359,808\n",
      "        MaxPool2d-10          [-1, 512, 14, 14]               0\n",
      "           Conv2d-11          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-12          [-1, 512, 14, 14]       2,359,808\n",
      "        MaxPool2d-13            [-1, 512, 7, 7]               0\n",
      "          Flatten-14                [-1, 25088]               0\n",
      "           Linear-15                 [-1, 4096]     102,764,544\n",
      "           Linear-16                 [-1, 4096]      16,781,312\n",
      "           Linear-17                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 132,863,336\n",
      "Trainable params: 132,863,336\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 68.59\n",
      "Params size (MB): 506.83\n",
      "Estimated Total Size (MB): 576.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2361ee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.rand(1,3,224,224)\n",
    "output = model(img.cuda())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e185f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_block(\n",
    "    in_channel=3,\n",
    "    out_channel=64,\n",
    "    num_cnn=3\n",
    "):\n",
    "    layers = []\n",
    "    for n in range(num_cnn):\n",
    "        layers.append(nn.Conv2d(in_channel, out_channel, 3, padding=1))\n",
    "        in_channel = out_channel\n",
    "    \n",
    "    layers.append(nn.MaxPool2d(2))\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ff2bd",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23ea4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cnn_list = [2,2,3,3,3]\n",
    "num_channel_list = [64, 128, 256, 512, 512]\n",
    "\n",
    "def vgg16(\n",
    "    in_channel=3,\n",
    "    num_cnn_list=[2,2,3,3,3],\n",
    "    num_channel_list=[64,128,256,512,512],\n",
    "    classes=10\n",
    "):\n",
    "    features = []\n",
    "    for num_cnn, channel in zip(num_cnn_list, num_channel_list):\n",
    "        \n",
    "        features += build_feature_block(\n",
    "            in_channel=in_channel,\n",
    "            out_channel=channel,\n",
    "            num_cnn=num_cnn\n",
    "        )\n",
    "        \n",
    "        in_channel = channel\n",
    "        \n",
    "    flatten = [nn.Flatten()]\n",
    "    \n",
    "    classifier = []\n",
    "    classifier += [nn.Linear(512*7*7, 4096)]\n",
    "    classifier += [nn.Linear(4096, 4096)]\n",
    "    classifier += [nn.Linear(4096, classes)]\n",
    "    \n",
    "    layers = features + flatten + classifier\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e11058f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (18): Flatten(start_dim=1, end_dim=-1)\n",
       "  (19): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (20): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (21): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_16 = vgg16(classes=1000)\n",
    "vgg_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c7314d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "            Conv2d-2         [-1, 64, 224, 224]          36,928\n",
      "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
      "            Conv2d-5        [-1, 128, 112, 112]         147,584\n",
      "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
      "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
      "            Conv2d-8          [-1, 256, 56, 56]         590,080\n",
      "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
      "        MaxPool2d-10          [-1, 256, 28, 28]               0\n",
      "           Conv2d-11          [-1, 512, 28, 28]       1,180,160\n",
      "           Conv2d-12          [-1, 512, 28, 28]       2,359,808\n",
      "           Conv2d-13          [-1, 512, 28, 28]       2,359,808\n",
      "        MaxPool2d-14          [-1, 512, 14, 14]               0\n",
      "           Conv2d-15          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-16          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
      "        MaxPool2d-18            [-1, 512, 7, 7]               0\n",
      "          Flatten-19                [-1, 25088]               0\n",
      "           Linear-20                 [-1, 4096]     102,764,544\n",
      "           Linear-21                 [-1, 4096]      16,781,312\n",
      "           Linear-22                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 115.30\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 643.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vgg_16.cuda(), (3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e8d615",
   "metadata": {},
   "source": [
    "![VGG](vgg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ebffe",
   "metadata": {},
   "source": [
    "# 파이써닉 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c3a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "747378dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, num_classes, batch_norm=False):\n",
    "        super(VGG, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.batch_norm = batch_norm\n",
    "        \n",
    "        self.features = self.create_conv_layers(VGG16)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def create_conv_layers(self, config):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "        batch_norm = self.batch_norm\n",
    "        \n",
    "        for out_channels in config:\n",
    "            # convolution\n",
    "            if type(out_channels) == int:\n",
    "                conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "                \n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                \n",
    "                in_channels = out_channels\n",
    "                \n",
    "            # maxpooling\n",
    "            else:\n",
    "                layers += [nn.MaxPool2d(2)]\n",
    "    \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4e9249c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16 = VGG(in_channels=3, num_classes=1000)\n",
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab5e80d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 244, 244]           1,792\n",
      "              ReLU-2         [-1, 64, 244, 244]               0\n",
      "            Conv2d-3         [-1, 64, 244, 244]          36,928\n",
      "              ReLU-4         [-1, 64, 244, 244]               0\n",
      "         MaxPool2d-5         [-1, 64, 122, 122]               0\n",
      "            Conv2d-6        [-1, 128, 122, 122]          73,856\n",
      "              ReLU-7        [-1, 128, 122, 122]               0\n",
      "            Conv2d-8        [-1, 128, 122, 122]         147,584\n",
      "              ReLU-9        [-1, 128, 122, 122]               0\n",
      "        MaxPool2d-10          [-1, 128, 61, 61]               0\n",
      "           Conv2d-11          [-1, 256, 61, 61]         295,168\n",
      "             ReLU-12          [-1, 256, 61, 61]               0\n",
      "           Conv2d-13          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-14          [-1, 256, 61, 61]               0\n",
      "           Conv2d-15          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-16          [-1, 256, 61, 61]               0\n",
      "        MaxPool2d-17          [-1, 256, 30, 30]               0\n",
      "           Conv2d-18          [-1, 512, 30, 30]       1,180,160\n",
      "             ReLU-19          [-1, 512, 30, 30]               0\n",
      "           Conv2d-20          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-21          [-1, 512, 30, 30]               0\n",
      "           Conv2d-22          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-23          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-24          [-1, 512, 15, 15]               0\n",
      "           Conv2d-25          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-26          [-1, 512, 15, 15]               0\n",
      "           Conv2d-27          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-28          [-1, 512, 15, 15]               0\n",
      "           Conv2d-29          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-30          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "           Linear-32                 [-1, 4096]     102,764,544\n",
      "             ReLU-33                 [-1, 4096]               0\n",
      "           Linear-34                 [-1, 4096]      16,781,312\n",
      "             ReLU-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 258.26\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 786.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(vgg16.cuda(), (3, 244, 244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6762559d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.rand(1,3,224,224)\n",
    "output = vgg16(img.cuda())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ddebdd",
   "metadata": {},
   "source": [
    "# 정리\n",
    "- 함수를 이용한 방법과 Class를 이용한 방법\n",
    "- 파이써닉하게 설계하기 위해서는 Class 방법을 선호\n",
    "- Adaptive pooling layer를 추가해서 모든 input size에 대해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb4d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
