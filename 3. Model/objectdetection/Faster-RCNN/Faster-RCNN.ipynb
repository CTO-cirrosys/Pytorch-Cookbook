{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28237516",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3d8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchinfo import summary\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from dataset import MyCocoDetection, MyCocoLimit, coco_show\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905abfe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.96s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=3.35s)\n",
      "creating index...\n",
      "index created!\n",
      "2692\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(width=512, height=512),\n",
    "#     A.Rotate(limit=40,p=0.9),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=[]))\n",
    "\n",
    "train_path = r'C:\\Users\\gjust\\Documents\\Github\\data\\COCO\\train2017'\n",
    "train_ann = r'C:\\Users\\gjust\\Documents\\Github\\data\\COCO\\annotations\\instances_train2017.json'\n",
    "test_path = r'C:\\Users\\gjust\\Documents\\Github\\data\\COCO\\val2017'\n",
    "test_ann = r'C:\\Users\\gjust\\Documents\\Github\\data\\COCO\\annotations\\instances_val2017.json'\n",
    "class_list = ['person']\n",
    "\n",
    "trainset = MyCocoLimit(root=train_path, annFile=train_ann, class_list=class_list, transform=transform)\n",
    "testset = MyCocoLimit(root=test_path, annFile=test_ann, class_list=class_list, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(testset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e85394",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad623de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected x_max for bbox (0.534265625, 0.7004374999999999, 1.2842656250000002, 1.5873958333333333) to be in the range [0.0, 1.0], got 1.2842656250000002.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22332/3049810982.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcoco_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\3. Model\\objectdetection\\Faster-RCNN\\utils\\dataset.py\u001b[0m in \u001b[0;36mcoco_show\u001b[1;34m(dataset, shape, figsize)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mimage_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minv_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\3. Model\\objectdetection\\Faster-RCNN\\utils\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0maugmentations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\core\\utils.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"to\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"to\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\core\\utils.py\u001b[0m in \u001b[0;36mcheck_and_convert\u001b[1;34m(self, data, rows, cols, direction)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"to\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_from_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mconvert_to_albumentations\u001b[1;34m(self, data, rows, cols)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_bboxes_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mconvert_bboxes_to_albumentations\u001b[1;34m(bboxes, source_format, rows, cols, check_validity)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_bboxes_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;34m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconvert_bbox_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_bboxes_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;34m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconvert_bbox_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mconvert_bbox_to_albumentations\u001b[1;34m(bbox, source_format, rows, cols, check_validity)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_bbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mcheck_bbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mcheck_bbox\u001b[1;34m(bbox)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x_min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x_max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_max\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    332\u001b[0m                 \u001b[1;34m\"Expected {name} for bbox {bbox} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m                 \u001b[1;34m\"to be in the range [0.0, 1.0], got {value}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected x_max for bbox (0.534265625, 0.7004374999999999, 1.2842656250000002, 1.5873958333333333) to be in the range [0.0, 1.0], got 1.2842656250000002."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAJDCAYAAAA8QNGHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsgElEQVR4nO3dYYhld33/8ffHbFNpGrWYESS7ayL/TeNWC6ZDahFqimnZpLD7wFZ2QVpLcNEaKSiFFEsa4iNbakHY1i5UooLG1QdlwJWU2khA3JgJ0ehuiIyrbTZKEzX6JMQY+v0/uDfmnnHnztnd85t7Jvt+wcA99/72/r7cnQ985syZe1NVSJIkqY2XLHoASZKkFzPLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDW0adlK8vEkTyT51gaPJ8lHk6wleTjJdcOPKY2HmZC6zIQ0X58zW3cB++Y8fhOwZ/p1GPiXCx9LGrW7MBPSrLswE9KGNi1bVXUf8OM5Sw4An6yJE8Arkrx6qAGlsTETUpeZkOYb4pqtK4HHZo7PTO+TLlZmQuoyE7qo7djKzZIcZnIKmcsuu+x3rr322q3cXtrQgw8++MOqWtrqfc2ExspMSF0XkokhytbjwK6Z453T+35JVR0FjgIsLy/X6urqANtLFy7Jfw/4dGZC256ZkLouJBND/BpxBfiz6V+bvAn4aVX9YIDnlbYrMyF1mQld1DY9s5XkM8ANwBVJzgB/B/wKQFV9DDgO3AysAU8Df9FqWGkMzITUZSak+TYtW1V1aJPHC3jvYBNJI2cmpC4zIc3nO8hLkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkN9SpbSfYleTTJWpLbzvL47iT3JnkoycNJbh5+VGk8zITUZSakjW1atpJcAhwBbgL2AoeS7F237G+BY1X1RuAg8M9DDyqNhZmQusyENF+fM1vXA2tVdbqqngXuBg6sW1PAy6a3Xw58f7gRpdExE1KXmZDm2NFjzZXAYzPHZ4DfXbfmDuA/krwPuAy4cZDppHEyE1KXmZDmGOoC+UPAXVW1E7gZ+FSSX3ruJIeTrCZZffLJJwfaWholMyF1mQldtPqUrceBXTPHO6f3zboFOAZQVV8FXgpcsf6JqupoVS1X1fLS0tL5TSwtnpmQusyENEefsvUAsCfJ1UkuZXJh48q6Nf8DvBUgyeuYhMgfSfRiZSakLjMhzbFp2aqq54BbgXuAR5j8NcnJJHcm2T9d9gHgXUm+AXwGeGdVVauhpUUyE1KXmZDm63OBPFV1HDi+7r7bZ26fAt487GjSeJkJqctMSBvzHeQlSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGepWtJPuSPJpkLcltG6x5e5JTSU4m+fSwY0rjYiakLjMhbWzHZguSXAIcAf4QOAM8kGSlqk7NrNkD/A3w5qp6KsmrWg0sLZqZkLrMhDRfnzNb1wNrVXW6qp4F7gYOrFvzLuBIVT0FUFVPDDumNCpmQuoyE9IcfcrWlcBjM8dnpvfNuga4JslXkpxIsm+oAaURMhNSl5mQ5tj014jn8Dx7gBuAncB9Sd5QVT+ZXZTkMHAYYPfu3QNtLY2SmZC6zIQuWn3ObD0O7Jo53jm9b9YZYKWqfl5V3wW+zSRUHVV1tKqWq2p5aWnpfGeWFs1MSF1mQpqjT9l6ANiT5OoklwIHgZV1a/6dyU8rJLmCyeni08ONKY2KmZC6zIQ0x6Zlq6qeA24F7gEeAY5V1ckkdybZP112D/CjJKeAe4G/rqoftRpaWiQzIXWZCWm+VNVCNl5eXq7V1dWF7C2tl+TBqlpe5AxmQmNiJqSuC8mE7yAvSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ11KtsJdmX5NEka0lum7PubUkqyfJwI0rjYyakLjMhbWzTspXkEuAIcBOwFziUZO9Z1l0O/BVw/9BDSmNiJqQuMyHN1+fM1vXAWlWdrqpngbuBA2dZ9yHgw8AzA84njZGZkLrMhDRHn7J1JfDYzPGZ6X2/kOQ6YFdVfWHA2aSxMhNSl5mQ5rjgC+STvAT4CPCBHmsPJ1lNsvrkk09e6NbSKJkJqctM6GLXp2w9DuyaOd45ve95lwOvB76c5HvAm4CVs138WFVHq2q5qpaXlpbOf2ppscyE1GUmpDn6lK0HgD1Jrk5yKXAQWHn+war6aVVdUVVXVdVVwAlgf1WtNplYWjwzIXWZCWmOTctWVT0H3ArcAzwCHKuqk0nuTLK/9YDS2JgJqctMSPPt6LOoqo4Dx9fdd/sGa2+48LGkcTMTUpeZkDbmO8hLkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkN9SpbSfYleTTJWpLbzvL4+5OcSvJwki8lec3wo0rjYSakLjMhbWzTspXkEuAIcBOwFziUZO+6ZQ8By1X128Dngb8felBpLMyE1GUmpPn6nNm6HlirqtNV9SxwN3BgdkFV3VtVT08PTwA7hx1TGhUzIXWZCWmOPmXrSuCxmeMz0/s2cgvwxQsZSho5MyF1mQlpjh1DPlmSdwDLwFs2ePwwcBhg9+7dQ24tjZKZkLrMhC5Gfc5sPQ7smjneOb2vI8mNwAeB/VX1s7M9UVUdrarlqlpeWlo6n3mlMTATUpeZkOboU7YeAPYkuTrJpcBBYGV2QZI3Av/KJEBPDD+mNCpmQuoyE9Icm5atqnoOuBW4B3gEOFZVJ5PcmWT/dNk/AL8OfC7J15OsbPB00rZnJqQuMyHN1+uarao6Dhxfd9/tM7dvHHguadTMhNRlJqSN+Q7ykiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ73KVpJ9SR5NspbktrM8/qtJPjt9/P4kVw0+qTQiZkLqMhPSxjYtW0kuAY4ANwF7gUNJ9q5bdgvwVFX9P+CfgA8PPag0FmZC6jIT0nx9zmxdD6xV1emqeha4Gziwbs0B4BPT258H3pokw40pjYqZkLrMhDRHn7J1JfDYzPGZ6X1nXVNVzwE/BV45xIDSCJkJqctMSHPs2MrNkhwGDk8Pf5bkW1u5/1lcAfzQGRY+w6L3B/jNRWxqJkY5w6L3H8sMZmJiDP8Xi55h0fuPZYbzzkSfsvU4sGvmeOf0vrOtOZNkB/By4Efrn6iqjgJHAZKsVtXy+Qw9FGcYxwyL3v/5Gc5huZl4Ec+w6P3HNMM5LDcTL+IZFr3/mGY433/b59eIDwB7klyd5FLgILCybs0K8OfT238C/FdV1fkOJY2cmZC6zIQ0x6ZntqrquSS3AvcAlwAfr6qTSe4EVqtqBfg34FNJ1oAfMwma9KJkJqQuMyHN1+uarao6Dhxfd9/tM7efAf70HPc+eo7rW3CGiUXPsOj94RxnMBNNLXqGRe8P23AGM9HUomdY9P6wzWeIZ3ElSZLa8eN6JEmSGmpetsbwEQ49Znh/klNJHk7ypSSv2cr9Z9a9LUklGfwvLvrMkOTt09fhZJJPb/UMSXYnuTfJQ9P/i5sH3v/jSZ7Y6E/JM/HR6XwPJ7luyP1n9jETZqLXDGbiF483zcSi89Bnhpl1ZmI7ZqKqmn0xuVDyO8BrgUuBbwB71635S+Bj09sHgc8uYIY/AH5tevs9Q87QZ//pusuB+4ATwPICXoM9wEPAb0yPX7WAGY4C75ne3gt8b+AZfh+4DvjWBo/fDHwRCPAm4P4h9z+H18FMlJmYrjET1TYTi85D3xmm68zENs1E6zNbY/gIh01nqKp7q+rp6eEJJu8Rs2X7T32IyWeFPTPg3ucyw7uAI1X1FEBVPbGAGQp42fT2y4HvDzlAVd3H5K+gNnIA+GRNnABekeTVQ86Amei1/5SZMBOzc7TKxKLz0GuGKTOxTTPRumyN4SMc+sww6xYmrXXL9p+ehtxVVV8YcN9zmgG4BrgmyVeSnEiybwEz3AG8I8kZJn/V9L6BZ9jMuX6vtNrDTJiJ592BmeisaZCJReeh1wxm4hfuYBtmYks/rmfskrwDWAbesoV7vgT4CPDOrdpzAzuYnCK+gclPbfcleUNV/WQLZzgE3FVV/5jk95i8J8/rq+r/tnAGzTATZkIvWEQepvuaiRdsy0y0PrN1Lh/hQOZ8hEPjGUhyI/BBYH9V/WwL978ceD3w5STfY/I74JWBL37s8xqcAVaq6udV9V3g20xCtZUz3AIcA6iqrwIvZfJ5WFul1/fKFuxhJszE88zEujUNMrHoPPSZwUy8YHtmYsgLy85yIdkO4DRwNS9c7PZb69a8l+6Fj8cWMMMbmVyUt2cRr8G69V9m+Asf+7wG+4BPTG9fweQ06Su3eIYvAu+c3n4dk9/FZ+DX4io2vvDxj+le+Pi1RXw/mAkzMbPGTFTbTCw6D31nWLfeTNT2ysTg3zRnGexmJu33O8AHp/fdyeSnA5i00s8Ba8DXgNcuYIb/BP4X+Pr0a2Ur91+3dvAQ9XwNwuQ09Sngm8DBBcywF/jKNGBfB/5o4P0/A/wA+DmTn9BuAd4NvHvmNTgyne+bLf4fer4OZqK71kyYiaaZWHQe+sywbq2Z2GaZ8B3kJUmSGvId5CVJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLU0KZlK8nHkzyR5FsbPJ4kH02yluThJNcNP6Y0HmZC6jIT0nx9zmzdBeyb8/hNwJ7p12HgXy58LGnU7sJMSLPuwkxIG9q0bFXVfcCP5yw5AHyyJk4Ar0jy6qEGlMbGTEhdZkKab4hrtq4EHps5PjO9T7pYmQmpy0zoorZjKzdLcpjJKWQuu+yy37n22mu3cntpQw8++OAPq2ppq/c1ExorMyF1XUgmhihbjwO7Zo53Tu/7JVV1FDgKsLy8XKurqwNsL124JP894NOZCW17ZkLqupBMDPFrxBXgz6Z/bfIm4KdV9YMBnlfarsyE1GUmdFHb9MxWks8ANwBXJDkD/B3wKwBV9THgOHAzsAY8DfxFq2GlMTATUpeZkObbtGxV1aFNHi/gvYNNJI2cmZC6zIQ0n+8gL0mS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNdSrbCXZl+TRJGtJbjvL47uT3JvkoSQPJ7l5+FGl8TATUpeZkDa2adlKcglwBLgJ2AscSrJ33bK/BY5V1RuBg8A/Dz2oNBZmQuoyE9J8fc5sXQ+sVdXpqnoWuBs4sG5NAS+b3n458P3hRpRGx0xIXWZCmmNHjzVXAo/NHJ8BfnfdmjuA/0jyPuAy4MZBppPGyUxIXWZCmmOoC+QPAXdV1U7gZuBTSX7puZMcTrKaZPXJJ58caGtplMyE1GUmdNHqU7YeB3bNHO+c3jfrFuAYQFV9FXgpcMX6J6qqo1W1XFXLS0tL5zextHhmQuoyE9IcfcrWA8CeJFcnuZTJhY0r69b8D/BWgCSvYxIifyTRi5WZkLrMhDTHpmWrqp4DbgXuAR5h8tckJ5PcmWT/dNkHgHcl+QbwGeCdVVWthpYWyUxIXWZCmq/PBfJU1XHg+Lr7bp+5fQp487CjSeNlJqQuMyFtzHeQlyRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGupVtpLsS/JokrUkt22w5u1JTiU5meTTw44pjYuZkLrMhLSxHZstSHIJcAT4Q+AM8ECSlao6NbNmD/A3wJur6qkkr2o1sLRoZkLqMhPSfH3ObF0PrFXV6ap6FrgbOLBuzbuAI1X1FEBVPTHsmNKomAmpy0xIc/QpW1cCj80cn5neN+sa4JokX0lyIsm+oQaURshMSF1mQppj018jnsPz7AFuAHYC9yV5Q1X9ZHZRksPAYYDdu3cPtLU0SmZC6jITumj1ObP1OLBr5njn9L5ZZ4CVqvp5VX0X+DaTUHVU1dGqWq6q5aWlpfOdWVo0MyF1mQlpjj5l6wFgT5Krk1wKHARW1q35dyY/rZDkCiani08PN6Y0KmZC6jIT0hyblq2qeg64FbgHeAQ4VlUnk9yZZP902T3Aj5KcAu4F/rqqftRqaGmRzITUZSak+VJVC9l4eXm5VldXF7K3tF6SB6tqeZEzmAmNiZmQui4kE76DvCRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1FCvspVkX5JHk6wluW3OurclqSTLw40ojY+ZkLrMhLSxTctWkkuAI8BNwF7gUJK9Z1l3OfBXwP1DDymNiZmQusyENF+fM1vXA2tVdbqqngXuBg6cZd2HgA8Dzww4nzRGZkLqMhPSHH3K1pXAYzPHZ6b3/UKS64BdVfWFAWeTxspMSF1mQprjgi+QT/IS4CPAB3qsPZxkNcnqk08+eaFbS6NkJqQuM6GLXZ+y9Tiwa+Z45/S+510OvB74cpLvAW8CVs528WNVHa2q5apaXlpaOv+ppcUyE1KXmZDm6FO2HgD2JLk6yaXAQWDl+Qer6qdVdUVVXVVVVwEngP1VtdpkYmnxzITUZSakOTYtW1X1HHArcA/wCHCsqk4muTPJ/tYDSmNjJqQuMyHNt6PPoqo6Dhxfd9/tG6y94cLHksbNTEhdZkLamO8gL0mS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNdSrbCXZl+TRJGtJbjvL4+9PcirJw0m+lOQ1w48qjYeZkLrMhLSxTctWkkuAI8BNwF7gUJK965Y9BCxX1W8Dnwf+fuhBpbEwE1KXmZDm63Nm63pgrapOV9WzwN3AgdkFVXVvVT09PTwB7Bx2TGlUzITUZSakOfqUrSuBx2aOz0zv28gtwBcvZChp5MyE1GUmpDl2DPlkSd4BLANv2eDxw8BhgN27dw+5tTRKZkLqMhO6GPU5s/U4sGvmeOf0vo4kNwIfBPZX1c/O9kRVdbSqlqtqeWlp6XzmlcbATEhdZkKao0/ZegDYk+TqJJcCB4GV2QVJ3gj8K5MAPTH8mNKomAmpy0xIc2xatqrqOeBW4B7gEeBYVZ1McmeS/dNl/wD8OvC5JF9PsrLB00nbnpmQusyENF+va7aq6jhwfN19t8/cvnHguaRRMxNSl5mQNuY7yEuSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ31KltJ9iV5NMlaktvO8vivJvns9PH7k1w1+KTSiJgJqctMSBvbtGwluQQ4AtwE7AUOJdm7btktwFNV9f+AfwI+PPSg0liYCanLTEjz9TmzdT2wVlWnq+pZ4G7gwLo1B4BPTG9/Hnhrkgw3pjQqZkLqMhPSHH3K1pXAYzPHZ6b3nXVNVT0H/BR45RADSiNkJqQuMyHNsWMrN0tyGDg8PfxZkm9t5f5ncQXwQ2dY+AyL3h/gNxexqZkY5QyL3n8sM5iJiTH8Xyx6hkXvP5YZzjsTfcrW48CumeOd0/vOtuZMkh3Ay4EfrX+iqjoKHAVIslpVy+cz9FCcYRwzLHr/52c4h+Vm4kU8w6L3H9MM57DcTLyIZ1j0/mOa4Xz/bZ9fIz4A7ElydZJLgYPAyro1K8CfT2//CfBfVVXnO5Q0cmZC6jIT0hybntmqqueS3ArcA1wCfLyqTia5E1itqhXg34BPJVkDfswkaNKLkpmQusyENF+va7aq6jhwfN19t8/cfgb403Pc++g5rm/BGSYWPcOi94dznMFMNLXoGRa9P2zDGcxEU4ueYdH7wzafIZ7FlSRJaseP65EkSWqoedkaw0c49Jjh/UlOJXk4yZeSvGYr959Z97YklWTwv7joM0OSt09fh5NJPr3VMyTZneTeJA9N/y9uHnj/jyd5YqM/Jc/ER6fzPZzkuiH3n9nHTJiJXjOYiV883jQTi85Dnxlm1pmJ7ZiJqmr2xeRCye8ArwUuBb4B7F235i+Bj01vHwQ+u4AZ/gD4tent9ww5Q5/9p+suB+4DTgDLC3gN9gAPAb8xPX7VAmY4Crxnensv8L2BZ/h94DrgWxs8fjPwRSDAm4D7h9z/HF4HM1FmYrrGTFTbTCw6D31nmK4zE9s0E63PbI3hIxw2naGq7q2qp6eHJ5i8R8yW7T/1ISafFfbMgHufywzvAo5U1VMAVfXEAmYo4GXT2y8Hvj/kAFV1H5O/gtrIAeCTNXECeEWSVw85A2ai1/5TZsJMzM7RKhOLzkOvGabMxDbNROuyNYaPcOgzw6xbmLTWLdt/ehpyV1V9YcB9z2kG4BrgmiRfSXIiyb4FzHAH8I4kZ5j8VdP7Bp5hM+f6vdJqDzNhJp53B2ais6ZBJhadh14zmIlfuINtmIkt/biesUvyDmAZeMsW7vkS4CPAO7dqzw3sYHKK+AYmP7Xdl+QNVfWTLZzhEHBXVf1jkt9j8p48r6+q/9vCGTTDTJgJvWAReZjuayZesC0z0frM1rl8hAOZ8xEOjWcgyY3AB4H9VfWzLdz/cuD1wJeTfI/J74BXBr74sc9rcAZYqaqfV9V3gW8zCdVWznALcAygqr4KvJTJ52FtlV7fK1uwh5kwE88zE+vWNMjEovPQZwYz8YLtmYkhLyw7y4VkO4DTwNW8cLHbb61b8166Fz4eW8AMb2RyUd6eRbwG69Z/meEvfOzzGuwDPjG9fQWT06Sv3OIZvgi8c3r7dUx+F5+BX4ur2PjCxz+me+Hj1xbx/WAmzMTMGjNRbTOx6Dz0nWHdejNR2ysTg3/TnGWwm5m03+8AH5zedyeTnw5g0ko/B6wBXwNeu4AZ/hP4X+Dr06+Vrdx/3drBQ9TzNQiT09SngG8CBxcww17gK9OAfR34o4H3/wzwA+DnTH5CuwV4N/DumdfgyHS+b7b4f+j5OpiJ7lozYSaaZmLReegzw7q1ZmKbZcJ3kJckSWrId5CXJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOblq0kH0/yRJJvbfB4knw0yVqSh5NcN/yY0niYCanLTEjz9TmzdRewb87jNwF7pl+HgX+58LGkUbsLMyHNugszIW1o07JVVfcBP56z5ADwyZo4AbwiyauHGlAaGzMhdZkJab4hrtm6Enhs5vjM9D7pYmUmpC4zoYvajq3cLMlhJqeQueyyy37n2muv3crtpQ09+OCDP6yqpa3e10xorMyE1HUhmRiibD0O7Jo53jm975dU1VHgKMDy8nKtrq4OsL104ZL894BPZya07ZkJqetCMjHErxFXgD+b/rXJm4CfVtUPBnheabsyE1KXmdBFbdMzW0k+A9wAXJHkDPB3wK8AVNXHgOPAzcAa8DTwF62GlcbATEhdZkKab9OyVVWHNnm8gPcONpE0cmZC6jIT0ny+g7wkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktRQr7KVZF+SR5OsJbntLI/vTnJvkoeSPJzk5uFHlcbDTEhdZkLa2KZlK8klwBHgJmAvcCjJ3nXL/hY4VlVvBA4C/zz0oNJYmAmpy0xI8/U5s3U9sFZVp6vqWeBu4MC6NQW8bHr75cD3hxtRGh0zIXWZCWmOHT3WXAk8NnN8BvjddWvuAP4jyfuAy4AbB5lOGiczIXWZCWmOoS6QPwTcVVU7gZuBTyX5pedOcjjJapLVJ598cqCtpVEyE1KXmdBFq0/ZehzYNXO8c3rfrFuAYwBV9VXgpcAV65+oqo5W1XJVLS8tLZ3fxNLimQmpy0xIc/QpWw8Ae5JcneRSJhc2rqxb8z/AWwGSvI5JiPyRRC9WZkLqMhPSHJuWrap6DrgVuAd4hMlfk5xMcmeS/dNlHwDeleQbwGeAd1ZVtRpaWiQzIXWZCWm+PhfIU1XHgePr7rt95vYp4M3DjiaNl5mQusyEtDHfQV6SJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWqoV9lKsi/Jo0nWkty2wZq3JzmV5GSSTw87pjQuZkLqMhPSxnZstiDJJcAR4A+BM8ADSVaq6tTMmj3A3wBvrqqnkryq1cDSopkJqctMSPP1ObN1PbBWVaer6lngbuDAujXvAo5U1VMAVfXEsGNKo2ImpC4zIc3Rp2xdCTw2c3xmet+sa4BrknwlyYkk+4YaUBohMyF1mQlpjk1/jXgOz7MHuAHYCdyX5A1V9ZPZRUkOA4cBdu/ePdDW0iiZCanLTOii1efM1uPArpnjndP7Zp0BVqrq51X1XeDbTELVUVVHq2q5qpaXlpbOd2Zp0cyE1GUmpDn6lK0HgD1Jrk5yKXAQWFm35t+Z/LRCkiuYnC4+PdyY0qiYCanLTEhzbFq2quo54FbgHuAR4FhVnUxyZ5L902X3AD9Kcgq4F/jrqvpRq6GlRTITUpeZkOZLVS1k4+Xl5VpdXV3I3tJ6SR6squVFzmAmNCZmQuq6kEz4DvKSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDvcpWkn1JHk2yluS2OevelqSSLA83ojQ+ZkLqMhPSxjYtW0kuAY4ANwF7gUNJ9p5l3eXAXwH3Dz2kNCZmQuoyE9J8fc5sXQ+sVdXpqnoWuBs4cJZ1HwI+DDwz4HzSGJkJqctMSHP0KVtXAo/NHJ+Z3vcLSa4DdlXVFwacTRorMyF1mQlpjgu+QD7JS4CPAB/osfZwktUkq08++eSFbi2NkpmQusyELnZ9ytbjwK6Z453T+553OfB64MtJvge8CVg528WPVXW0qparanlpaen8p5YWy0xIXWZCmqNP2XoA2JPk6iSXAgeBlecfrKqfVtUVVXVVVV0FnAD2V9Vqk4mlxTMTUpeZkObYtGxV1XPArcA9wCPAsao6meTOJPtbDyiNjZmQusyENN+OPouq6jhwfN19t2+w9oYLH0saNzMhdZkJaWO+g7wkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktRQr7KVZF+SR5OsJbntLI+/P8mpJA8n+VKS1ww/qjQeZkLqMhPSxjYtW0kuAY4ANwF7gUNJ9q5b9hCwXFW/DXwe+PuhB5XGwkxIXWZCmq/Pma3rgbWqOl1VzwJ3AwdmF1TVvVX19PTwBLBz2DGlUTETUpeZkOboU7auBB6bOT4zvW8jtwBfvJChpJEzE1KXmZDm2DHkkyV5B7AMvGWDxw8DhwF279495NbSKJkJqctM6GLU58zW48CumeOd0/s6ktwIfBDYX1U/O9sTVdXRqlququWlpaXzmVcaAzMhdZkJaY4+ZesBYE+Sq5NcChwEVmYXJHkj8K9MAvTE8GNKo2ImpC4zIc2xadmqqueAW4F7gEeAY1V1MsmdSfZPl/0D8OvA55J8PcnKBk8nbXtmQuoyE9J8va7ZqqrjwPF1990+c/vGgeeSRs1MSF1mQtqY7yAvSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ11KtsJdmX5NEka0luO8vjv5rks9PH709y1eCTSiNiJqQuMyFtbNOyleQS4AhwE7AXOJRk77pltwBPVdX/A/4J+PDQg0pjYSakLjMhzdfnzNb1wFpVna6qZ4G7gQPr1hwAPjG9/XngrUky3JjSqJgJqctMSHP0KVtXAo/NHJ+Z3nfWNVX1HPBT4JVDDCiNkJmQusyENMeOrdwsyWHg8PTwZ0m+tZX7n8UVwA+dYeEzLHp/gN9cxKZmYpQzLHr/scxgJibG8H+x6BkWvf9YZjjvTPQpW48Du2aOd07vO9uaM0l2AC8HfrT+iarqKHAUIMlqVS2fz9BDcYZxzLDo/Z+f4RyWm4kX8QyL3n9MM5zDcjPxIp5h0fuPaYbz/bd9fo34ALAnydVJLgUOAivr1qwAfz69/SfAf1VVne9Q0siZCanLTEhzbHpmq6qeS3IrcA9wCfDxqjqZ5E5gtapWgH8DPpVkDfgxk6BJL0pmQuoyE9J8va7ZqqrjwPF1990+c/sZ4E/Pce+j57i+BWeYWPQMi94fznEGM9HUomdY9P6wDWcwE00teoZF7w/bfIZ4FleSJKkdP65HkiSpoeZlawwf4dBjhvcnOZXk4SRfSvKardx/Zt3bklSSwf/ios8MSd4+fR1OJvn0Vs+QZHeSe5M8NP2/uHng/T+e5ImN/pQ8Ex+dzvdwkuuG3H9mHzNhJnrNYCZ+8XjTTCw6D31mmFlnJrZjJqqq2ReTCyW/A7wWuBT4BrB33Zq/BD42vX0Q+OwCZvgD4Nemt98z5Ax99p+uuxy4DzgBLC/gNdgDPAT8xvT4VQuY4SjwnuntvcD3Bp7h94HrgG9t8PjNwBeBAG8C7h9y/3N4HcxEmYnpGjNRbTOx6Dz0nWG6zkxs00y0PrM1ho9w2HSGqrq3qp6eHp5g8h4xW7b/1IeYfFbYMwPufS4zvAs4UlVPAVTVEwuYoYCXTW+/HPj+kANU1X1M/gpqIweAT9bECeAVSV495AyYiV77T5kJMzE7R6tMLDoPvWaYMhPbNBOty9YYPsKhzwyzbmHSWrds/+lpyF1V9YUB9z2nGYBrgGuSfCXJiST7FjDDHcA7kpxh8ldN7xt4hs2c6/dKqz3MhJl43h2Yic6aBplYdB56zWAmfuEOtmEmtvTjesYuyTuAZeAtW7jnS4CPAO/cqj03sIPJKeIbmPzUdl+SN1TVT7ZwhkPAXVX1j0l+j8l78ry+qv5vC2fQDDNhJvSCReRhuq+ZeMG2zETrM1vn8hEOZM5HODSegSQ3Ah8E9lfVz7Zw/8uB1wNfTvI9Jr8DXhn44sc+r8EZYKWqfl5V3wW+zSRUWznDLcAxgKr6KvBSJp+HtVV6fa9swR5mwkw8z0ysW9MgE4vOQ58ZzMQLtmcmhryw7CwXku0ATgNX88LFbr+1bs176V74eGwBM7yRyUV5exbxGqxb/2WGv/Cxz2uwD/jE9PYVTE6TvnKLZ/gi8M7p7dcx+V18Bn4trmLjCx//mO6Fj19bxPeDmTATM2vMRLXNxKLz0HeGdevNRG2vTAz+TXOWwW5m0n6/A3xwet+dTH46gEkr/RywBnwNeO0CZvhP4H+Br0+/VrZy/3VrBw9Rz9cgTE5TnwK+CRxcwAx7ga9MA/Z14I8G3v8zwA+AnzP5Ce0W4N3Au2degyPT+b7Z4v+h5+tgJrprzYSZaJqJReehzwzr1pqJbZYJ30FekiSpId9BXpIkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktTQ/wfFYYebF1+UMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coco_show(trainset, shape=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feffe08",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95396444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1def9cb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef32eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "FasterRCNN                                              --                        --\n",
       "├─BackboneWithFPN: 1                                    --                        --\n",
       "│    └─FeaturePyramidNetwork: 2                         --                        --\n",
       "│    │    └─ModuleList: 3-1                             --                        984,064\n",
       "│    │    └─ModuleList: 3-2                             --                        2,360,320\n",
       "├─GeneralizedRCNNTransform: 1-1                         --                        --\n",
       "├─BackboneWithFPN: 1-2                                  [2, 256, 13, 13]          --\n",
       "│    └─IntermediateLayerGetter: 2-1                     [2, 2048, 25, 25]         --\n",
       "│    │    └─Conv2d: 3-3                                 [2, 64, 400, 400]         (9,408)\n",
       "│    │    └─FrozenBatchNorm2d: 3-4                      [2, 64, 400, 400]         --\n",
       "│    │    └─ReLU: 3-5                                   [2, 64, 400, 400]         --\n",
       "│    │    └─MaxPool2d: 3-6                              [2, 64, 200, 200]         --\n",
       "│    │    └─Sequential: 3-7                             [2, 256, 200, 200]        (212,992)\n",
       "│    │    └─Sequential: 3-8                             [2, 512, 100, 100]        1,212,416\n",
       "│    │    └─Sequential: 3-9                             [2, 1024, 50, 50]         7,077,888\n",
       "│    │    └─Sequential: 3-10                            [2, 2048, 25, 25]         14,942,208\n",
       "│    └─FeaturePyramidNetwork: 2-2                       [2, 256, 13, 13]          --\n",
       "│    │    └─LastLevelMaxPool: 3-11                      [2, 256, 200, 200]        --\n",
       "├─RegionProposalNetwork: 1-3                            [1000, 4]                 --\n",
       "│    └─RPNHead: 2-3                                     [2, 3, 200, 200]          --\n",
       "│    │    └─Conv2d: 3-12                                [2, 256, 200, 200]        590,080\n",
       "│    │    └─Conv2d: 3-13                                [2, 3, 200, 200]          771\n",
       "│    │    └─Conv2d: 3-14                                [2, 12, 200, 200]         3,084\n",
       "│    │    └─Conv2d: 3-15                                [2, 256, 100, 100]        (recursive)\n",
       "│    │    └─Conv2d: 3-16                                [2, 3, 100, 100]          (recursive)\n",
       "│    │    └─Conv2d: 3-17                                [2, 12, 100, 100]         (recursive)\n",
       "│    │    └─Conv2d: 3-18                                [2, 256, 50, 50]          (recursive)\n",
       "│    │    └─Conv2d: 3-19                                [2, 3, 50, 50]            (recursive)\n",
       "│    │    └─Conv2d: 3-20                                [2, 12, 50, 50]           (recursive)\n",
       "│    │    └─Conv2d: 3-21                                [2, 256, 25, 25]          (recursive)\n",
       "│    │    └─Conv2d: 3-22                                [2, 3, 25, 25]            (recursive)\n",
       "│    │    └─Conv2d: 3-23                                [2, 12, 25, 25]           (recursive)\n",
       "│    │    └─Conv2d: 3-24                                [2, 256, 13, 13]          (recursive)\n",
       "│    │    └─Conv2d: 3-25                                [2, 3, 13, 13]            (recursive)\n",
       "│    │    └─Conv2d: 3-26                                [2, 12, 13, 13]           (recursive)\n",
       "│    └─AnchorGenerator: 2-4                             [159882, 4]               --\n",
       "├─RoIHeads: 1-4                                         --                        --\n",
       "│    └─MultiScaleRoIAlign: 2-5                          [2000, 256, 7, 7]         --\n",
       "│    └─TwoMLPHead: 2-6                                  [2000, 1024]              --\n",
       "│    │    └─Linear: 3-27                                [2000, 1024]              12,846,080\n",
       "│    │    └─Linear: 3-28                                [2000, 1024]              1,049,600\n",
       "│    └─FastRCNNPredictor: 2-7                           [2000, 6]                 --\n",
       "│    │    └─Linear: 3-29                                [2000, 6]                 6,150\n",
       "│    │    └─Linear: 3-30                                [2000, 24]                24,600\n",
       "=========================================================================================================\n",
       "Total params: 41,319,661\n",
       "Trainable params: 41,097,261\n",
       "Non-trainable params: 222,400\n",
       "Total mult-adds (G): 267.98\n",
       "=========================================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 2910.05\n",
       "Params size (MB): 165.28\n",
       "Estimated Total Size (MB): 3076.53\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "num_classes = len(class_list) + 1\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "summary(model, (2,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c693d95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected x_max for bbox (0.65225, 0.13258333333333333, 1.5522500000000001, 1.1191041666666666) to be in the range [0.0, 1.0], got 1.5522500000000001.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22332/337724705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\3. Model\\objectdetection\\Faster-RCNN\\utils\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0maugmentations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\core\\utils.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"to\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"to\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\core\\utils.py\u001b[0m in \u001b[0;36mcheck_and_convert\u001b[1;34m(self, data, rows, cols, direction)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"to\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_from_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mconvert_to_albumentations\u001b[1;34m(self, data, rows, cols)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_bboxes_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mconvert_bboxes_to_albumentations\u001b[1;34m(bboxes, source_format, rows, cols, check_validity)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_bboxes_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;34m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconvert_bbox_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_bboxes_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;34m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconvert_bbox_to_albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mconvert_bbox_to_albumentations\u001b[1;34m(bbox, source_format, rows, cols, check_validity)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_bbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mcheck_bbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\bbox_utils.py\u001b[0m in \u001b[0;36mcheck_bbox\u001b[1;34m(bbox)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x_min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x_max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_max\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    332\u001b[0m                 \u001b[1;34m\"Expected {name} for bbox {bbox} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m                 \u001b[1;34m\"to be in the range [0.0, 1.0], got {value}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected x_max for bbox (0.65225, 0.13258333333333333, 1.5522500000000001, 1.1191041666666666) to be in the range [0.0, 1.0], got 1.5522500000000001."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    idx, images, targets = iter(train_loader).next()\n",
    "    images = [img.to(device) for img in images]\n",
    "    targets = [{k:v.to(device) for k,v in t.items()} for t in targets]\n",
    "#     print(images)\n",
    "#     print(targets)\n",
    "    print(model(images, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b52631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco2pascal(bboxes):\n",
    "    new_bboxes = torch.zeros_like(bboxes)\n",
    "    new_bboxes[:,:2] = bboxes[:, :2]\n",
    "    new_bboxes[:, 2:] = bboxes[:, :2] + bboxes[:, 2:]\n",
    "    \n",
    "    return new_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db65d48",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57b3238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# scheduler = StepLR(optimizer, step_size=15, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08094f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244d0678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'dog', 'car', 'keyboard', 'horse']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df66b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edb0e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : [1/1] ---- Iter : [0/42881] ---- Loss : 2.576 --- Time : 3.556\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26628/212695467.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mnew_targets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtrain_loss_per_iter_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mregression_targets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m             loss_classifier, loss_box_reg = fastrcnn_loss(\n\u001b[0m\u001b[0;32m    761\u001b[0m                 class_logits, box_regression, labels, regression_targets)\n\u001b[0;32m    762\u001b[0m             losses = {\n",
      "\u001b[1;32m~\\Documents\\Github\\Pytorch-Cookbook\\pytorch\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py\u001b[0m in \u001b[0;36mfastrcnn_loss\u001b[1;34m(class_logits, box_regression, labels, regression_targets)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# the corresponding ground truth labels, to be used with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# advanced indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0msampled_pos_inds_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mlabels_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampled_pos_inds_subset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_logits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "train_loss_per_epoch_list = []\n",
    "train_loss_per_iter_list = []\n",
    "EPOCH = 1\n",
    "model.train()\n",
    "for e in range(EPOCH):\n",
    "        \n",
    "    for i, (idx, images, targets) in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        images = [img.to(device) for img in images]\n",
    "        new_targets = []\n",
    "        for t in targets:\n",
    "            t['boxes'] = coco2pascal(t['boxes'])\n",
    "            new_targets.append({k:v.to(device) for k,v in t.items()})\n",
    "        \n",
    "        loss_dict = model(images, new_targets)\n",
    "        loss = sum(v for v in loss_dict.values())\n",
    "        train_loss_per_iter_list.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        end = time.time()\n",
    "        if i % 10 == 0:\n",
    "            print('EPOCH : [%d/%d] ---- Iter : [%d/%d] ---- Loss : %0.3f --- Time : %0.3f'\n",
    "                 % (e+1, EPOCH, i, len(train_loader), loss, (end-start)*10))\n",
    "            \n",
    "    train_loss_per_epoch_list.append(loss)        \n",
    "    print('EPOCH : [%d/%d] ---- Iter : [%d/%d] ---- Loss : %0.3f --- Time : %0.3f \\n'\n",
    "            % (e+1, EPOCH, i, len(train_loader), loss, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710bba1",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46250c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1819/1819 [06:17<00:00,  4.82iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of total ground Truths bboxes : torch.Size([17912, 6])\n",
      "Shape of total predicted bboxes : torch.Size([363800, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    total_gt_bboxes = torch.tensor([])\n",
    "    total_pred_bboxes = torch.tensor([])\n",
    "    with tqdm(test_loader, unit='iter') as iters:\n",
    "        for i, (img_ids, images, targets) in enumerate(iters):\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "\n",
    "            for img_id, target, output in zip(img_ids, targets, outputs):\n",
    "                gt_bboxes = get_bbox(img_id, target)\n",
    "                pred_bboxes = get_bbox(img_id, output, pred=True)\n",
    "\n",
    "                total_gt_bboxes = torch.cat([total_gt_bboxes, gt_bboxes])\n",
    "                total_pred_bboxes = torch.cat([total_pred_bboxes, pred_bboxes])\n",
    "\n",
    "      #      print('r\\')\n",
    "        \n",
    "print('Shape of total ground Truths bboxes :', total_gt_bboxes.shape)\n",
    "print('Shape of total predicted bboxes :', total_pred_bboxes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e71f6b",
   "metadata": {},
   "source": [
    "# mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2326705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.50s/class]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP : tensor(0.0002)\n",
      "tensor([0.0000, 0.0001, 0.0000, 0.0007, 0.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mAP, AP_per_classes = mean_average_precision(total_pred_bboxes,\n",
    "                                             total_gt_bboxes,\n",
    "                                             iou_threshold=0.5,\n",
    "                                             box_format='corner',\n",
    "                                             num_classes=5)\n",
    "print('mAP :', mAP)\n",
    "print(AP_per_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
