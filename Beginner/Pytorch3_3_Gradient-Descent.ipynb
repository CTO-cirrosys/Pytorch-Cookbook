{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사하강법\n",
    "\n",
    "https://gjustin40.github.io/pytorch/2020/12/13/Pytorch-GradientDescent.html\n",
    "\n",
    "- 앞, 뒤 부분은 모두 생략하고 학습하는 부분만 작성하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Batch Gradient Descent(BGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정의\n",
    "# 모델 정의\n",
    "# 손실 및 최적화 함수 정의\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    \n",
    "    train_loss = 0\n",
    "    for data in dataloader: # batch_size=1인 dataloader\n",
    "        image, label = data # image = 1개\n",
    "        \n",
    "        output = model(image)\n",
    "        loss = loss_func(output, label)\n",
    "        \n",
    "        train_loss = train_loss + loss\n",
    "        ### error 계산 완료\n",
    "        \n",
    "    optimizer.zero_grad()    \n",
    "    train_loss.backward()\n",
    "    otimizer.step()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정의\n",
    "# 모델 정의\n",
    "# 손실 및 최적화 함수 정의\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    \n",
    "    for data in dataloader: # batch_size=1인 dataloader\n",
    "        image, label = data # image = 1개\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(image)\n",
    "        loss = loss_func(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mini-batch Stochastic Gradient Descent(MSGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정의\n",
    "# 모델 정의\n",
    "# 손실 및 최적화 함수 정의\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "dataloader = dataloader(batch_size = BATCH_SIZE)\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    \n",
    "    for data in dataloader: # batch_size=10인 dataloader\n",
    "        image, label = data # image = 10개\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(image)\n",
    "        loss = loss_func(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0], std=[1])\n",
      "           )\n",
      "****************************************************************************************************\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0], std=[1])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Dataset & DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0], [1])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root = '../data', train = True,\n",
    "                                      download = True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 16,\n",
    "                                          shuffle = True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root = '../data', train = False,\n",
    "                                     download = True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 128,\n",
    "                                         shuffle = True, num_workers=1)\n",
    "\n",
    "classes = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "\n",
    "print(trainset)\n",
    "print('*'*100)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 7, padding = 3)\n",
    "        self.conv2 = nn.Conv2d(10, 50, 7, padding = 3)\n",
    "        self.conv3 = nn.Conv2d(50, 120, 7, padding = 3)\n",
    "        self.conv4 = nn.Conv2d(120, 100, 5)\n",
    "        self.conv5 = nn.Conv2d(100, 20, 5)\n",
    "        self.conv6 = nn.Conv2d(20, 10, 5)\n",
    "        self.conv7 = nn.Conv2d(10, 10, 3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(10 * 8 * 8, 120)\n",
    "        self.fc2 = nn.Linear(120, 360)\n",
    "        self.fc3 = nn.Linear(360, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # 28 28\n",
    "        x = F.relu(self.conv2(x)) # 28 28\n",
    "        x = F.relu(self.conv3(x)) # 28 28\n",
    "        x = F.relu(self.conv4(x)) # 24 24\n",
    "        x = F.relu(self.conv5(x)) # 20 20\n",
    "        x = self.pool(F.relu(self.conv6(x))) # 8 8\n",
    "        x = x.view(-1, 10 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can use GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용여부 판단\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('We can use GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('We can use CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss() SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "print(loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "loss :  tensor(2.3147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[0/468] LOSS : 2.315------ Time : 2-------------------\n",
      "loss :  tensor(2.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[1/468] LOSS : 4.634------ Time : 2-------------------\n",
      "loss :  tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[2/468] LOSS : 6.934------ Time : 2-------------------\n",
      "loss :  tensor(2.2807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[3/468] LOSS : 9.215------ Time : 2-------------------\n",
      "loss :  tensor(2.3111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[4/468] LOSS : 11.526------ Time : 2-------------------\n",
      "loss :  tensor(2.3419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[5/468] LOSS : 13.868------ Time : 2-------------------\n",
      "loss :  tensor(2.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[6/468] LOSS : 16.206------ Time : 2-------------------\n",
      "loss :  tensor(2.2979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[7/468] LOSS : 18.504------ Time : 2-------------------\n",
      "loss :  tensor(2.2988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[8/468] LOSS : 20.802------ Time : 2-------------------\n",
      "loss :  tensor(2.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[9/468] LOSS : 23.091------ Time : 2-------------------\n",
      "loss :  tensor(2.3125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[10/468] LOSS : 25.403------ Time : 2-------------------\n",
      "loss :  tensor(2.3087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[11/468] LOSS : 27.712------ Time : 2-------------------\n",
      "loss :  tensor(2.2944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[12/468] LOSS : 30.006------ Time : 2-------------------\n",
      "loss :  tensor(2.3004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[13/468] LOSS : 32.307------ Time : 2-------------------\n",
      "loss :  tensor(2.2802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[14/468] LOSS : 34.587------ Time : 2-------------------\n",
      "loss :  tensor(2.3337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[15/468] LOSS : 36.920------ Time : 2-------------------\n",
      "loss :  tensor(2.3111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[16/468] LOSS : 39.232------ Time : 3-------------------\n",
      "loss :  tensor(2.3082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[17/468] LOSS : 41.540------ Time : 3-------------------\n",
      "loss :  tensor(2.3035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[18/468] LOSS : 43.843------ Time : 3-------------------\n",
      "loss :  tensor(2.3006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[19/468] LOSS : 46.144------ Time : 3-------------------\n",
      "loss :  tensor(2.3072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[20/468] LOSS : 48.451------ Time : 3-------------------\n",
      "loss :  tensor(2.3026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[21/468] LOSS : 50.754------ Time : 3-------------------\n",
      "loss :  tensor(2.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[22/468] LOSS : 53.058------ Time : 3-------------------\n",
      "loss :  tensor(2.3197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[23/468] LOSS : 55.378------ Time : 3-------------------\n",
      "loss :  tensor(2.2755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[24/468] LOSS : 57.654------ Time : 3-------------------\n",
      "loss :  tensor(2.3223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[25/468] LOSS : 59.976------ Time : 3-------------------\n",
      "loss :  tensor(2.2990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[26/468] LOSS : 62.275------ Time : 3-------------------\n",
      "loss :  tensor(2.3291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[27/468] LOSS : 64.604------ Time : 3-------------------\n",
      "loss :  tensor(2.2779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[28/468] LOSS : 66.882------ Time : 3-------------------\n",
      "loss :  tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[29/468] LOSS : 69.173------ Time : 3-------------------\n",
      "loss :  tensor(2.3066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[30/468] LOSS : 71.479------ Time : 3-------------------\n",
      "loss :  tensor(2.2913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[31/468] LOSS : 73.771------ Time : 3-------------------\n",
      "loss :  tensor(2.2828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[32/468] LOSS : 76.053------ Time : 3-------------------\n",
      "loss :  tensor(2.3163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[33/468] LOSS : 78.370------ Time : 3-------------------\n",
      "loss :  tensor(2.2815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[34/468] LOSS : 80.651------ Time : 3-------------------\n",
      "loss :  tensor(2.3245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[35/468] LOSS : 82.976------ Time : 3-------------------\n",
      "loss :  tensor(2.3036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[36/468] LOSS : 85.279------ Time : 3-------------------\n",
      "loss :  tensor(2.2895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[37/468] LOSS : 87.569------ Time : 3-------------------\n",
      "loss :  tensor(2.2875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[38/468] LOSS : 89.856------ Time : 3-------------------\n",
      "loss :  tensor(2.3121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[39/468] LOSS : 92.168------ Time : 3-------------------\n",
      "loss :  tensor(2.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[40/468] LOSS : 94.463------ Time : 3-------------------\n",
      "loss :  tensor(2.2809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[41/468] LOSS : 96.744------ Time : 3-------------------\n",
      "loss :  tensor(2.3096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[42/468] LOSS : 99.054------ Time : 3-------------------\n",
      "loss :  tensor(2.2599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[43/468] LOSS : 101.314------ Time : 3-------------------\n",
      "loss :  tensor(2.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[44/468] LOSS : 103.626------ Time : 3-------------------\n",
      "loss :  tensor(2.3008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[45/468] LOSS : 105.926------ Time : 3-------------------\n",
      "loss :  tensor(2.3215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[46/468] LOSS : 108.248------ Time : 3-------------------\n",
      "loss :  tensor(2.3021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[47/468] LOSS : 110.550------ Time : 3-------------------\n",
      "loss :  tensor(2.3073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[48/468] LOSS : 112.857------ Time : 3-------------------\n",
      "loss :  tensor(2.2831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[49/468] LOSS : 115.140------ Time : 3-------------------\n",
      "loss :  tensor(2.2886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[50/468] LOSS : 117.429------ Time : 3-------------------\n",
      "loss :  tensor(2.3044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[51/468] LOSS : 119.733------ Time : 3-------------------\n",
      "loss :  tensor(2.2930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[52/468] LOSS : 122.026------ Time : 3-------------------\n",
      "loss :  tensor(2.3431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[53/468] LOSS : 124.369------ Time : 3-------------------\n",
      "loss :  tensor(2.3402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[54/468] LOSS : 126.709------ Time : 3-------------------\n",
      "loss :  tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[55/468] LOSS : 129.013------ Time : 3-------------------\n",
      "loss :  tensor(2.3313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[56/468] LOSS : 131.344------ Time : 3-------------------\n",
      "loss :  tensor(2.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[57/468] LOSS : 133.645------ Time : 3-------------------\n",
      "loss :  tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[58/468] LOSS : 135.944------ Time : 3-------------------\n",
      "loss :  tensor(2.2779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[59/468] LOSS : 138.222------ Time : 3-------------------\n",
      "loss :  tensor(2.2513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[60/468] LOSS : 140.473------ Time : 3-------------------\n",
      "loss :  tensor(2.3083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[61/468] LOSS : 142.782------ Time : 3-------------------\n",
      "loss :  tensor(2.3330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[62/468] LOSS : 145.115------ Time : 3-------------------\n",
      "loss :  tensor(2.2927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[63/468] LOSS : 147.407------ Time : 3-------------------\n",
      "loss :  tensor(2.2918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[64/468] LOSS : 149.699------ Time : 3-------------------\n",
      "loss :  tensor(2.3163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[65/468] LOSS : 152.016------ Time : 3-------------------\n",
      "loss :  tensor(2.3114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[66/468] LOSS : 154.327------ Time : 3-------------------\n",
      "loss :  tensor(2.3068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[67/468] LOSS : 156.634------ Time : 3-------------------\n",
      "loss :  tensor(2.3171, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[68/468] LOSS : 158.951------ Time : 3-------------------\n",
      "loss :  tensor(2.3080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[69/468] LOSS : 161.259------ Time : 3-------------------\n",
      "loss :  tensor(2.3116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[70/468] LOSS : 163.570------ Time : 3-------------------\n",
      "loss :  tensor(2.2829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[71/468] LOSS : 165.853------ Time : 3-------------------\n",
      "loss :  tensor(2.2893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[72/468] LOSS : 168.142------ Time : 3-------------------\n",
      "loss :  tensor(2.3111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[73/468] LOSS : 170.454------ Time : 3-------------------\n",
      "loss :  tensor(2.3012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[74/468] LOSS : 172.755------ Time : 3-------------------\n",
      "loss :  tensor(2.3008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[75/468] LOSS : 175.056------ Time : 3-------------------\n",
      "loss :  tensor(2.2619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[76/468] LOSS : 177.317------ Time : 3-------------------\n",
      "loss :  tensor(2.3313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[77/468] LOSS : 179.649------ Time : 3-------------------\n",
      "loss :  tensor(2.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[78/468] LOSS : 181.959------ Time : 3-------------------\n",
      "loss :  tensor(2.3061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[79/468] LOSS : 184.265------ Time : 3-------------------\n",
      "loss :  tensor(2.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[80/468] LOSS : 186.570------ Time : 3-------------------\n",
      "loss :  tensor(2.2929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[81/468] LOSS : 188.863------ Time : 3-------------------\n",
      "loss :  tensor(2.2794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[82/468] LOSS : 191.143------ Time : 3-------------------\n",
      "loss :  tensor(2.3045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[83/468] LOSS : 193.447------ Time : 3-------------------\n",
      "loss :  tensor(2.2822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[84/468] LOSS : 195.729------ Time : 3-------------------\n",
      "loss :  tensor(2.2765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[85/468] LOSS : 198.006------ Time : 3-------------------\n",
      "loss :  tensor(2.2738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[86/468] LOSS : 200.280------ Time : 3-------------------\n",
      "loss :  tensor(2.3034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[87/468] LOSS : 202.583------ Time : 3-------------------\n",
      "loss :  tensor(2.3148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[88/468] LOSS : 204.898------ Time : 3-------------------\n",
      "loss :  tensor(2.3395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[89/468] LOSS : 207.237------ Time : 3-------------------\n",
      "loss :  tensor(2.2856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[90/468] LOSS : 209.523------ Time : 3-------------------\n",
      "loss :  tensor(2.3115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[91/468] LOSS : 211.835------ Time : 3-------------------\n",
      "loss :  tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[92/468] LOSS : 214.137------ Time : 3-------------------\n",
      "loss :  tensor(2.2526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[93/468] LOSS : 216.390------ Time : 3-------------------\n",
      "loss :  tensor(2.2447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[94/468] LOSS : 218.635------ Time : 3-------------------\n",
      "loss :  tensor(2.3060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[95/468] LOSS : 220.941------ Time : 3-------------------\n",
      "loss :  tensor(2.3039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[96/468] LOSS : 223.245------ Time : 3-------------------\n",
      "loss :  tensor(2.2978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[97/468] LOSS : 225.542------ Time : 3-------------------\n",
      "loss :  tensor(2.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[98/468] LOSS : 227.847------ Time : 3-------------------\n",
      "loss :  tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[99/468] LOSS : 230.137------ Time : 3-------------------\n",
      "loss :  tensor(2.3441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[100/468] LOSS : 232.482------ Time : 3-------------------\n",
      "loss :  tensor(2.2898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[101/468] LOSS : 234.771------ Time : 3-------------------\n",
      "loss :  tensor(2.2734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[102/468] LOSS : 237.045------ Time : 3-------------------\n",
      "loss :  tensor(2.3022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[103/468] LOSS : 239.347------ Time : 3-------------------\n",
      "loss :  tensor(2.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[104/468] LOSS : 241.626------ Time : 3-------------------\n",
      "loss :  tensor(2.2552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[105/468] LOSS : 243.881------ Time : 3-------------------\n",
      "loss :  tensor(2.3035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[106/468] LOSS : 246.185------ Time : 3-------------------\n",
      "loss :  tensor(2.3056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[107/468] LOSS : 248.490------ Time : 3-------------------\n",
      "loss :  tensor(2.3415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[108/468] LOSS : 250.832------ Time : 3-------------------\n",
      "loss :  tensor(2.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[109/468] LOSS : 253.127------ Time : 3-------------------\n",
      "loss :  tensor(2.2874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[110/468] LOSS : 255.414------ Time : 3-------------------\n",
      "loss :  tensor(2.3205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[111/468] LOSS : 257.734------ Time : 3-------------------\n",
      "loss :  tensor(2.3325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[112/468] LOSS : 260.067------ Time : 3-------------------\n",
      "loss :  tensor(2.3366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[113/468] LOSS : 262.404------ Time : 3-------------------\n",
      "loss :  tensor(2.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[114/468] LOSS : 264.688------ Time : 3-------------------\n",
      "loss :  tensor(2.3187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[115/468] LOSS : 267.006------ Time : 3-------------------\n",
      "loss :  tensor(2.3154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[116/468] LOSS : 269.322------ Time : 3-------------------\n",
      "loss :  tensor(2.3069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[117/468] LOSS : 271.629------ Time : 4-------------------\n",
      "loss :  tensor(2.3077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[118/468] LOSS : 273.936------ Time : 4-------------------\n",
      "loss :  tensor(2.3014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[119/468] LOSS : 276.238------ Time : 4-------------------\n",
      "loss :  tensor(2.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[120/468] LOSS : 278.526------ Time : 4-------------------\n",
      "loss :  tensor(2.2975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[121/468] LOSS : 280.823------ Time : 4-------------------\n",
      "loss :  tensor(2.3094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[122/468] LOSS : 283.133------ Time : 4-------------------\n",
      "loss :  tensor(2.2958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[123/468] LOSS : 285.428------ Time : 4-------------------\n",
      "loss :  tensor(2.3011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[124/468] LOSS : 287.730------ Time : 4-------------------\n",
      "loss :  tensor(2.3243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[125/468] LOSS : 290.054------ Time : 4-------------------\n",
      "loss :  tensor(2.2845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[126/468] LOSS : 292.338------ Time : 4-------------------\n",
      "loss :  tensor(2.3130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[127/468] LOSS : 294.651------ Time : 4-------------------\n",
      "loss :  tensor(2.2939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[128/468] LOSS : 296.945------ Time : 4-------------------\n",
      "loss :  tensor(2.3281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[129/468] LOSS : 299.273------ Time : 4-------------------\n",
      "loss :  tensor(2.3047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[130/468] LOSS : 301.578------ Time : 4-------------------\n",
      "loss :  tensor(2.3095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[131/468] LOSS : 303.888------ Time : 4-------------------\n",
      "loss :  tensor(2.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[132/468] LOSS : 306.183------ Time : 4-------------------\n",
      "loss :  tensor(2.2569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[133/468] LOSS : 308.440------ Time : 4-------------------\n",
      "loss :  tensor(2.2807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[134/468] LOSS : 310.721------ Time : 4-------------------\n",
      "loss :  tensor(2.2808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[135/468] LOSS : 313.002------ Time : 4-------------------\n",
      "loss :  tensor(2.3290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[136/468] LOSS : 315.331------ Time : 4-------------------\n",
      "loss :  tensor(2.3142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[137/468] LOSS : 317.645------ Time : 4-------------------\n",
      "loss :  tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[138/468] LOSS : 319.946------ Time : 4-------------------\n",
      "loss :  tensor(2.3126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[139/468] LOSS : 322.258------ Time : 4-------------------\n",
      "loss :  tensor(2.2975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[140/468] LOSS : 324.556------ Time : 4-------------------\n",
      "loss :  tensor(2.2885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[141/468] LOSS : 326.844------ Time : 4-------------------\n",
      "loss :  tensor(2.3326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[142/468] LOSS : 329.177------ Time : 4-------------------\n",
      "loss :  tensor(2.3241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[143/468] LOSS : 331.501------ Time : 4-------------------\n",
      "loss :  tensor(2.2854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[144/468] LOSS : 333.786------ Time : 4-------------------\n",
      "loss :  tensor(2.3183, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[145/468] LOSS : 336.105------ Time : 4-------------------\n",
      "loss :  tensor(2.3360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[146/468] LOSS : 338.441------ Time : 4-------------------\n",
      "loss :  tensor(2.3558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[147/468] LOSS : 340.796------ Time : 4-------------------\n",
      "loss :  tensor(2.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[148/468] LOSS : 343.101------ Time : 4-------------------\n",
      "loss :  tensor(2.3085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[149/468] LOSS : 345.410------ Time : 4-------------------\n",
      "loss :  tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[150/468] LOSS : 347.710------ Time : 4-------------------\n",
      "loss :  tensor(2.2981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[151/468] LOSS : 350.008------ Time : 4-------------------\n",
      "loss :  tensor(2.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[152/468] LOSS : 352.313------ Time : 4-------------------\n",
      "loss :  tensor(2.3101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[153/468] LOSS : 354.623------ Time : 4-------------------\n",
      "loss :  tensor(2.3221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[154/468] LOSS : 356.945------ Time : 4-------------------\n",
      "loss :  tensor(2.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[155/468] LOSS : 359.257------ Time : 4-------------------\n",
      "loss :  tensor(2.3213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[156/468] LOSS : 361.578------ Time : 4-------------------\n",
      "loss :  tensor(2.2856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[157/468] LOSS : 363.864------ Time : 4-------------------\n",
      "loss :  tensor(2.3318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[158/468] LOSS : 366.195------ Time : 4-------------------\n",
      "loss :  tensor(2.2916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[159/468] LOSS : 368.487------ Time : 4-------------------\n",
      "loss :  tensor(2.2819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[160/468] LOSS : 370.769------ Time : 4-------------------\n",
      "loss :  tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[161/468] LOSS : 373.090------ Time : 4-------------------\n",
      "loss :  tensor(2.2903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[162/468] LOSS : 375.381------ Time : 4-------------------\n",
      "loss :  tensor(2.2853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[163/468] LOSS : 377.666------ Time : 4-------------------\n",
      "loss :  tensor(2.3035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[164/468] LOSS : 379.969------ Time : 4-------------------\n",
      "loss :  tensor(2.2771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[165/468] LOSS : 382.247------ Time : 4-------------------\n",
      "loss :  tensor(2.3158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[166/468] LOSS : 384.562------ Time : 4-------------------\n",
      "loss :  tensor(2.3292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[167/468] LOSS : 386.892------ Time : 4-------------------\n",
      "loss :  tensor(2.2922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[168/468] LOSS : 389.184------ Time : 4-------------------\n",
      "loss :  tensor(2.3156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[169/468] LOSS : 391.499------ Time : 4-------------------\n",
      "loss :  tensor(2.3107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[170/468] LOSS : 393.810------ Time : 4-------------------\n",
      "loss :  tensor(2.3274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[171/468] LOSS : 396.137------ Time : 4-------------------\n",
      "loss :  tensor(2.3301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[172/468] LOSS : 398.467------ Time : 4-------------------\n",
      "loss :  tensor(2.3039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[173/468] LOSS : 400.771------ Time : 4-------------------\n",
      "loss :  tensor(2.2935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[174/468] LOSS : 403.065------ Time : 4-------------------\n",
      "loss :  tensor(2.2885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[175/468] LOSS : 405.353------ Time : 4-------------------\n",
      "loss :  tensor(2.2997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[176/468] LOSS : 407.653------ Time : 4-------------------\n",
      "loss :  tensor(2.2993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[177/468] LOSS : 409.952------ Time : 4-------------------\n",
      "loss :  tensor(2.3089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[178/468] LOSS : 412.261------ Time : 4-------------------\n",
      "loss :  tensor(2.3149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[179/468] LOSS : 414.576------ Time : 4-------------------\n",
      "loss :  tensor(2.3189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[180/468] LOSS : 416.895------ Time : 4-------------------\n",
      "loss :  tensor(2.2969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[181/468] LOSS : 419.192------ Time : 4-------------------\n",
      "loss :  tensor(2.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[182/468] LOSS : 421.497------ Time : 4-------------------\n",
      "loss :  tensor(2.3071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[183/468] LOSS : 423.804------ Time : 4-------------------\n",
      "loss :  tensor(2.3203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[184/468] LOSS : 426.124------ Time : 4-------------------\n",
      "loss :  tensor(2.3114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[185/468] LOSS : 428.436------ Time : 4-------------------\n",
      "loss :  tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[186/468] LOSS : 430.733------ Time : 4-------------------\n",
      "loss :  tensor(2.3008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[187/468] LOSS : 433.033------ Time : 4-------------------\n",
      "loss :  tensor(2.3052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[188/468] LOSS : 435.339------ Time : 4-------------------\n",
      "loss :  tensor(2.3276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[189/468] LOSS : 437.666------ Time : 4-------------------\n",
      "loss :  tensor(2.2802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[190/468] LOSS : 439.947------ Time : 4-------------------\n",
      "loss :  tensor(2.3249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[191/468] LOSS : 442.271------ Time : 4-------------------\n",
      "loss :  tensor(2.3234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[192/468] LOSS : 444.595------ Time : 4-------------------\n",
      "loss :  tensor(2.3138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[193/468] LOSS : 446.909------ Time : 4-------------------\n",
      "loss :  tensor(2.3165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[194/468] LOSS : 449.225------ Time : 4-------------------\n",
      "loss :  tensor(2.3063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[195/468] LOSS : 451.531------ Time : 4-------------------\n",
      "loss :  tensor(2.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[196/468] LOSS : 453.827------ Time : 4-------------------\n",
      "loss :  tensor(2.2984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[197/468] LOSS : 456.125------ Time : 4-------------------\n",
      "loss :  tensor(2.3066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[198/468] LOSS : 458.432------ Time : 4-------------------\n",
      "loss :  tensor(2.2940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[199/468] LOSS : 460.726------ Time : 4-------------------\n",
      "loss :  tensor(2.2795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[200/468] LOSS : 463.006------ Time : 4-------------------\n",
      "loss :  tensor(2.3060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[201/468] LOSS : 465.312------ Time : 4-------------------\n",
      "loss :  tensor(2.3328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[202/468] LOSS : 467.644------ Time : 4-------------------\n",
      "loss :  tensor(2.3200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[203/468] LOSS : 469.964------ Time : 4-------------------\n",
      "loss :  tensor(2.3071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[204/468] LOSS : 472.271------ Time : 4-------------------\n",
      "loss :  tensor(2.3163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[205/468] LOSS : 474.588------ Time : 4-------------------\n",
      "loss :  tensor(2.2918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[206/468] LOSS : 476.880------ Time : 4-------------------\n",
      "loss :  tensor(2.2950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[207/468] LOSS : 479.174------ Time : 4-------------------\n",
      "loss :  tensor(2.2868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[208/468] LOSS : 481.461------ Time : 4-------------------\n",
      "loss :  tensor(2.3240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[209/468] LOSS : 483.785------ Time : 4-------------------\n",
      "loss :  tensor(2.3083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[210/468] LOSS : 486.094------ Time : 4-------------------\n",
      "loss :  tensor(2.2908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[211/468] LOSS : 488.384------ Time : 4-------------------\n",
      "loss :  tensor(2.3041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[212/468] LOSS : 490.688------ Time : 4-------------------\n",
      "loss :  tensor(2.3329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[213/468] LOSS : 493.021------ Time : 4-------------------\n",
      "loss :  tensor(2.2891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[214/468] LOSS : 495.310------ Time : 4-------------------\n",
      "loss :  tensor(2.3291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[215/468] LOSS : 497.640------ Time : 4-------------------\n",
      "loss :  tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[216/468] LOSS : 499.925------ Time : 4-------------------\n",
      "loss :  tensor(2.3118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[217/468] LOSS : 502.237------ Time : 4-------------------\n",
      "loss :  tensor(2.2991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[218/468] LOSS : 504.536------ Time : 4-------------------\n",
      "loss :  tensor(2.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[219/468] LOSS : 506.829------ Time : 4-------------------\n",
      "loss :  tensor(2.3286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[220/468] LOSS : 509.157------ Time : 4-------------------\n",
      "loss :  tensor(2.3193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[221/468] LOSS : 511.477------ Time : 5-------------------\n",
      "loss :  tensor(2.3087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[222/468] LOSS : 513.785------ Time : 5-------------------\n",
      "loss :  tensor(2.3141, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[223/468] LOSS : 516.100------ Time : 5-------------------\n",
      "loss :  tensor(2.3089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[224/468] LOSS : 518.409------ Time : 5-------------------\n",
      "loss :  tensor(2.3163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[225/468] LOSS : 520.725------ Time : 5-------------------\n",
      "loss :  tensor(2.3091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[226/468] LOSS : 523.034------ Time : 5-------------------\n",
      "loss :  tensor(2.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[227/468] LOSS : 525.346------ Time : 5-------------------\n",
      "loss :  tensor(2.2965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[228/468] LOSS : 527.643------ Time : 5-------------------\n",
      "loss :  tensor(2.3126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[229/468] LOSS : 529.955------ Time : 5-------------------\n",
      "loss :  tensor(2.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[230/468] LOSS : 532.256------ Time : 5-------------------\n",
      "loss :  tensor(2.3025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[231/468] LOSS : 534.558------ Time : 5-------------------\n",
      "loss :  tensor(2.2947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[232/468] LOSS : 536.853------ Time : 5-------------------\n",
      "loss :  tensor(2.2961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[233/468] LOSS : 539.149------ Time : 5-------------------\n",
      "loss :  tensor(2.3177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[234/468] LOSS : 541.466------ Time : 5-------------------\n",
      "loss :  tensor(2.2969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[235/468] LOSS : 543.763------ Time : 5-------------------\n",
      "loss :  tensor(2.3071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[236/468] LOSS : 546.071------ Time : 5-------------------\n",
      "loss :  tensor(2.3118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[237/468] LOSS : 548.382------ Time : 5-------------------\n",
      "loss :  tensor(2.2903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[238/468] LOSS : 550.673------ Time : 5-------------------\n",
      "loss :  tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[239/468] LOSS : 552.963------ Time : 5-------------------\n",
      "loss :  tensor(2.3300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[240/468] LOSS : 555.293------ Time : 5-------------------\n",
      "loss :  tensor(2.2934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[241/468] LOSS : 557.587------ Time : 5-------------------\n",
      "loss :  tensor(2.3043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[242/468] LOSS : 559.891------ Time : 5-------------------\n",
      "loss :  tensor(2.3109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[243/468] LOSS : 562.202------ Time : 5-------------------\n",
      "loss :  tensor(2.2939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[244/468] LOSS : 564.496------ Time : 5-------------------\n",
      "loss :  tensor(2.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[245/468] LOSS : 566.800------ Time : 5-------------------\n",
      "loss :  tensor(2.2841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[246/468] LOSS : 569.084------ Time : 5-------------------\n",
      "loss :  tensor(2.2982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[247/468] LOSS : 571.383------ Time : 5-------------------\n",
      "loss :  tensor(2.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[248/468] LOSS : 573.693------ Time : 5-------------------\n",
      "loss :  tensor(2.2980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[249/468] LOSS : 575.991------ Time : 5-------------------\n",
      "loss :  tensor(2.2925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[250/468] LOSS : 578.284------ Time : 5-------------------\n",
      "loss :  tensor(2.2986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[251/468] LOSS : 580.583------ Time : 5-------------------\n",
      "loss :  tensor(2.3076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[252/468] LOSS : 582.890------ Time : 5-------------------\n",
      "loss :  tensor(2.3043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[253/468] LOSS : 585.194------ Time : 5-------------------\n",
      "loss :  tensor(2.3003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[254/468] LOSS : 587.495------ Time : 5-------------------\n",
      "loss :  tensor(2.3019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[255/468] LOSS : 589.797------ Time : 5-------------------\n",
      "loss :  tensor(2.2943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[256/468] LOSS : 592.091------ Time : 5-------------------\n",
      "loss :  tensor(2.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[257/468] LOSS : 594.411------ Time : 5-------------------\n",
      "loss :  tensor(2.3124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[258/468] LOSS : 596.723------ Time : 5-------------------\n",
      "loss :  tensor(2.2864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[259/468] LOSS : 599.010------ Time : 5-------------------\n",
      "loss :  tensor(2.3101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[260/468] LOSS : 601.320------ Time : 5-------------------\n",
      "loss :  tensor(2.3016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[261/468] LOSS : 603.622------ Time : 5-------------------\n",
      "loss :  tensor(2.3181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[262/468] LOSS : 605.940------ Time : 5-------------------\n",
      "loss :  tensor(2.2877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[263/468] LOSS : 608.227------ Time : 5-------------------\n",
      "loss :  tensor(2.3248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[264/468] LOSS : 610.552------ Time : 5-------------------\n",
      "loss :  tensor(2.2999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[265/468] LOSS : 612.852------ Time : 5-------------------\n",
      "loss :  tensor(2.2991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[266/468] LOSS : 615.151------ Time : 5-------------------\n",
      "loss :  tensor(2.2929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[267/468] LOSS : 617.444------ Time : 5-------------------\n",
      "loss :  tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[268/468] LOSS : 619.743------ Time : 5-------------------\n",
      "loss :  tensor(2.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[269/468] LOSS : 622.038------ Time : 5-------------------\n",
      "loss :  tensor(2.3282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[270/468] LOSS : 624.367------ Time : 5-------------------\n",
      "loss :  tensor(2.3096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[271/468] LOSS : 626.676------ Time : 5-------------------\n",
      "loss :  tensor(2.3118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[272/468] LOSS : 628.988------ Time : 5-------------------\n",
      "loss :  tensor(2.3090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[273/468] LOSS : 631.297------ Time : 5-------------------\n",
      "loss :  tensor(2.2939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[274/468] LOSS : 633.591------ Time : 5-------------------\n",
      "loss :  tensor(2.2911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[275/468] LOSS : 635.882------ Time : 5-------------------\n",
      "loss :  tensor(2.3093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[276/468] LOSS : 638.191------ Time : 5-------------------\n",
      "loss :  tensor(2.2992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[277/468] LOSS : 640.490------ Time : 5-------------------\n",
      "loss :  tensor(2.2936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[278/468] LOSS : 642.784------ Time : 5-------------------\n",
      "loss :  tensor(2.2850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[279/468] LOSS : 645.069------ Time : 5-------------------\n",
      "loss :  tensor(2.3176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[280/468] LOSS : 647.387------ Time : 5-------------------\n",
      "loss :  tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[281/468] LOSS : 649.687------ Time : 5-------------------\n",
      "loss :  tensor(2.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[282/468] LOSS : 651.999------ Time : 5-------------------\n",
      "loss :  tensor(2.3406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[283/468] LOSS : 654.339------ Time : 5-------------------\n",
      "loss :  tensor(2.3105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[284/468] LOSS : 656.650------ Time : 5-------------------\n",
      "loss :  tensor(2.3067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[285/468] LOSS : 658.956------ Time : 5-------------------\n",
      "loss :  tensor(2.3071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[286/468] LOSS : 661.264------ Time : 5-------------------\n",
      "loss :  tensor(2.3000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[287/468] LOSS : 663.564------ Time : 5-------------------\n",
      "loss :  tensor(2.3114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[288/468] LOSS : 665.875------ Time : 5-------------------\n",
      "loss :  tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[289/468] LOSS : 668.175------ Time : 5-------------------\n",
      "loss :  tensor(2.3107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[290/468] LOSS : 670.486------ Time : 5-------------------\n",
      "loss :  tensor(2.3058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[291/468] LOSS : 672.792------ Time : 5-------------------\n",
      "loss :  tensor(2.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[292/468] LOSS : 675.102------ Time : 5-------------------\n",
      "loss :  tensor(2.3127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[293/468] LOSS : 677.415------ Time : 5-------------------\n",
      "loss :  tensor(2.3189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[294/468] LOSS : 679.734------ Time : 5-------------------\n",
      "loss :  tensor(2.2934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[295/468] LOSS : 682.027------ Time : 5-------------------\n",
      "loss :  tensor(2.2901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[296/468] LOSS : 684.317------ Time : 5-------------------\n",
      "loss :  tensor(2.2747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[297/468] LOSS : 686.592------ Time : 5-------------------\n",
      "loss :  tensor(2.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[298/468] LOSS : 688.904------ Time : 5-------------------\n",
      "loss :  tensor(2.3011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[299/468] LOSS : 691.205------ Time : 5-------------------\n",
      "loss :  tensor(2.3224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[300/468] LOSS : 693.528------ Time : 5-------------------\n",
      "loss :  tensor(2.3008, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[301/468] LOSS : 695.828------ Time : 5-------------------\n",
      "loss :  tensor(2.2809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[302/468] LOSS : 698.109------ Time : 5-------------------\n",
      "loss :  tensor(2.3080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[303/468] LOSS : 700.417------ Time : 5-------------------\n",
      "loss :  tensor(2.3181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[304/468] LOSS : 702.736------ Time : 5-------------------\n",
      "loss :  tensor(2.3056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[305/468] LOSS : 705.041------ Time : 5-------------------\n",
      "loss :  tensor(2.3190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[306/468] LOSS : 707.360------ Time : 5-------------------\n",
      "loss :  tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[307/468] LOSS : 709.663------ Time : 5-------------------\n",
      "loss :  tensor(2.2809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[308/468] LOSS : 711.944------ Time : 5-------------------\n",
      "loss :  tensor(2.2968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[309/468] LOSS : 714.241------ Time : 5-------------------\n",
      "loss :  tensor(2.2804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[310/468] LOSS : 716.521------ Time : 5-------------------\n",
      "loss :  tensor(2.2978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[311/468] LOSS : 718.819------ Time : 5-------------------\n",
      "loss :  tensor(2.3119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[312/468] LOSS : 721.131------ Time : 5-------------------\n",
      "loss :  tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[313/468] LOSS : 723.421------ Time : 5-------------------\n",
      "loss :  tensor(2.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[314/468] LOSS : 725.710------ Time : 5-------------------\n",
      "loss :  tensor(2.3084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[315/468] LOSS : 728.018------ Time : 5-------------------\n",
      "loss :  tensor(2.2994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[316/468] LOSS : 730.317------ Time : 5-------------------\n",
      "loss :  tensor(2.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[317/468] LOSS : 732.610------ Time : 5-------------------\n",
      "loss :  tensor(2.3226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[318/468] LOSS : 734.932------ Time : 5-------------------\n",
      "loss :  tensor(2.3296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[319/468] LOSS : 737.262------ Time : 5-------------------\n",
      "loss :  tensor(2.2862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[320/468] LOSS : 739.548------ Time : 5-------------------\n",
      "loss :  tensor(2.2959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[321/468] LOSS : 741.844------ Time : 5-------------------\n",
      "loss :  tensor(2.3103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[322/468] LOSS : 744.154------ Time : 5-------------------\n",
      "loss :  tensor(2.3121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[323/468] LOSS : 746.467------ Time : 5-------------------\n",
      "loss :  tensor(2.2836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[324/468] LOSS : 748.750------ Time : 5-------------------\n",
      "loss :  tensor(2.3103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[325/468] LOSS : 751.060------ Time : 6-------------------\n",
      "loss :  tensor(2.3028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[326/468] LOSS : 753.363------ Time : 6-------------------\n",
      "loss :  tensor(2.3122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[327/468] LOSS : 755.675------ Time : 6-------------------\n",
      "loss :  tensor(2.3349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[328/468] LOSS : 758.010------ Time : 6-------------------\n",
      "loss :  tensor(2.3138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[329/468] LOSS : 760.324------ Time : 6-------------------\n",
      "loss :  tensor(2.3177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[330/468] LOSS : 762.642------ Time : 6-------------------\n",
      "loss :  tensor(2.2986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[331/468] LOSS : 764.940------ Time : 6-------------------\n",
      "loss :  tensor(2.3011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[332/468] LOSS : 767.242------ Time : 6-------------------\n",
      "loss :  tensor(2.3015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[333/468] LOSS : 769.543------ Time : 6-------------------\n",
      "loss :  tensor(2.3102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[334/468] LOSS : 771.853------ Time : 6-------------------\n",
      "loss :  tensor(2.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[335/468] LOSS : 774.158------ Time : 6-------------------\n",
      "loss :  tensor(2.2985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[336/468] LOSS : 776.457------ Time : 6-------------------\n",
      "loss :  tensor(2.2974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[337/468] LOSS : 778.754------ Time : 6-------------------\n",
      "loss :  tensor(2.3111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[338/468] LOSS : 781.065------ Time : 6-------------------\n",
      "loss :  tensor(2.2935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[339/468] LOSS : 783.359------ Time : 6-------------------\n",
      "loss :  tensor(2.2982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[340/468] LOSS : 785.657------ Time : 6-------------------\n",
      "loss :  tensor(2.2969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[341/468] LOSS : 787.954------ Time : 6-------------------\n",
      "loss :  tensor(2.2939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[342/468] LOSS : 790.248------ Time : 6-------------------\n",
      "loss :  tensor(2.3152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[343/468] LOSS : 792.563------ Time : 6-------------------\n",
      "loss :  tensor(2.2976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[344/468] LOSS : 794.860------ Time : 6-------------------\n",
      "loss :  tensor(2.3156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[345/468] LOSS : 797.176------ Time : 6-------------------\n",
      "loss :  tensor(2.3090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[346/468] LOSS : 799.485------ Time : 6-------------------\n",
      "loss :  tensor(2.2927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[347/468] LOSS : 801.778------ Time : 6-------------------\n",
      "loss :  tensor(2.2898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[348/468] LOSS : 804.067------ Time : 6-------------------\n",
      "loss :  tensor(2.3079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[349/468] LOSS : 806.375------ Time : 6-------------------\n",
      "loss :  tensor(2.3065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[350/468] LOSS : 808.682------ Time : 6-------------------\n",
      "loss :  tensor(2.2993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[351/468] LOSS : 810.981------ Time : 6-------------------\n",
      "loss :  tensor(2.3085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[352/468] LOSS : 813.290------ Time : 6-------------------\n",
      "loss :  tensor(2.2929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[353/468] LOSS : 815.582------ Time : 6-------------------\n",
      "loss :  tensor(2.2995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[354/468] LOSS : 817.882------ Time : 6-------------------\n",
      "loss :  tensor(2.2963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[355/468] LOSS : 820.178------ Time : 6-------------------\n",
      "loss :  tensor(2.2885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[356/468] LOSS : 822.467------ Time : 6-------------------\n",
      "loss :  tensor(2.2962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[357/468] LOSS : 824.763------ Time : 6-------------------\n",
      "loss :  tensor(2.2751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[358/468] LOSS : 827.038------ Time : 6-------------------\n",
      "loss :  tensor(2.2883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[359/468] LOSS : 829.326------ Time : 6-------------------\n",
      "loss :  tensor(2.2900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[360/468] LOSS : 831.616------ Time : 6-------------------\n",
      "loss :  tensor(2.3011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[361/468] LOSS : 833.917------ Time : 6-------------------\n",
      "loss :  tensor(2.3167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[362/468] LOSS : 836.234------ Time : 6-------------------\n",
      "loss :  tensor(2.3043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[363/468] LOSS : 838.538------ Time : 6-------------------\n",
      "loss :  tensor(2.3269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[364/468] LOSS : 840.865------ Time : 6-------------------\n",
      "loss :  tensor(2.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[365/468] LOSS : 843.177------ Time : 6-------------------\n",
      "loss :  tensor(2.3024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[366/468] LOSS : 845.479------ Time : 6-------------------\n",
      "loss :  tensor(2.3010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[367/468] LOSS : 847.781------ Time : 6-------------------\n",
      "loss :  tensor(2.2767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[368/468] LOSS : 850.057------ Time : 6-------------------\n",
      "loss :  tensor(2.2888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[369/468] LOSS : 852.346------ Time : 6-------------------\n",
      "loss :  tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[370/468] LOSS : 854.671------ Time : 6-------------------\n",
      "loss :  tensor(2.2694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[371/468] LOSS : 856.940------ Time : 6-------------------\n",
      "loss :  tensor(2.3301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[372/468] LOSS : 859.271------ Time : 6-------------------\n",
      "loss :  tensor(2.2854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[373/468] LOSS : 861.556------ Time : 6-------------------\n",
      "loss :  tensor(2.2956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[374/468] LOSS : 863.852------ Time : 6-------------------\n",
      "loss :  tensor(2.3129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[375/468] LOSS : 866.164------ Time : 6-------------------\n",
      "loss :  tensor(2.2966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[376/468] LOSS : 868.461------ Time : 6-------------------\n",
      "loss :  tensor(2.3358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[377/468] LOSS : 870.797------ Time : 6-------------------\n",
      "loss :  tensor(2.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[378/468] LOSS : 873.092------ Time : 6-------------------\n",
      "loss :  tensor(2.3179, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[379/468] LOSS : 875.410------ Time : 6-------------------\n",
      "loss :  tensor(2.3079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[380/468] LOSS : 877.718------ Time : 6-------------------\n",
      "loss :  tensor(2.3147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[381/468] LOSS : 880.032------ Time : 6-------------------\n",
      "loss :  tensor(2.3029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[382/468] LOSS : 882.335------ Time : 6-------------------\n",
      "loss :  tensor(2.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[383/468] LOSS : 884.630------ Time : 6-------------------\n",
      "loss :  tensor(2.2939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[384/468] LOSS : 886.924------ Time : 6-------------------\n",
      "loss :  tensor(2.2832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[385/468] LOSS : 889.207------ Time : 6-------------------\n",
      "loss :  tensor(2.3018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[386/468] LOSS : 891.509------ Time : 6-------------------\n",
      "loss :  tensor(2.2736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[387/468] LOSS : 893.783------ Time : 6-------------------\n",
      "loss :  tensor(2.2534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[388/468] LOSS : 896.036------ Time : 6-------------------\n",
      "loss :  tensor(2.3311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[389/468] LOSS : 898.367------ Time : 6-------------------\n",
      "loss :  tensor(2.3198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[390/468] LOSS : 900.687------ Time : 6-------------------\n",
      "loss :  tensor(2.2984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[391/468] LOSS : 902.985------ Time : 6-------------------\n",
      "loss :  tensor(2.3370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[392/468] LOSS : 905.322------ Time : 6-------------------\n",
      "loss :  tensor(2.3181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[393/468] LOSS : 907.640------ Time : 6-------------------\n",
      "loss :  tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[394/468] LOSS : 909.941------ Time : 6-------------------\n",
      "loss :  tensor(2.2976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[395/468] LOSS : 912.239------ Time : 6-------------------\n",
      "loss :  tensor(2.2594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[396/468] LOSS : 914.498------ Time : 6-------------------\n",
      "loss :  tensor(2.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[397/468] LOSS : 916.803------ Time : 6-------------------\n",
      "loss :  tensor(2.3160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[398/468] LOSS : 919.119------ Time : 6-------------------\n",
      "loss :  tensor(2.3108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[399/468] LOSS : 921.430------ Time : 6-------------------\n",
      "loss :  tensor(2.2879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[400/468] LOSS : 923.718------ Time : 6-------------------\n",
      "loss :  tensor(2.3122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[401/468] LOSS : 926.030------ Time : 6-------------------\n",
      "loss :  tensor(2.2733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[402/468] LOSS : 928.304------ Time : 6-------------------\n",
      "loss :  tensor(2.3254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[403/468] LOSS : 930.629------ Time : 6-------------------\n",
      "loss :  tensor(2.3079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[404/468] LOSS : 932.937------ Time : 6-------------------\n",
      "loss :  tensor(2.2957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[405/468] LOSS : 935.233------ Time : 6-------------------\n",
      "loss :  tensor(2.3485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[406/468] LOSS : 937.581------ Time : 6-------------------\n",
      "loss :  tensor(2.3009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[407/468] LOSS : 939.882------ Time : 6-------------------\n",
      "loss :  tensor(2.2723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[408/468] LOSS : 942.154------ Time : 6-------------------\n",
      "loss :  tensor(2.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[409/468] LOSS : 944.455------ Time : 6-------------------\n",
      "loss :  tensor(2.2962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[410/468] LOSS : 946.751------ Time : 6-------------------\n",
      "loss :  tensor(2.3132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[411/468] LOSS : 949.064------ Time : 6-------------------\n",
      "loss :  tensor(2.3203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[412/468] LOSS : 951.384------ Time : 6-------------------\n",
      "loss :  tensor(2.3268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[413/468] LOSS : 953.711------ Time : 6-------------------\n",
      "loss :  tensor(2.3112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[414/468] LOSS : 956.023------ Time : 6-------------------\n",
      "loss :  tensor(2.3076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[415/468] LOSS : 958.330------ Time : 6-------------------\n",
      "loss :  tensor(2.3243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[416/468] LOSS : 960.654------ Time : 6-------------------\n",
      "loss :  tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[417/468] LOSS : 962.954------ Time : 6-------------------\n",
      "loss :  tensor(2.3134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[418/468] LOSS : 965.267------ Time : 6-------------------\n",
      "loss :  tensor(2.2837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[419/468] LOSS : 967.551------ Time : 6-------------------\n",
      "loss :  tensor(2.3013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[420/468] LOSS : 969.852------ Time : 6-------------------\n",
      "loss :  tensor(2.3161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[421/468] LOSS : 972.169------ Time : 6-------------------\n",
      "loss :  tensor(2.3147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[422/468] LOSS : 974.483------ Time : 6-------------------\n",
      "loss :  tensor(2.3121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[423/468] LOSS : 976.795------ Time : 6-------------------\n",
      "loss :  tensor(2.3166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[424/468] LOSS : 979.112------ Time : 6-------------------\n",
      "loss :  tensor(2.2841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[425/468] LOSS : 981.396------ Time : 6-------------------\n",
      "loss :  tensor(2.2891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[426/468] LOSS : 983.685------ Time : 6-------------------\n",
      "loss :  tensor(2.3197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[427/468] LOSS : 986.005------ Time : 6-------------------\n",
      "loss :  tensor(2.2984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[428/468] LOSS : 988.303------ Time : 6-------------------\n",
      "loss :  tensor(2.2728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[429/468] LOSS : 990.576------ Time : 7-------------------\n",
      "loss :  tensor(2.2957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[430/468] LOSS : 992.872------ Time : 7-------------------\n",
      "loss :  tensor(2.3116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[431/468] LOSS : 995.183------ Time : 7-------------------\n",
      "loss :  tensor(2.2722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[432/468] LOSS : 997.456------ Time : 7-------------------\n",
      "loss :  tensor(2.3292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[433/468] LOSS : 999.785------ Time : 7-------------------\n",
      "loss :  tensor(2.2855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[434/468] LOSS : 1002.070------ Time : 7-------------------\n",
      "loss :  tensor(2.2957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[435/468] LOSS : 1004.366------ Time : 7-------------------\n",
      "loss :  tensor(2.2704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[436/468] LOSS : 1006.636------ Time : 7-------------------\n",
      "loss :  tensor(2.3063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[437/468] LOSS : 1008.943------ Time : 7-------------------\n",
      "loss :  tensor(2.3000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[438/468] LOSS : 1011.243------ Time : 7-------------------\n",
      "loss :  tensor(2.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[439/468] LOSS : 1013.560------ Time : 7-------------------\n",
      "loss :  tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[440/468] LOSS : 1015.857------ Time : 7-------------------\n",
      "loss :  tensor(2.2720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[441/468] LOSS : 1018.129------ Time : 7-------------------\n",
      "loss :  tensor(2.2319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[442/468] LOSS : 1020.361------ Time : 7-------------------\n",
      "loss :  tensor(2.3152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[443/468] LOSS : 1022.676------ Time : 7-------------------\n",
      "loss :  tensor(2.3051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[444/468] LOSS : 1024.981------ Time : 7-------------------\n",
      "loss :  tensor(2.2734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[445/468] LOSS : 1027.254------ Time : 7-------------------\n",
      "loss :  tensor(2.2901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[446/468] LOSS : 1029.544------ Time : 7-------------------\n",
      "loss :  tensor(2.2802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[447/468] LOSS : 1031.825------ Time : 7-------------------\n",
      "loss :  tensor(2.3138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[448/468] LOSS : 1034.138------ Time : 7-------------------\n",
      "loss :  tensor(2.3211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[449/468] LOSS : 1036.459------ Time : 7-------------------\n",
      "loss :  tensor(2.2841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[450/468] LOSS : 1038.744------ Time : 7-------------------\n",
      "loss :  tensor(2.2889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[451/468] LOSS : 1041.032------ Time : 7-------------------\n",
      "loss :  tensor(2.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[452/468] LOSS : 1043.337------ Time : 7-------------------\n",
      "loss :  tensor(2.2776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[453/468] LOSS : 1045.615------ Time : 7-------------------\n",
      "loss :  tensor(2.2800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[454/468] LOSS : 1047.895------ Time : 7-------------------\n",
      "loss :  tensor(2.3430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[455/468] LOSS : 1050.238------ Time : 7-------------------\n",
      "loss :  tensor(2.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[456/468] LOSS : 1052.543------ Time : 7-------------------\n",
      "loss :  tensor(2.3093, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[457/468] LOSS : 1054.852------ Time : 7-------------------\n",
      "loss :  tensor(2.3297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[458/468] LOSS : 1057.182------ Time : 7-------------------\n",
      "loss :  tensor(2.3092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[459/468] LOSS : 1059.491------ Time : 7-------------------\n",
      "loss :  tensor(2.3105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[460/468] LOSS : 1061.802------ Time : 7-------------------\n",
      "loss :  tensor(2.3018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[461/468] LOSS : 1064.104------ Time : 7-------------------\n",
      "loss :  tensor(2.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[462/468] LOSS : 1066.408------ Time : 7-------------------\n",
      "loss :  tensor(2.3037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[463/468] LOSS : 1068.712------ Time : 7-------------------\n",
      "loss :  tensor(2.2793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[464/468] LOSS : 1070.991------ Time : 7-------------------\n",
      "loss :  tensor(2.3323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[465/468] LOSS : 1073.324------ Time : 7-------------------\n",
      "loss :  tensor(2.3150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[466/468] LOSS : 1075.639------ Time : 7-------------------\n",
      "loss :  tensor(2.3073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[467/468] LOSS : 1077.946------ Time : 7-------------------\n",
      "loss :  tensor(2.2572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[468/468] LOSS : 1080.203------ Time : 7-------------------\n",
      "loss :  tensor(2.3213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[469/468] LOSS : 1082.524------ Time : 7-------------------\n",
      "loss :  tensor(2.3047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[470/468] LOSS : 1084.829------ Time : 7-------------------\n",
      "loss :  tensor(2.2933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[471/468] LOSS : 1087.122------ Time : 7-------------------\n",
      "loss :  tensor(2.2893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[472/468] LOSS : 1089.412------ Time : 7-------------------\n",
      "loss :  tensor(2.2750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[473/468] LOSS : 1091.687------ Time : 7-------------------\n",
      "loss :  tensor(2.3090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[474/468] LOSS : 1093.996------ Time : 7-------------------\n",
      "loss :  tensor(2.3411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[475/468] LOSS : 1096.337------ Time : 7-------------------\n",
      "loss :  tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[476/468] LOSS : 1098.634------ Time : 7-------------------\n",
      "loss :  tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[477/468] LOSS : 1100.931------ Time : 7-------------------\n",
      "loss :  tensor(2.3088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[478/468] LOSS : 1103.240------ Time : 7-------------------\n",
      "loss :  tensor(2.3181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[479/468] LOSS : 1105.558------ Time : 7-------------------\n",
      "loss :  tensor(2.3249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[480/468] LOSS : 1107.883------ Time : 7-------------------\n",
      "loss :  tensor(2.2784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[481/468] LOSS : 1110.161------ Time : 7-------------------\n",
      "loss :  tensor(2.2988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[482/468] LOSS : 1112.460------ Time : 7-------------------\n",
      "loss :  tensor(2.3075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[483/468] LOSS : 1114.767------ Time : 7-------------------\n",
      "loss :  tensor(2.3049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[484/468] LOSS : 1117.072------ Time : 7-------------------\n",
      "loss :  tensor(2.2932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[485/468] LOSS : 1119.366------ Time : 7-------------------\n",
      "loss :  tensor(2.2898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[486/468] LOSS : 1121.655------ Time : 7-------------------\n",
      "loss :  tensor(2.2944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[487/468] LOSS : 1123.950------ Time : 7-------------------\n",
      "loss :  tensor(2.3465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[488/468] LOSS : 1126.296------ Time : 7-------------------\n",
      "loss :  tensor(2.3439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[489/468] LOSS : 1128.640------ Time : 7-------------------\n",
      "loss :  tensor(2.2821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[490/468] LOSS : 1130.922------ Time : 7-------------------\n",
      "loss :  tensor(2.2934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[491/468] LOSS : 1133.216------ Time : 7-------------------\n",
      "loss :  tensor(2.3118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[492/468] LOSS : 1135.528------ Time : 7-------------------\n",
      "loss :  tensor(2.3193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[493/468] LOSS : 1137.847------ Time : 7-------------------\n",
      "loss :  tensor(2.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[494/468] LOSS : 1140.148------ Time : 7-------------------\n",
      "loss :  tensor(2.2828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[495/468] LOSS : 1142.430------ Time : 7-------------------\n",
      "loss :  tensor(2.3130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[496/468] LOSS : 1144.743------ Time : 7-------------------\n",
      "loss :  tensor(2.3266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[497/468] LOSS : 1147.070------ Time : 7-------------------\n",
      "loss :  tensor(2.2968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[498/468] LOSS : 1149.367------ Time : 7-------------------\n",
      "loss :  tensor(2.2677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[499/468] LOSS : 1151.635------ Time : 7-------------------\n",
      "loss :  tensor(2.2957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[500/468] LOSS : 1153.930------ Time : 7-------------------\n",
      "loss :  tensor(2.2894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[501/468] LOSS : 1156.220------ Time : 7-------------------\n",
      "loss :  tensor(2.2883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[502/468] LOSS : 1158.508------ Time : 7-------------------\n",
      "loss :  tensor(2.2845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[503/468] LOSS : 1160.793------ Time : 7-------------------\n",
      "loss :  tensor(2.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[504/468] LOSS : 1163.085------ Time : 7-------------------\n",
      "loss :  tensor(2.2476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[505/468] LOSS : 1165.332------ Time : 7-------------------\n",
      "loss :  tensor(2.3223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[506/468] LOSS : 1167.655------ Time : 7-------------------\n",
      "loss :  tensor(2.2537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[507/468] LOSS : 1169.908------ Time : 7-------------------\n",
      "loss :  tensor(2.2671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[508/468] LOSS : 1172.175------ Time : 7-------------------\n",
      "loss :  tensor(2.3678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[509/468] LOSS : 1174.543------ Time : 7-------------------\n",
      "loss :  tensor(2.3063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[510/468] LOSS : 1176.849------ Time : 7-------------------\n",
      "loss :  tensor(2.2875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[511/468] LOSS : 1179.137------ Time : 7-------------------\n",
      "loss :  tensor(2.3161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[512/468] LOSS : 1181.453------ Time : 7-------------------\n",
      "loss :  tensor(2.3356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[513/468] LOSS : 1183.789------ Time : 7-------------------\n",
      "loss :  tensor(2.2715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[514/468] LOSS : 1186.060------ Time : 7-------------------\n",
      "loss :  tensor(2.3152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[515/468] LOSS : 1188.375------ Time : 7-------------------\n",
      "loss :  tensor(2.3152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[516/468] LOSS : 1190.691------ Time : 7-------------------\n",
      "loss :  tensor(2.3306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[517/468] LOSS : 1193.021------ Time : 7-------------------\n",
      "loss :  tensor(2.3366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[518/468] LOSS : 1195.358------ Time : 7-------------------\n",
      "loss :  tensor(2.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[519/468] LOSS : 1197.647------ Time : 7-------------------\n",
      "loss :  tensor(2.3336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[520/468] LOSS : 1199.981------ Time : 7-------------------\n",
      "loss :  tensor(2.2508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[521/468] LOSS : 1202.231------ Time : 7-------------------\n",
      "loss :  tensor(2.2626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[522/468] LOSS : 1204.494------ Time : 7-------------------\n",
      "loss :  tensor(2.2948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[523/468] LOSS : 1206.789------ Time : 7-------------------\n",
      "loss :  tensor(2.3370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[524/468] LOSS : 1209.126------ Time : 7-------------------\n",
      "loss :  tensor(2.3141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[525/468] LOSS : 1211.440------ Time : 7-------------------\n",
      "loss :  tensor(2.3096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[526/468] LOSS : 1213.750------ Time : 7-------------------\n",
      "loss :  tensor(2.3593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[527/468] LOSS : 1216.109------ Time : 7-------------------\n",
      "loss :  tensor(2.3337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[528/468] LOSS : 1218.443------ Time : 7-------------------\n",
      "loss :  tensor(2.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[529/468] LOSS : 1220.731------ Time : 7-------------------\n",
      "loss :  tensor(2.2990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[530/468] LOSS : 1223.030------ Time : 7-------------------\n",
      "loss :  tensor(2.3068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[531/468] LOSS : 1225.337------ Time : 7-------------------\n",
      "loss :  tensor(2.2965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[532/468] LOSS : 1227.633------ Time : 7-------------------\n",
      "loss :  tensor(2.2669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[533/468] LOSS : 1229.900------ Time : 7-------------------\n",
      "loss :  tensor(2.2801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[534/468] LOSS : 1232.180------ Time : 8-------------------\n",
      "loss :  tensor(2.2532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[535/468] LOSS : 1234.433------ Time : 8-------------------\n",
      "loss :  tensor(2.3068, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[536/468] LOSS : 1236.740------ Time : 8-------------------\n",
      "loss :  tensor(2.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[537/468] LOSS : 1239.078------ Time : 8-------------------\n",
      "loss :  tensor(2.3105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[538/468] LOSS : 1241.388------ Time : 8-------------------\n",
      "loss :  tensor(2.2887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[539/468] LOSS : 1243.677------ Time : 8-------------------\n",
      "loss :  tensor(2.3111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[540/468] LOSS : 1245.988------ Time : 8-------------------\n",
      "loss :  tensor(2.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[541/468] LOSS : 1248.272------ Time : 8-------------------\n",
      "loss :  tensor(2.3368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[542/468] LOSS : 1250.609------ Time : 8-------------------\n",
      "loss :  tensor(2.3246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[543/468] LOSS : 1252.933------ Time : 8-------------------\n",
      "loss :  tensor(2.3124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[544/468] LOSS : 1255.246------ Time : 8-------------------\n",
      "loss :  tensor(2.2743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[545/468] LOSS : 1257.520------ Time : 8-------------------\n",
      "loss :  tensor(2.2821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[546/468] LOSS : 1259.802------ Time : 8-------------------\n",
      "loss :  tensor(2.2709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[547/468] LOSS : 1262.073------ Time : 8-------------------\n",
      "loss :  tensor(2.3125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[548/468] LOSS : 1264.385------ Time : 8-------------------\n",
      "loss :  tensor(2.2648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[549/468] LOSS : 1266.650------ Time : 8-------------------\n",
      "loss :  tensor(2.3084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[550/468] LOSS : 1268.958------ Time : 8-------------------\n",
      "loss :  tensor(2.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[551/468] LOSS : 1271.288------ Time : 8-------------------\n",
      "loss :  tensor(2.2277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[552/468] LOSS : 1273.516------ Time : 8-------------------\n",
      "loss :  tensor(2.2889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[553/468] LOSS : 1275.804------ Time : 8-------------------\n",
      "loss :  tensor(2.2829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[554/468] LOSS : 1278.087------ Time : 8-------------------\n",
      "loss :  tensor(2.3151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[555/468] LOSS : 1280.402------ Time : 8-------------------\n",
      "loss :  tensor(2.3092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[556/468] LOSS : 1282.712------ Time : 8-------------------\n",
      "loss :  tensor(2.3176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[557/468] LOSS : 1285.029------ Time : 8-------------------\n",
      "loss :  tensor(2.3067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[558/468] LOSS : 1287.336------ Time : 8-------------------\n",
      "loss :  tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[559/468] LOSS : 1289.661------ Time : 8-------------------\n",
      "loss :  tensor(2.2706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[560/468] LOSS : 1291.932------ Time : 8-------------------\n",
      "loss :  tensor(2.2774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[561/468] LOSS : 1294.209------ Time : 8-------------------\n",
      "loss :  tensor(2.3213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[562/468] LOSS : 1296.530------ Time : 8-------------------\n",
      "loss :  tensor(2.2998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[563/468] LOSS : 1298.830------ Time : 8-------------------\n",
      "loss :  tensor(2.2602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[564/468] LOSS : 1301.090------ Time : 8-------------------\n",
      "loss :  tensor(2.3260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[565/468] LOSS : 1303.416------ Time : 8-------------------\n",
      "loss :  tensor(2.3275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[566/468] LOSS : 1305.744------ Time : 8-------------------\n",
      "loss :  tensor(2.2727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[567/468] LOSS : 1308.016------ Time : 8-------------------\n",
      "loss :  tensor(2.2959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[568/468] LOSS : 1310.312------ Time : 8-------------------\n",
      "loss :  tensor(2.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[569/468] LOSS : 1312.618------ Time : 8-------------------\n",
      "loss :  tensor(2.3429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[570/468] LOSS : 1314.961------ Time : 8-------------------\n",
      "loss :  tensor(2.3139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[571/468] LOSS : 1317.274------ Time : 8-------------------\n",
      "loss :  tensor(2.2925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[572/468] LOSS : 1319.567------ Time : 8-------------------\n",
      "loss :  tensor(2.2885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[573/468] LOSS : 1321.855------ Time : 8-------------------\n",
      "loss :  tensor(2.2995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[574/468] LOSS : 1324.155------ Time : 8-------------------\n",
      "loss :  tensor(2.3010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[575/468] LOSS : 1326.456------ Time : 8-------------------\n",
      "loss :  tensor(2.3056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[576/468] LOSS : 1328.761------ Time : 8-------------------\n",
      "loss :  tensor(2.3167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[577/468] LOSS : 1331.078------ Time : 8-------------------\n",
      "loss :  tensor(2.2916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[578/468] LOSS : 1333.370------ Time : 8-------------------\n",
      "loss :  tensor(2.3126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[579/468] LOSS : 1335.682------ Time : 8-------------------\n",
      "loss :  tensor(2.3183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[580/468] LOSS : 1338.000------ Time : 8-------------------\n",
      "loss :  tensor(2.3224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[581/468] LOSS : 1340.323------ Time : 8-------------------\n",
      "loss :  tensor(2.2743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[582/468] LOSS : 1342.597------ Time : 8-------------------\n",
      "loss :  tensor(2.3192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[583/468] LOSS : 1344.916------ Time : 8-------------------\n",
      "loss :  tensor(2.2822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[584/468] LOSS : 1347.198------ Time : 8-------------------\n",
      "loss :  tensor(2.3138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[585/468] LOSS : 1349.512------ Time : 8-------------------\n",
      "loss :  tensor(2.3077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[586/468] LOSS : 1351.820------ Time : 8-------------------\n",
      "loss :  tensor(2.2893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[587/468] LOSS : 1354.109------ Time : 8-------------------\n",
      "loss :  tensor(2.2981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[588/468] LOSS : 1356.407------ Time : 8-------------------\n",
      "loss :  tensor(2.3028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[589/468] LOSS : 1358.710------ Time : 8-------------------\n",
      "loss :  tensor(2.3213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[590/468] LOSS : 1361.031------ Time : 8-------------------\n",
      "loss :  tensor(2.2872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[591/468] LOSS : 1363.319------ Time : 8-------------------\n",
      "loss :  tensor(2.3241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[592/468] LOSS : 1365.643------ Time : 8-------------------\n",
      "loss :  tensor(2.2671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[593/468] LOSS : 1367.910------ Time : 8-------------------\n",
      "loss :  tensor(2.3355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[594/468] LOSS : 1370.245------ Time : 8-------------------\n",
      "loss :  tensor(2.3058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[595/468] LOSS : 1372.551------ Time : 8-------------------\n",
      "loss :  tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[596/468] LOSS : 1374.858------ Time : 8-------------------\n",
      "loss :  tensor(2.2997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[597/468] LOSS : 1377.157------ Time : 8-------------------\n",
      "loss :  tensor(2.3081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[598/468] LOSS : 1379.465------ Time : 8-------------------\n",
      "loss :  tensor(2.3157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[599/468] LOSS : 1381.781------ Time : 8-------------------\n",
      "loss :  tensor(2.3314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[600/468] LOSS : 1384.113------ Time : 8-------------------\n",
      "loss :  tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[601/468] LOSS : 1386.398------ Time : 8-------------------\n",
      "loss :  tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[602/468] LOSS : 1388.699------ Time : 8-------------------\n",
      "loss :  tensor(2.2666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[603/468] LOSS : 1390.966------ Time : 8-------------------\n",
      "loss :  tensor(2.2990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[604/468] LOSS : 1393.265------ Time : 8-------------------\n",
      "loss :  tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[605/468] LOSS : 1395.590------ Time : 8-------------------\n",
      "loss :  tensor(2.3567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[606/468] LOSS : 1397.946------ Time : 8-------------------\n",
      "loss :  tensor(2.3116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[607/468] LOSS : 1400.258------ Time : 8-------------------\n",
      "loss :  tensor(2.3252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[608/468] LOSS : 1402.583------ Time : 8-------------------\n",
      "loss :  tensor(2.2998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[609/468] LOSS : 1404.883------ Time : 8-------------------\n",
      "loss :  tensor(2.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[610/468] LOSS : 1407.165------ Time : 8-------------------\n",
      "loss :  tensor(2.3094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[611/468] LOSS : 1409.474------ Time : 8-------------------\n",
      "loss :  tensor(2.3354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[612/468] LOSS : 1411.810------ Time : 8-------------------\n",
      "loss :  tensor(2.3283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[613/468] LOSS : 1414.138------ Time : 8-------------------\n",
      "loss :  tensor(2.3335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[614/468] LOSS : 1416.471------ Time : 8-------------------\n",
      "loss :  tensor(2.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[615/468] LOSS : 1418.791------ Time : 8-------------------\n",
      "loss :  tensor(2.2972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[616/468] LOSS : 1421.088------ Time : 8-------------------\n",
      "loss :  tensor(2.3130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[617/468] LOSS : 1423.401------ Time : 8-------------------\n",
      "loss :  tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[618/468] LOSS : 1425.698------ Time : 8-------------------\n",
      "loss :  tensor(2.3051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[619/468] LOSS : 1428.003------ Time : 8-------------------\n",
      "loss :  tensor(2.3042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[620/468] LOSS : 1430.307------ Time : 8-------------------\n",
      "loss :  tensor(2.2908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[621/468] LOSS : 1432.598------ Time : 8-------------------\n",
      "loss :  tensor(2.3083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[622/468] LOSS : 1434.906------ Time : 8-------------------\n",
      "loss :  tensor(2.3012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[623/468] LOSS : 1437.207------ Time : 8-------------------\n",
      "loss :  tensor(2.2913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[624/468] LOSS : 1439.499------ Time : 8-------------------\n",
      "loss :  tensor(2.3239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[625/468] LOSS : 1441.823------ Time : 8-------------------\n",
      "loss :  tensor(2.2927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[626/468] LOSS : 1444.115------ Time : 8-------------------\n",
      "loss :  tensor(2.2950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[627/468] LOSS : 1446.410------ Time : 8-------------------\n",
      "loss :  tensor(2.3004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[628/468] LOSS : 1448.711------ Time : 8-------------------\n",
      "loss :  tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[629/468] LOSS : 1451.011------ Time : 8-------------------\n",
      "loss :  tensor(2.2806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[630/468] LOSS : 1453.292------ Time : 8-------------------\n",
      "loss :  tensor(2.2930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[631/468] LOSS : 1455.585------ Time : 8-------------------\n",
      "loss :  tensor(2.3447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[632/468] LOSS : 1457.930------ Time : 8-------------------\n",
      "loss :  tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[633/468] LOSS : 1460.227------ Time : 8-------------------\n",
      "loss :  tensor(2.2888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[634/468] LOSS : 1462.516------ Time : 8-------------------\n",
      "loss :  tensor(2.3033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[635/468] LOSS : 1464.819------ Time : 8-------------------\n",
      "loss :  tensor(2.2808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[636/468] LOSS : 1467.100------ Time : 8-------------------\n",
      "loss :  tensor(2.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[637/468] LOSS : 1469.411------ Time : 8-------------------\n",
      "loss :  tensor(2.2873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[638/468] LOSS : 1471.698------ Time : 8-------------------\n",
      "loss :  tensor(2.3094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[639/468] LOSS : 1474.007------ Time : 9-------------------\n",
      "loss :  tensor(2.3098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[640/468] LOSS : 1476.317------ Time : 9-------------------\n",
      "loss :  tensor(2.3144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[641/468] LOSS : 1478.631------ Time : 9-------------------\n",
      "loss :  tensor(2.3101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[642/468] LOSS : 1480.941------ Time : 9-------------------\n",
      "loss :  tensor(2.3196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[643/468] LOSS : 1483.261------ Time : 9-------------------\n",
      "loss :  tensor(2.3152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[644/468] LOSS : 1485.576------ Time : 9-------------------\n",
      "loss :  tensor(2.3009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[645/468] LOSS : 1487.877------ Time : 9-------------------\n",
      "loss :  tensor(2.2884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[646/468] LOSS : 1490.165------ Time : 9-------------------\n",
      "loss :  tensor(2.3117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[647/468] LOSS : 1492.477------ Time : 9-------------------\n",
      "loss :  tensor(2.3194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[648/468] LOSS : 1494.797------ Time : 9-------------------\n",
      "loss :  tensor(2.3150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[649/468] LOSS : 1497.111------ Time : 9-------------------\n",
      "loss :  tensor(2.3273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[650/468] LOSS : 1499.439------ Time : 9-------------------\n",
      "loss :  tensor(2.3010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[651/468] LOSS : 1501.740------ Time : 9-------------------\n",
      "loss :  tensor(2.2884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[652/468] LOSS : 1504.028------ Time : 9-------------------\n",
      "loss :  tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[653/468] LOSS : 1506.335------ Time : 9-------------------\n",
      "loss :  tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[654/468] LOSS : 1508.634------ Time : 9-------------------\n",
      "loss :  tensor(2.3036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[655/468] LOSS : 1510.938------ Time : 9-------------------\n",
      "loss :  tensor(2.3217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[656/468] LOSS : 1513.260------ Time : 9-------------------\n",
      "loss :  tensor(2.2947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[657/468] LOSS : 1515.554------ Time : 9-------------------\n",
      "loss :  tensor(2.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[658/468] LOSS : 1517.838------ Time : 9-------------------\n",
      "loss :  tensor(2.3078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[659/468] LOSS : 1520.146------ Time : 9-------------------\n",
      "loss :  tensor(2.2846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[660/468] LOSS : 1522.431------ Time : 9-------------------\n",
      "loss :  tensor(2.2837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[661/468] LOSS : 1524.714------ Time : 9-------------------\n",
      "loss :  tensor(2.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[662/468] LOSS : 1527.007------ Time : 9-------------------\n",
      "loss :  tensor(2.2962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[663/468] LOSS : 1529.303------ Time : 9-------------------\n",
      "loss :  tensor(2.3099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[664/468] LOSS : 1531.613------ Time : 9-------------------\n",
      "loss :  tensor(2.3070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[665/468] LOSS : 1533.920------ Time : 9-------------------\n",
      "loss :  tensor(2.3384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[666/468] LOSS : 1536.258------ Time : 9-------------------\n",
      "loss :  tensor(2.2945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[667/468] LOSS : 1538.553------ Time : 9-------------------\n",
      "loss :  tensor(2.2989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[668/468] LOSS : 1540.852------ Time : 9-------------------\n",
      "loss :  tensor(2.2822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[669/468] LOSS : 1543.134------ Time : 9-------------------\n",
      "loss :  tensor(2.3184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[670/468] LOSS : 1545.452------ Time : 9-------------------\n",
      "loss :  tensor(2.2974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[671/468] LOSS : 1547.750------ Time : 9-------------------\n",
      "loss :  tensor(2.2816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[672/468] LOSS : 1550.031------ Time : 9-------------------\n",
      "loss :  tensor(2.2912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[673/468] LOSS : 1552.323------ Time : 9-------------------\n",
      "loss :  tensor(2.2891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[674/468] LOSS : 1554.612------ Time : 9-------------------\n",
      "loss :  tensor(2.2847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[675/468] LOSS : 1556.896------ Time : 9-------------------\n",
      "loss :  tensor(2.2644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[676/468] LOSS : 1559.161------ Time : 9-------------------\n",
      "loss :  tensor(2.3289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[677/468] LOSS : 1561.490------ Time : 9-------------------\n",
      "loss :  tensor(2.3319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[678/468] LOSS : 1563.822------ Time : 9-------------------\n",
      "loss :  tensor(2.3014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[679/468] LOSS : 1566.123------ Time : 9-------------------\n",
      "loss :  tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[680/468] LOSS : 1568.423------ Time : 9-------------------\n",
      "loss :  tensor(2.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[681/468] LOSS : 1570.752------ Time : 9-------------------\n",
      "loss :  tensor(2.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[682/468] LOSS : 1573.057------ Time : 9-------------------\n",
      "loss :  tensor(2.2880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[683/468] LOSS : 1575.345------ Time : 9-------------------\n",
      "loss :  tensor(2.2980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[684/468] LOSS : 1577.643------ Time : 9-------------------\n",
      "loss :  tensor(2.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[685/468] LOSS : 1579.960------ Time : 9-------------------\n",
      "loss :  tensor(2.3185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[686/468] LOSS : 1582.279------ Time : 9-------------------\n",
      "loss :  tensor(2.3245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[687/468] LOSS : 1584.603------ Time : 9-------------------\n",
      "loss :  tensor(2.2912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[688/468] LOSS : 1586.894------ Time : 9-------------------\n",
      "loss :  tensor(2.2592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[689/468] LOSS : 1589.154------ Time : 9-------------------\n",
      "loss :  tensor(2.3290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[690/468] LOSS : 1591.483------ Time : 9-------------------\n",
      "loss :  tensor(2.2695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[691/468] LOSS : 1593.752------ Time : 9-------------------\n",
      "loss :  tensor(2.3206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[692/468] LOSS : 1596.073------ Time : 9-------------------\n",
      "loss :  tensor(2.2848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[693/468] LOSS : 1598.358------ Time : 9-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  tensor(2.2943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[694/468] LOSS : 1600.652------ Time : 9-------------------\n",
      "loss :  tensor(2.3391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[695/468] LOSS : 1602.991------ Time : 9-------------------\n",
      "loss :  tensor(2.3233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[696/468] LOSS : 1605.314------ Time : 9-------------------\n",
      "loss :  tensor(2.2916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[697/468] LOSS : 1607.606------ Time : 9-------------------\n",
      "loss :  tensor(2.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[698/468] LOSS : 1609.898------ Time : 9-------------------\n",
      "loss :  tensor(2.3092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[699/468] LOSS : 1612.208------ Time : 9-------------------\n",
      "loss :  tensor(2.2703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[700/468] LOSS : 1614.478------ Time : 9-------------------\n",
      "loss :  tensor(2.3121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[701/468] LOSS : 1616.790------ Time : 9-------------------\n",
      "loss :  tensor(2.3198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[702/468] LOSS : 1619.110------ Time : 9-------------------\n",
      "loss :  tensor(2.2862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[703/468] LOSS : 1621.396------ Time : 9-------------------\n",
      "loss :  tensor(2.3026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[704/468] LOSS : 1623.699------ Time : 9-------------------\n",
      "loss :  tensor(2.2709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[705/468] LOSS : 1625.969------ Time : 9-------------------\n",
      "loss :  tensor(2.2988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[706/468] LOSS : 1628.268------ Time : 9-------------------\n",
      "loss :  tensor(2.2741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[707/468] LOSS : 1630.542------ Time : 9-------------------\n",
      "loss :  tensor(2.2934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[708/468] LOSS : 1632.836------ Time : 9-------------------\n",
      "loss :  tensor(2.3324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[709/468] LOSS : 1635.168------ Time : 9-------------------\n",
      "loss :  tensor(2.2670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[710/468] LOSS : 1637.435------ Time : 9-------------------\n",
      "loss :  tensor(2.2871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[711/468] LOSS : 1639.722------ Time : 9-------------------\n",
      "loss :  tensor(2.2838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[712/468] LOSS : 1642.006------ Time : 9-------------------\n",
      "loss :  tensor(2.2608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[713/468] LOSS : 1644.267------ Time : 9-------------------\n",
      "loss :  tensor(2.2958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[714/468] LOSS : 1646.563------ Time : 9-------------------\n",
      "loss :  tensor(2.2865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[715/468] LOSS : 1648.849------ Time : 9-------------------\n",
      "loss :  tensor(2.2872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[716/468] LOSS : 1651.136------ Time : 9-------------------\n",
      "loss :  tensor(2.3441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[717/468] LOSS : 1653.480------ Time : 9-------------------\n",
      "loss :  tensor(2.2816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[718/468] LOSS : 1655.762------ Time : 9-------------------\n",
      "loss :  tensor(2.2978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[719/468] LOSS : 1658.060------ Time : 9-------------------\n",
      "loss :  tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[720/468] LOSS : 1660.351------ Time : 9-------------------\n",
      "loss :  tensor(2.3074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[721/468] LOSS : 1662.658------ Time : 9-------------------\n",
      "loss :  tensor(2.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[722/468] LOSS : 1664.963------ Time : 9-------------------\n",
      "loss :  tensor(2.3061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[723/468] LOSS : 1667.269------ Time : 9-------------------\n",
      "loss :  tensor(2.3352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[724/468] LOSS : 1669.605------ Time : 9-------------------\n",
      "loss :  tensor(2.3143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[725/468] LOSS : 1671.919------ Time : 9-------------------\n",
      "loss :  tensor(2.3044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[726/468] LOSS : 1674.223------ Time : 9-------------------\n",
      "loss :  tensor(2.3187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[727/468] LOSS : 1676.542------ Time : 9-------------------\n",
      "loss :  tensor(2.3208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[728/468] LOSS : 1678.863------ Time : 9-------------------\n",
      "loss :  tensor(2.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[729/468] LOSS : 1681.173------ Time : 9-------------------\n",
      "loss :  tensor(2.3239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[730/468] LOSS : 1683.497------ Time : 9-------------------\n",
      "loss :  tensor(2.3196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[731/468] LOSS : 1685.817------ Time : 9-------------------\n",
      "loss :  tensor(2.3198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[732/468] LOSS : 1688.137------ Time : 9-------------------\n",
      "loss :  tensor(2.2785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[733/468] LOSS : 1690.415------ Time : 9-------------------\n",
      "loss :  tensor(2.3045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[734/468] LOSS : 1692.720------ Time : 9-------------------\n",
      "loss :  tensor(2.2879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[735/468] LOSS : 1695.008------ Time : 9-------------------\n",
      "loss :  tensor(2.3216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[736/468] LOSS : 1697.329------ Time : 9-------------------\n",
      "loss :  tensor(2.3088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[737/468] LOSS : 1699.638------ Time : 9-------------------\n",
      "loss :  tensor(2.2952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[738/468] LOSS : 1701.933------ Time : 9-------------------\n",
      "loss :  tensor(2.3086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[739/468] LOSS : 1704.242------ Time : 9-------------------\n",
      "loss :  tensor(2.2832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[740/468] LOSS : 1706.525------ Time : 9-------------------\n",
      "loss :  tensor(2.3428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[741/468] LOSS : 1708.868------ Time : 9-------------------\n",
      "loss :  tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[742/468] LOSS : 1711.154------ Time : 10-------------------\n",
      "loss :  tensor(2.3095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[743/468] LOSS : 1713.463------ Time : 10-------------------\n",
      "loss :  tensor(2.3152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[744/468] LOSS : 1715.778------ Time : 10-------------------\n",
      "loss :  tensor(2.3210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[745/468] LOSS : 1718.099------ Time : 10-------------------\n",
      "loss :  tensor(2.2763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[746/468] LOSS : 1720.376------ Time : 10-------------------\n",
      "loss :  tensor(2.2838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[747/468] LOSS : 1722.659------ Time : 10-------------------\n",
      "loss :  tensor(2.3176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[748/468] LOSS : 1724.977------ Time : 10-------------------\n",
      "loss :  tensor(2.2846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[749/468] LOSS : 1727.262------ Time : 10-------------------\n",
      "loss :  tensor(2.3079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[750/468] LOSS : 1729.570------ Time : 10-------------------\n",
      "loss :  tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[751/468] LOSS : 1731.869------ Time : 10-------------------\n",
      "loss :  tensor(2.3069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[752/468] LOSS : 1734.176------ Time : 10-------------------\n",
      "loss :  tensor(2.3082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[753/468] LOSS : 1736.484------ Time : 10-------------------\n",
      "loss :  tensor(2.3049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[754/468] LOSS : 1738.789------ Time : 10-------------------\n",
      "loss :  tensor(2.2940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[755/468] LOSS : 1741.083------ Time : 10-------------------\n",
      "loss :  tensor(2.3285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[756/468] LOSS : 1743.412------ Time : 10-------------------\n",
      "loss :  tensor(2.2982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[757/468] LOSS : 1745.710------ Time : 10-------------------\n",
      "loss :  tensor(2.3163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[758/468] LOSS : 1748.026------ Time : 10-------------------\n",
      "loss :  tensor(2.3351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[759/468] LOSS : 1750.361------ Time : 10-------------------\n",
      "loss :  tensor(2.3050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[760/468] LOSS : 1752.666------ Time : 10-------------------\n",
      "loss :  tensor(2.3079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[761/468] LOSS : 1754.974------ Time : 10-------------------\n",
      "loss :  tensor(2.3020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[762/468] LOSS : 1757.276------ Time : 10-------------------\n",
      "loss :  tensor(2.3034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[763/468] LOSS : 1759.580------ Time : 10-------------------\n",
      "loss :  tensor(2.3357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[764/468] LOSS : 1761.915------ Time : 10-------------------\n",
      "loss :  tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[765/468] LOSS : 1764.215------ Time : 10-------------------\n",
      "loss :  tensor(2.2938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[766/468] LOSS : 1766.509------ Time : 10-------------------\n",
      "loss :  tensor(2.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[767/468] LOSS : 1768.820------ Time : 10-------------------\n",
      "loss :  tensor(2.2889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[768/468] LOSS : 1771.109------ Time : 10-------------------\n",
      "loss :  tensor(2.2971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[769/468] LOSS : 1773.406------ Time : 10-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  tensor(2.3402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[770/468] LOSS : 1775.746------ Time : 10-------------------\n",
      "loss :  tensor(2.3033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[771/468] LOSS : 1778.049------ Time : 10-------------------\n",
      "loss :  tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[772/468] LOSS : 1780.345------ Time : 10-------------------\n",
      "loss :  tensor(2.3038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[773/468] LOSS : 1782.648------ Time : 10-------------------\n",
      "loss :  tensor(2.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[774/468] LOSS : 1784.949------ Time : 10-------------------\n",
      "loss :  tensor(2.2944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[775/468] LOSS : 1787.243------ Time : 10-------------------\n",
      "loss :  tensor(2.2989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[776/468] LOSS : 1789.542------ Time : 10-------------------\n",
      "loss :  tensor(2.3086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[777/468] LOSS : 1791.851------ Time : 10-------------------\n",
      "loss :  tensor(2.2795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[778/468] LOSS : 1794.130------ Time : 10-------------------\n",
      "loss :  tensor(2.2803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[779/468] LOSS : 1796.411------ Time : 10-------------------\n",
      "loss :  tensor(2.2845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[780/468] LOSS : 1798.695------ Time : 10-------------------\n",
      "loss :  tensor(2.3060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[781/468] LOSS : 1801.001------ Time : 10-------------------\n",
      "loss :  tensor(2.2704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[782/468] LOSS : 1803.272------ Time : 10-------------------\n",
      "loss :  tensor(2.2644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[783/468] LOSS : 1805.536------ Time : 10-------------------\n",
      "loss :  tensor(2.3180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[784/468] LOSS : 1807.854------ Time : 10-------------------\n",
      "loss :  tensor(2.2959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[785/468] LOSS : 1810.150------ Time : 10-------------------\n",
      "loss :  tensor(2.3072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[786/468] LOSS : 1812.457------ Time : 10-------------------\n",
      "loss :  tensor(2.3554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[787/468] LOSS : 1814.812------ Time : 10-------------------\n",
      "loss :  tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[788/468] LOSS : 1817.137------ Time : 10-------------------\n",
      "loss :  tensor(2.3369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[789/468] LOSS : 1819.474------ Time : 10-------------------\n",
      "loss :  tensor(2.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[790/468] LOSS : 1821.793------ Time : 10-------------------\n",
      "loss :  tensor(2.3012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[791/468] LOSS : 1824.095------ Time : 10-------------------\n",
      "loss :  tensor(2.2933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[792/468] LOSS : 1826.388------ Time : 10-------------------\n",
      "loss :  tensor(2.2967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[793/468] LOSS : 1828.685------ Time : 10-------------------\n",
      "loss :  tensor(2.2914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[794/468] LOSS : 1830.976------ Time : 10-------------------\n",
      "loss :  tensor(2.2864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[795/468] LOSS : 1833.262------ Time : 10-------------------\n",
      "loss :  tensor(2.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[796/468] LOSS : 1835.555------ Time : 10-------------------\n",
      "loss :  tensor(2.2868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[797/468] LOSS : 1837.842------ Time : 10-------------------\n",
      "loss :  tensor(2.3213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[798/468] LOSS : 1840.163------ Time : 10-------------------\n",
      "loss :  tensor(2.3196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[799/468] LOSS : 1842.483------ Time : 10-------------------\n",
      "loss :  tensor(2.3025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[800/468] LOSS : 1844.785------ Time : 10-------------------\n",
      "loss :  tensor(2.3241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[801/468] LOSS : 1847.109------ Time : 10-------------------\n",
      "loss :  tensor(2.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[802/468] LOSS : 1849.401------ Time : 10-------------------\n",
      "loss :  tensor(2.3072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[803/468] LOSS : 1851.708------ Time : 10-------------------\n",
      "loss :  tensor(2.2972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[804/468] LOSS : 1854.005------ Time : 10-------------------\n",
      "loss :  tensor(2.3414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[805/468] LOSS : 1856.347------ Time : 10-------------------\n",
      "loss :  tensor(2.3472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[806/468] LOSS : 1858.694------ Time : 10-------------------\n",
      "loss :  tensor(2.3174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[807/468] LOSS : 1861.011------ Time : 10-------------------\n",
      "loss :  tensor(2.3290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[808/468] LOSS : 1863.340------ Time : 10-------------------\n",
      "loss :  tensor(2.3038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[809/468] LOSS : 1865.644------ Time : 10-------------------\n",
      "loss :  tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[810/468] LOSS : 1867.951------ Time : 10-------------------\n",
      "loss :  tensor(2.2829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[811/468] LOSS : 1870.234------ Time : 10-------------------\n",
      "loss :  tensor(2.2836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[812/468] LOSS : 1872.517------ Time : 10-------------------\n",
      "loss :  tensor(2.2839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[813/468] LOSS : 1874.801------ Time : 10-------------------\n",
      "loss :  tensor(2.3104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[814/468] LOSS : 1877.112------ Time : 10-------------------\n",
      "loss :  tensor(2.2909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[815/468] LOSS : 1879.402------ Time : 10-------------------\n",
      "loss :  tensor(2.2866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[816/468] LOSS : 1881.689------ Time : 10-------------------\n",
      "loss :  tensor(2.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[817/468] LOSS : 1883.971------ Time : 10-------------------\n",
      "loss :  tensor(2.3263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[818/468] LOSS : 1886.297------ Time : 10-------------------\n",
      "loss :  tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[819/468] LOSS : 1888.598------ Time : 10-------------------\n",
      "loss :  tensor(2.3025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[820/468] LOSS : 1890.900------ Time : 10-------------------\n",
      "loss :  tensor(2.3123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[821/468] LOSS : 1893.213------ Time : 10-------------------\n",
      "loss :  tensor(2.3087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[822/468] LOSS : 1895.521------ Time : 10-------------------\n",
      "loss :  tensor(2.3109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[823/468] LOSS : 1897.832------ Time : 10-------------------\n",
      "loss :  tensor(2.2936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[824/468] LOSS : 1900.126------ Time : 10-------------------\n",
      "loss :  tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[825/468] LOSS : 1902.432------ Time : 10-------------------\n",
      "loss :  tensor(2.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[826/468] LOSS : 1904.752------ Time : 10-------------------\n",
      "loss :  tensor(2.3253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[827/468] LOSS : 1907.078------ Time : 10-------------------\n",
      "loss :  tensor(2.3008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[828/468] LOSS : 1909.379------ Time : 10-------------------\n",
      "loss :  tensor(2.3192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[829/468] LOSS : 1911.698------ Time : 10-------------------\n",
      "loss :  tensor(2.2984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[830/468] LOSS : 1913.996------ Time : 10-------------------\n",
      "loss :  tensor(2.2877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[831/468] LOSS : 1916.284------ Time : 10-------------------\n",
      "loss :  tensor(2.3144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[832/468] LOSS : 1918.598------ Time : 10-------------------\n",
      "loss :  tensor(2.3371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[833/468] LOSS : 1920.935------ Time : 10-------------------\n",
      "loss :  tensor(2.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[834/468] LOSS : 1923.241------ Time : 10-------------------\n",
      "loss :  tensor(2.2986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[835/468] LOSS : 1925.539------ Time : 10-------------------\n",
      "loss :  tensor(2.2875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[836/468] LOSS : 1927.827------ Time : 10-------------------\n",
      "loss :  tensor(2.3071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[837/468] LOSS : 1930.134------ Time : 10-------------------\n",
      "loss :  tensor(2.3085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[838/468] LOSS : 1932.442------ Time : 10-------------------\n",
      "loss :  tensor(2.2983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[839/468] LOSS : 1934.741------ Time : 10-------------------\n",
      "loss :  tensor(2.2960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[840/468] LOSS : 1937.037------ Time : 10-------------------\n",
      "loss :  tensor(2.2986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[841/468] LOSS : 1939.335------ Time : 10-------------------\n",
      "loss :  tensor(2.3058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[842/468] LOSS : 1941.641------ Time : 10-------------------\n",
      "loss :  tensor(2.2860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[843/468] LOSS : 1943.927------ Time : 10-------------------\n",
      "loss :  tensor(2.3190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[844/468] LOSS : 1946.246------ Time : 10-------------------\n",
      "loss :  tensor(2.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[845/468] LOSS : 1948.551------ Time : 11-------------------\n",
      "loss :  tensor(2.2637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[846/468] LOSS : 1950.815------ Time : 11-------------------\n",
      "loss :  tensor(2.3237, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]-----[847/468] LOSS : 1953.139------ Time : 11-------------------\n",
      "loss :  tensor(2.2999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[848/468] LOSS : 1955.439------ Time : 11-------------------\n",
      "loss :  tensor(2.3367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[849/468] LOSS : 1957.776------ Time : 11-------------------\n",
      "loss :  tensor(2.2702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[850/468] LOSS : 1960.046------ Time : 11-------------------\n",
      "loss :  tensor(2.3153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[851/468] LOSS : 1962.361------ Time : 11-------------------\n",
      "loss :  tensor(2.2799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[852/468] LOSS : 1964.641------ Time : 11-------------------\n",
      "loss :  tensor(2.3238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[853/468] LOSS : 1966.965------ Time : 11-------------------\n",
      "loss :  tensor(2.3261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[854/468] LOSS : 1969.291------ Time : 11-------------------\n",
      "loss :  tensor(2.2976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[855/468] LOSS : 1971.589------ Time : 11-------------------\n",
      "loss :  tensor(2.3079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[856/468] LOSS : 1973.896------ Time : 11-------------------\n",
      "loss :  tensor(2.3111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[857/468] LOSS : 1976.208------ Time : 11-------------------\n",
      "loss :  tensor(2.2967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[858/468] LOSS : 1978.504------ Time : 11-------------------\n",
      "loss :  tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[859/468] LOSS : 1980.790------ Time : 11-------------------\n",
      "loss :  tensor(2.2924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[860/468] LOSS : 1983.082------ Time : 11-------------------\n",
      "loss :  tensor(2.3034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[861/468] LOSS : 1985.386------ Time : 11-------------------\n",
      "loss :  tensor(2.3109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[862/468] LOSS : 1987.697------ Time : 11-------------------\n",
      "loss :  tensor(2.2866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[863/468] LOSS : 1989.983------ Time : 11-------------------\n",
      "loss :  tensor(2.2967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[864/468] LOSS : 1992.280------ Time : 11-------------------\n",
      "loss :  tensor(2.2719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[865/468] LOSS : 1994.552------ Time : 11-------------------\n",
      "loss :  tensor(2.2905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[866/468] LOSS : 1996.842------ Time : 11-------------------\n",
      "loss :  tensor(2.3306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[867/468] LOSS : 1999.173------ Time : 11-------------------\n",
      "loss :  tensor(2.3144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[868/468] LOSS : 2001.487------ Time : 11-------------------\n",
      "loss :  tensor(2.3151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[869/468] LOSS : 2003.802------ Time : 11-------------------\n",
      "loss :  tensor(2.3247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[870/468] LOSS : 2006.127------ Time : 11-------------------\n",
      "loss :  tensor(2.2811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[871/468] LOSS : 2008.408------ Time : 11-------------------\n",
      "loss :  tensor(2.3078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[872/468] LOSS : 2010.716------ Time : 11-------------------\n",
      "loss :  tensor(2.2835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[873/468] LOSS : 2012.999------ Time : 11-------------------\n",
      "loss :  tensor(2.3309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[874/468] LOSS : 2015.330------ Time : 11-------------------\n",
      "loss :  tensor(2.2773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[875/468] LOSS : 2017.608------ Time : 11-------------------\n",
      "loss :  tensor(2.3261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[876/468] LOSS : 2019.934------ Time : 11-------------------\n",
      "loss :  tensor(2.2991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[877/468] LOSS : 2022.233------ Time : 11-------------------\n",
      "loss :  tensor(2.2752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[878/468] LOSS : 2024.508------ Time : 11-------------------\n",
      "loss :  tensor(2.3275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[879/468] LOSS : 2026.835------ Time : 11-------------------\n",
      "loss :  tensor(2.3015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[880/468] LOSS : 2029.137------ Time : 11-------------------\n",
      "loss :  tensor(2.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[881/468] LOSS : 2031.416------ Time : 11-------------------\n",
      "loss :  tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[882/468] LOSS : 2033.713------ Time : 11-------------------\n",
      "loss :  tensor(2.2615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[883/468] LOSS : 2035.974------ Time : 11-------------------\n",
      "loss :  tensor(2.3134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[884/468] LOSS : 2038.288------ Time : 11-------------------\n",
      "loss :  tensor(2.2755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[885/468] LOSS : 2040.563------ Time : 11-------------------\n",
      "loss :  tensor(2.3243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[886/468] LOSS : 2042.887------ Time : 11-------------------\n",
      "loss :  tensor(2.3093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[887/468] LOSS : 2045.197------ Time : 11-------------------\n",
      "loss :  tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[888/468] LOSS : 2047.500------ Time : 11-------------------\n",
      "loss :  tensor(2.3015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[889/468] LOSS : 2049.801------ Time : 11-------------------\n",
      "loss :  tensor(2.2927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[890/468] LOSS : 2052.094------ Time : 11-------------------\n",
      "loss :  tensor(2.2639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[891/468] LOSS : 2054.358------ Time : 11-------------------\n",
      "loss :  tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[892/468] LOSS : 2056.653------ Time : 11-------------------\n",
      "loss :  tensor(2.2908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[893/468] LOSS : 2058.944------ Time : 11-------------------\n",
      "loss :  tensor(2.2831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[894/468] LOSS : 2061.227------ Time : 11-------------------\n",
      "loss :  tensor(2.3189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[895/468] LOSS : 2063.546------ Time : 11-------------------\n",
      "loss :  tensor(2.2963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[896/468] LOSS : 2065.842------ Time : 11-------------------\n",
      "loss :  tensor(2.3356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[897/468] LOSS : 2068.178------ Time : 11-------------------\n",
      "loss :  tensor(2.2845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[898/468] LOSS : 2070.462------ Time : 11-------------------\n",
      "loss :  tensor(2.3253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[899/468] LOSS : 2072.787------ Time : 11-------------------\n",
      "loss :  tensor(2.2906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[900/468] LOSS : 2075.078------ Time : 11-------------------\n",
      "loss :  tensor(2.2990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[901/468] LOSS : 2077.377------ Time : 11-------------------\n",
      "loss :  tensor(2.3100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[902/468] LOSS : 2079.687------ Time : 11-------------------\n",
      "loss :  tensor(2.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[903/468] LOSS : 2081.991------ Time : 11-------------------\n",
      "loss :  tensor(2.2865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[904/468] LOSS : 2084.278------ Time : 11-------------------\n",
      "loss :  tensor(2.2812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[905/468] LOSS : 2086.559------ Time : 11-------------------\n",
      "loss :  tensor(2.2557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[906/468] LOSS : 2088.815------ Time : 11-------------------\n",
      "loss :  tensor(2.2968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/1]-----[907/468] LOSS : 2091.112------ Time : 11-------------------\n",
      "loss :  tensor(2.2868, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2d0f3c9afa8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "import time\n",
    "\n",
    "EPOCH = 1\n",
    "\n",
    "for e in range(1, EPOCH+1):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        print('-------------------')\n",
    "        print('loss : ', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss\n",
    "        now = time.time()\n",
    "        print('\\r[%d/%d]-----[%d/%d] LOSS : %.3f------ Time : %d' \n",
    "              %(e, EPOCH, i, 60000/128, running_loss, now - start_time), end = '')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
