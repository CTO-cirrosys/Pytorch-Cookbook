{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification MNSIT Datasets\n",
    "- 로컬 컴퓨터를 이용할 때는 에폭을 낮게 지정(단지 실행이 되는지만 확인)\n",
    "- Kaggle이나 gcp를 이용할 때는 GPU를 사용하여 실제 훈련 실시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:42:58.574784Z",
     "start_time": "2019-11-10T04:42:55.371996Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets 다운로드 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:42:58.903555Z",
     "start_time": "2019-11-10T04:42:58.661688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0], std=[1])\n",
      "           )\n",
      "****************************************************************************************************\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0], std=[1])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Dataset & DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0], [1])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root = './data', train = True,\n",
    "                                      download = True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 128,\n",
    "                                          shuffle = True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root = './data', train = False,\n",
    "                                     download = True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 128,\n",
    "                                         shuffle = True, num_workers=1)\n",
    "\n",
    "classes = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "\n",
    "print(trainset)\n",
    "print('*'*100)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:43:01.651424Z",
     "start_time": "2019-11-10T04:42:58.954198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization Datasets\n",
    "\n",
    "def show(img):\n",
    "    print(img.size())\n",
    "    grid = torchvision.utils.make_grid(img, padding = 0) # make_grid 함수는 3채널로 만든다(모두 같은 format으로)\n",
    "    print(grid.size())\n",
    "    tranimg = grid.permute(1,2,0)\n",
    "    print(tranimg.size())\n",
    "    plt.imshow(tranimg, aspect = 'auto')\n",
    "\n",
    "images, labels = iter(trainloader).next()\n",
    "show(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:43:01.853310Z",
     "start_time": "2019-11-10T04:43:01.727381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make Model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 7, padding = 3)\n",
    "        self.conv2 = nn.Conv2d(10, 50, 7, padding = 3)\n",
    "        self.conv3 = nn.Conv2d(50, 120, 7, padding = 3)\n",
    "        self.conv4 = nn.Conv2d(120, 100, 5)\n",
    "        self.conv5 = nn.Conv2d(100, 20, 5)\n",
    "        self.conv6 = nn.Conv2d(20, 10, 5)\n",
    "        self.conv7 = nn.Conv2d(10, 10, 3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(10 * 8 * 8, 120)\n",
    "        self.fc2 = nn.Linear(120, 360)\n",
    "        self.fc3 = nn.Linear(360, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # 28 28\n",
    "        x = F.relu(self.conv2(x)) # 28 28\n",
    "        x = F.relu(self.conv3(x)) # 28 28\n",
    "        x = F.relu(self.conv4(x)) # 24 24\n",
    "        x = F.relu(self.conv5(x)) # 20 20\n",
    "        x = self.pool(F.relu(self.conv6(x))) # 8 8\n",
    "        x = x.view(-1, 10 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 사용 여부 판단하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:50:52.350152Z",
     "start_time": "2019-11-10T04:50:52.337158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GPU 사용여부 판단\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('We can use GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('We can use CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 및 Optimizer 생성\n",
    "- Model Parameters 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:54:46.552946Z",
     "start_time": "2019-11-10T04:54:46.523966Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "print(loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:57:39.459212Z",
     "start_time": "2019-11-10T04:57:39.379256Z"
    }
   },
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 작동상태 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:56:08.994704Z",
     "start_time": "2019-11-10T04:56:04.742141Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels = next(iter(trainloader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    print(images.size())\n",
    "    example = model(images)\n",
    "    print('Test : ', example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T05:05:42.807684Z",
     "start_time": "2019-11-10T05:05:06.793637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "import time\n",
    "\n",
    "EPOCH = 1\n",
    "\n",
    "for e in range(1, EPOCH+1):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss\n",
    "        now = time.time()\n",
    "        print('\\r[%d/%d]-----[%d/%d] LOSS : %.3f------ Time : %d' \n",
    "              %(e, EPOCH, i, 60000/128, running_loss, now - start_time), end = '')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'data/mnist_classifier.pth')\n",
    "test_model = torch.load('data/mnist_classifier.pth')\n",
    "test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측이 작동하는지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = 8,\n",
    "                                         shuffle = True, num_workers=1)\n",
    "    test_data = iter(testloader)\n",
    "    test_images, test_labels = test_data.next()\n",
    "    show(test_images)\n",
    "    test_images, test_labels = test_images.cuda(), test_labels.cuda()\n",
    "    \n",
    "    test_outputs = test_model(test_images)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    \n",
    "    \n",
    "    print('GroundTruth : ', ' '.join(classes[test_labels[j]] for j in range(8)))\n",
    "    print('Predicted : ', ' '.join(classes[predicted[i]] for i in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 성능 시험하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T05:19:20.849947Z",
     "start_time": "2019-11-10T05:19:16.564408Z"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        val_images, val_labels = data\n",
    "        val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "        \n",
    "        val_outputs = model(val_images)\n",
    "        #_, val_predicted = torch.max(val_outputs.data, 1)  # 이것 보다는\n",
    "        pred = val_outputs.argmax(dim=1, keepdim=True)\n",
    "        #correct += (val_predicted == val_labels).sum().item() # 이것 보다는\n",
    "        correct += pred\n",
    "print('Accuracy of the network on the 10000 test images : %.3f %%' %(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:18:04.156820Z",
     "start_time": "2019-11-10T06:18:04.135837Z"
    }
   },
   "outputs": [],
   "source": [
    "isinstance(Net(), nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:37:38.144097Z",
     "start_time": "2019-11-10T06:37:38.137104Z"
    }
   },
   "outputs": [],
   "source": [
    "type(nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:39:39.769421Z",
     "start_time": "2019-11-10T06:39:39.760411Z"
    }
   },
   "outputs": [],
   "source": [
    "type(nn.Conv2d(1, 10, 7)) == nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:39:32.469584Z",
     "start_time": "2019-11-10T06:39:32.462592Z"
    }
   },
   "outputs": [],
   "source": [
    "type(model.conv1) == nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.conv1 = nn.Conv2d(1, 10, 7, padding = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:50:15.541084Z",
     "start_time": "2019-11-10T06:50:15.536091Z"
    }
   },
   "outputs": [],
   "source": [
    "a = 10\n",
    "if a == (9 or 10):\n",
    "    print('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:52:37.047997Z",
     "start_time": "2019-11-10T06:52:36.983033Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if ((type(m) == nn.Conv2d) or (type(m) == nn.Linear)):\n",
    "        print('0')\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "model.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:41:21.984827Z",
     "start_time": "2019-11-10T06:41:21.971835Z"
    }
   },
   "outputs": [],
   "source": [
    "nn.init.xavier_normal(torch.zeros(3,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
