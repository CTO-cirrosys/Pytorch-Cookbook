{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Pytorch Chapter 3 : Neural Networks\n",
    "https://9bow.github.io/PyTorch-tutorials-kr-0.3.1/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "- torch.nn 패키지를 이용한다.\n",
    "- nn은 모델을 정의하고 미분할 때 autograd를 사용한다.\n",
    "- 숫자 이미지를 분류하는 신경망을 예제로 실습한다.\n",
    "![nn_example](image/nn_example.png)\n",
    "- feed-forward-network(입력을 받아 여러 계층을 차례로 전달한 후 최종 출력하는 과정)\n",
    "\n",
    "## Process of train neural network\n",
    "1. 학습 가능한 매개변수(or 가중치)를 갖는 신경망을 정의\n",
    "2. 데이터셋 입력을 반복\n",
    "3. 입력을 신경망에서 처리(계산)\n",
    "4. 손실(loss, 정답과 얼마나 다른지)을 계산\n",
    "5. 변화도(gradiant, 기울기)를 신경망의 매개변수들에게 역으로 전파(역전파)\n",
    "6. 신경망의 가중치 갱신\n",
    "![weight_formula](image/weight_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Neural Network\n",
    "1. nn.Conv2d()\n",
    " ![conv2d](image/conv2d_explain.png)\n",
    " - 입력값의 채널 수는 filter의 개수와 같다.(ex. RGB(3개) = filter 3개)\n",
    " - in_channels : 입력값의 채널 수(= filter의 개수)\n",
    " - out_chnnels : 출력값의 채널 수(= filter 묶음(입력값의 채널 수)의 개수) \n",
    " \n",
    "2. nn.Linear()\n",
    " ![linear](image/linear_explain.png)\n",
    " - Kears의 dense와 같은 역할\n",
    " - flatten을 해줘야 적용이 가능함(1차원으로 펴버리기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 in_channel, 6 out_channel, 5 x 5 filter\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 사각형이면 그냥 숫자만 적어도 됨\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- forward 함수만 저의하면 backward(변화도를 계산하는 함수)sms autograd를 사용하여<br> 자동으로 정의된다. forward 함수에서는 어떠한 Tensor연산을 사용해도 된다.\n",
    "\n",
    "### 모델의 학습 가능한 매개변수들 확인\n",
    "- 매 학습마다 갱신되는 매개변수들(가중치)\n",
    "- 필터의 사이즈, 개수 등\n",
    "- channel의 개수\n",
    "- linear의 노드 개수 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "- 위에서 정의한 신경망(LeNet)의 입력은 32x32다.\n",
    "- MNIST 데이터셋을 사용하기 위해서는 입력 데이터를 32x32의 크기로 바꿔야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1530, -0.2315,  0.3958,  ...,  0.1192,  0.1148,  0.5588],\n",
       "          [ 0.5073,  0.0241, -0.9834,  ..., -0.8436,  0.4634, -0.6591],\n",
       "          [ 0.0606, -0.2803, -1.5516,  ..., -0.5638, -0.4434,  2.0210],\n",
       "          ...,\n",
       "          [ 1.2012, -0.6769, -0.6062,  ...,  1.8109, -0.4125,  1.8415],\n",
       "          [ 2.7800, -1.1861, -0.5775,  ..., -0.6046, -1.5729,  0.5226],\n",
       "          [-0.9175, -1.1226, -0.0238,  ..., -0.5195, -0.4093, -0.0698]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1,1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1249,  0.0288,  0.0351, -0.0150, -0.0178,  0.1136,  0.0241, -0.0171,\n",
      "         -0.0882,  0.1407]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "output = net(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파\n",
    "- 모든 매개변수의 변화도 버퍼(gradient buffer)를 0으로 초기화\n",
    "- 무작위 값으로 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "output.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "### 1. what is super()?\n",
    "- 클래스가 여러 클래스들에 대해 서로서로 상속을 받은 상태일 때,<br>\n",
    "최상위 클라스의 생성자가 각각의 클래스에 대해 중복해서 출력되기 때문에<br>\n",
    "이를 방지하기 위해 최상단 부모 클래스를 한 번만 호출하도록 하는 함수\n",
    "- 참고http://bluese05.tistory.com/5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
