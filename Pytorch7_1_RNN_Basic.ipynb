{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with a single Neuron\n",
    "- 싱글 뉴런이란게 hidden이 1개라는건지 hidden의 size가 1이라는건지.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:57:09.239737Z",
     "start_time": "2018-12-09T16:57:07.226324Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T17:45:28.480680Z",
     "start_time": "2018-12-09T17:45:28.443745Z"
    }
   },
   "outputs": [],
   "source": [
    "# single RNN\n",
    "\n",
    "class SingleRNN(nn.Module):\n",
    "    def __init__(self, input_size, neurons_size):\n",
    "        super(SingleRNN, self).__init__() # 상위 클래스로 설정 -> nn.Moudle안에 있는 부모 class중 가장 위로 올린다.\n",
    "        \n",
    "        self.Wx = torch.randn(input_size, neurons_size) # 4 x 1 -> weight값\n",
    "        self.Wy = torch.randn(neurons_size, neurons_size) # 1 x 1 -> weight값\n",
    "        \n",
    "        self.b = torch.zeros(1,neurons_size) # 1 x 4 -> bias값\n",
    "        \n",
    "    def forward(self, x0, x1):\n",
    "        self.Y0 = torch.tanh(torch.mm(x0, self.Wx) + self.b) # 4 x 1 -> x와 weight값 내적\n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) + \n",
    "                            torch.mm(x1, self.Wx) + self.b) # 4 x 1 -> x와 weight값 내적\n",
    "        \n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:01:05.908466Z",
     "start_time": "2018-12-09T18:01:05.896488Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch로 입력 -> 한 번에 4개씩\n",
    "x0_batch = torch.tensor([[0,1,2,0],\n",
    "                         [3,4,5,0],\n",
    "                         [6,7,8,0],\n",
    "                         [9,0,1,0]], dtype = torch.float) # 4 x 4\n",
    "\n",
    "x1_batch = torch.tensor([[9,8,7,0], \n",
    "                         [0,0,0,0], \n",
    "                         [6,5,4,0], \n",
    "                         [3,2,1,0]], dtype = torch.float) # 4 x 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T17:59:23.681688Z",
     "start_time": "2018-12-09T17:59:23.672206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleRNN()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 4\n",
    "neurons_size = 1\n",
    "model = SingleRNN(input_size, neurons_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T17:59:33.892611Z",
     "start_time": "2018-12-09T17:59:33.881632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9735],\n",
       "        [ 0.9999],\n",
       "        [ 1.0000],\n",
       "        [-1.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y0_val, Y1_val = model(x0_batch, x1_batch)\n",
    "Y0_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:00:39.394871Z",
     "start_time": "2018-12-09T18:00:39.385388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Wx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:01:07.540932Z",
     "start_time": "2018-12-09T18:01:07.532451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0_batch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with Multi Neurons\n",
    "Basic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:46:18.655903Z",
     "start_time": "2018-12-09T18:46:18.612985Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, input_size, neurons_size):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        \n",
    "        self.Wx = torch.randn(input_size, neurons_size)\n",
    "        self.Wy = torch.randn(neurons_size, neurons_size)\n",
    "        \n",
    "        self.b = torch.randn(1, neurons_size)\n",
    "        \n",
    "    def forward(self, x0, x1):\n",
    "        self.Y0 = torch.tanh(torch.mm(x0, self.Wx) + self.b)\n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) + \n",
    "                            torch.mm(x1, self.Wx) + self.b)\n",
    "        \n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:46:57.706346Z",
     "start_time": "2018-12-09T18:46:57.695367Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "neurons_size = 5\n",
    "\n",
    "X0_batch = torch.tensor([[0,1,2], \n",
    "                         [3,4,5], \n",
    "                         [6,7,8], \n",
    "                         [9,0,1]], dtype = torch.float) #t=0 => 4 X 3\n",
    "\n",
    "X1_batch = torch.tensor([[9,8,7], \n",
    "                         [0,0,0], \n",
    "                         [6,5,4], \n",
    "                         [3,2,1]], dtype = torch.float) #t=1 => 4 X 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:48:11.713935Z",
     "start_time": "2018-12-09T18:48:11.703455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicRNN()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicRNN(input_size, neurons_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:48:34.201433Z",
     "start_time": "2018-12-09T18:48:34.190458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9101, -0.9330, -0.9997, -0.9848,  0.9992],\n",
       "        [ 1.0000, -0.9999, -1.0000, -0.5102,  1.0000],\n",
       "        [ 1.0000, -1.0000, -1.0000,  0.8646,  1.0000],\n",
       "        [ 1.0000,  0.9844,  1.0000,  1.0000, -0.9392]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0, y1 = model(X0_batch, X1_batch)\n",
    "y0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Built-in RNN Cell\n",
    "- 여기서 Built-in RNN Cell은 이미 만들어져 있는 RNN을 말하는 것 같다.\n",
    "- nn Class에서 바로 가져오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:05:23.542952Z",
     "start_time": "2018-12-09T20:05:23.526984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNNCell(3,5) # input_size : 3, neurons_size = 5\n",
    "\n",
    "x_batch = torch.tensor([[[0,1,2], \n",
    "                         [3,4,5], \n",
    "                         [6,7,8], \n",
    "                         [9,0,1]],\n",
    "                        [[9,8,7], \n",
    "                         [0,0,0], \n",
    "                         [6,5,4],\n",
    "                         [3,2,1]]], dtype = torch.float) # X0 and X1\n",
    "\n",
    "x_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:05:23.912659Z",
     "start_time": "2018-12-09T20:05:23.893195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.7622,  0.9226, -0.9347, -0.1788,  0.6269],\n",
      "        [-0.9285,  0.9771, -0.9775, -0.9971,  0.9974],\n",
      "        [-0.9764,  0.9987, -1.0000, -0.9998,  1.0000],\n",
      "        [ 0.9588,  0.9851, -0.9974, -0.9984,  0.9964]],\n",
      "       grad_fn=<TanhBackward>), tensor([[-0.6137,  0.9984, -1.0000, -1.0000,  1.0000],\n",
      "        [ 0.2652,  0.3874, -0.1155, -0.3601, -0.1925],\n",
      "        [-0.0387,  0.9792, -0.9996, -0.9986,  0.9999],\n",
      "        [ 0.8634,  0.4560, -0.9214, -0.9613,  0.9836]],\n",
      "       grad_fn=<TanhBackward>)]\n"
     ]
    }
   ],
   "source": [
    "# hidden layer\n",
    "hx = torch.randn(4,5) # m x neurons_size\n",
    "\n",
    "output = []\n",
    "for i in range(2):\n",
    "    hx = rnn(x_batch[i], hx)\n",
    "    output.append(hx)\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice\n",
    "- 초반에 진행했던 BasicRNN과 같은 모델이다.\n",
    "- 계산에 필요한 weight와 bias를 자동으로 생성해준다.\n",
    "- 히든 레이어까지 그대로 다음 step으로 넘길 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:13:49.306166Z",
     "start_time": "2018-12-09T20:13:49.272729Z"
    }
   },
   "outputs": [],
   "source": [
    "class CleanBasicRNN(nn.Module):\n",
    "    def __init__(self, batch_size, input_size, hidden_size):\n",
    "        super(CleanBasicRNN, self).__init__()\n",
    "        \n",
    "        rnn = nn.RNNCell(input_size, hidden_size)\n",
    "        self.hx = torch.randn(batch_size, hidden_size) # hidden layer 초기화\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        \n",
    "        for i in range(2):\n",
    "            self.hx = rnn(x[i], self.hx)\n",
    "            output.append(self.hx)\n",
    "            \n",
    "        return output, self.hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:13:49.976921Z",
     "start_time": "2018-12-09T20:13:49.957457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "\n",
    "x_batch = torch.tensor([[[0,1,2], \n",
    "                         [3,4,5], \n",
    "                         [6,7,8], \n",
    "                         [9,0,1]],\n",
    "                        [[9,8,7], \n",
    "                         [0,0,0], \n",
    "                         [6,5,4], \n",
    "                         [3,2,1]]], dtype = torch.float) # X0 and X1\n",
    "x_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:13:50.582796Z",
     "start_time": "2018-12-09T20:13:50.573313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CleanBasicRNN()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CleanBasicRNN(batch_size, input_size, hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:14:15.292918Z",
     "start_time": "2018-12-09T20:14:15.282418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.9496,  0.9757, -0.7815, -0.1414,  0.0891],\n",
      "        [-0.9257,  0.9916, -0.9969, -0.9903,  0.9989],\n",
      "        [-0.9917,  0.9998, -1.0000, -0.9996,  1.0000],\n",
      "        [ 0.9205,  0.9911, -0.9987, -0.9975,  0.9939]],\n",
      "       grad_fn=<TanhBackward>), tensor([[-0.6878,  0.9983, -1.0000, -1.0000,  1.0000],\n",
      "        [ 0.2721,  0.3846, -0.1309, -0.3553, -0.1860],\n",
      "        [-0.0449,  0.9794, -0.9996, -0.9986,  0.9999],\n",
      "        [ 0.8597,  0.4649, -0.9227, -0.9607,  0.9832]],\n",
      "       grad_fn=<TanhBackward>)]\n"
     ]
    }
   ],
   "source": [
    "output, hidden_layer = model(x_batch)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새롭게 배운 것\n",
    "1. input(x)의 Batch_size은 hidden_layer의 첫 번째 요소와 같다.\n",
    " - input = torch.zeros(batch_size, input_size)\n",
    " - weight1 = torch.zeros(hidden_size, input_size) --> 전치행렬이 input과 곱해지기 때문에\n",
    " - hidden = torch.zeors(batch_size, hidden_size) 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
