{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with Faster R-CNN\n",
    "- Faster R-CNN을 이용해 물체인식 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:35.159191Z",
     "start_time": "2019-12-17T13:49:35.125191Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bbox 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:35.181162Z",
     "start_time": "2019-12-17T13:49:35.165169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 800, 800])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.zeros((1,3,800,800))\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:35.200150Z",
     "start_time": "2019-12-17T13:49:35.187155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.,  30., 400., 500.],\n",
       "        [300., 400., 500., 600.]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]])\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:35.219138Z",
     "start_time": "2019-12-17T13:49:35.206144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.,  30., 400., 500.],\n",
       "       [300., 400., 500., 600.]], dtype=float32)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:35.581930Z",
     "start_time": "2019-12-17T13:49:35.227138Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Rectangle at 0x19497699080>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor = image\n",
    "tensor = tensor.squeeze()\n",
    "tensor = tensor.permute(1,2,0)\n",
    "img = np.array(tensor)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "rect1 = patches.Rectangle((20,30),380,470, facecolor='none', edgecolor='r')\n",
    "rect2 = patches.Rectangle((300,400),100,200, facecolor='none', edgecolor='r')\n",
    "\n",
    "ax.add_patch(rect1)\n",
    "ax.add_patch(rect2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone -> VGG16\n",
    "- inpput size == 800 \n",
    "- output size == 800//16 = 50\n",
    "- input과 output의 size를 위와 같도록 model 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:35.842780Z",
     "start_time": "2019-12-17T13:49:35.587927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 800, 800])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인을 위해 dummy image 생성\n",
    "dummy_img = torch.zeros((1,3,800,800)).float()\n",
    "dummy_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:39.085927Z",
     "start_time": "2019-12-17T13:49:35.848776Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG16 모델 아키텍처 보기\n",
    "import torchvision\n",
    "\n",
    "model_vgg16 = torchvision.models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:39.107915Z",
     "start_time": "2019-12-17T13:49:39.093921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_list = list(model_vgg16.features)\n",
    "layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:39.128901Z",
     "start_time": "2019-12-17T13:49:39.113911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 800, 800])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:39.482699Z",
     "start_time": "2019-12-17T13:49:39.133898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 800, 800])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_list[0](dummy_img).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:54.365186Z",
     "start_time": "2019-12-17T13:49:39.487697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# output_size가 50이 될때까지 필요한 layer \n",
    "require_layers = []\n",
    "for layer in layer_list:\n",
    "    dummy_img = layer(dummy_img)\n",
    "    if dummy_img.size()[2] < 800//16:\n",
    "        break\n",
    "    require_layers.append(layer)\n",
    "    output_channel = dummy_img.size()[1]\n",
    "    \n",
    "print(output_channel)\n",
    "print(len(require_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:49:54.422157Z",
     "start_time": "2019-12-17T13:49:54.378179Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "faster_rcnn_feature_extractor = nn.Sequential(*require_layers)\n",
    "faster_rcnn_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:14.430712Z",
     "start_time": "2019-12-17T13:49:54.433148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "output_feature = faster_rcnn_feature_extractor(image)\n",
    "print(output_feature.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Anchor box(방법 확인, 실제 만드는 건 뒤에)\n",
    "- 각 비율, 크기마다 다른 anchor box 생성 -> 0.5, 1, 2 / 8, 16, 32\n",
    "- 각 box는 x1,y1,x2,y2를 가지고 있음 -> size == (9,4)\n",
    "- 1개의 feature map에 있는 1개의 픽셀에 대해 생성\n",
    "> Now every pixel in the output feature map maps to corresponding 16 * 16 pixels in the image. This is shown in the below image<br>\n",
    "-> 800x800에서 50x50으로 축소했으니 원본에서 16x16사이즈의 anchor box가 결국 feature map에서의 1개의 픽셀이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:14.561639Z",
     "start_time": "2019-12-17T13:50:14.457697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = [0.5, 1, 2]\n",
    "anchor_scales = [8,16,32]\n",
    "\n",
    "anchor_base = np.zeros((len(ratio) * len(anchor_scales), 4))\n",
    "anchor_base # feature map 1개의 픽셀에 대해 anchor box가 가질 수 있는 경우 9가지(비율3 x 크기3, x1 y1 x2 y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:14.848473Z",
     "start_time": "2019-12-17T13:50:14.571632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.50966799187809 181.01933598375618\n",
      "0\n",
      "181.01933598375618 362.03867196751236\n",
      "1\n",
      "362.03867196751236 724.0773439350247\n",
      "2\n",
      "128.0 128.0\n",
      "3\n",
      "256.0 256.0\n",
      "4\n",
      "512.0 512.0\n",
      "5\n",
      "181.01933598375618 90.50966799187809\n",
      "6\n",
      "362.03867196751236 181.01933598375618\n",
      "7\n",
      "724.0773439350247 362.03867196751236\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -37.254834  ,  -82.50966799,   53.254834  ,   98.50966799],\n",
       "       [ -82.50966799, -173.01933598,   98.50966799,  189.01933598],\n",
       "       [-173.01933598, -354.03867197,  189.01933598,  370.03867197],\n",
       "       [ -56.        ,  -56.        ,   72.        ,   72.        ],\n",
       "       [-120.        , -120.        ,  136.        ,  136.        ],\n",
       "       [-248.        , -248.        ,  264.        ,  264.        ],\n",
       "       [ -82.50966799,  -37.254834  ,   98.50966799,   53.254834  ],\n",
       "       [-173.01933598,  -82.50966799,  189.01933598,   98.50966799],\n",
       "       [-354.03867197, -173.01933598,  370.03867197,  189.01933598]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchor base 채우기\n",
    "sub_sample = 16\n",
    "ctr_x = sub_sample / 2\n",
    "ctr_y = sub_sample / 2\n",
    "\n",
    "for i in range(len(ratio)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "        h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "        w = sub_sample * anchor_scales[j] * np.sqrt(1/ratio[i])\n",
    "        print(h,w)\n",
    "        \n",
    "        index = i * len(anchor_scales) + j\n",
    "        print(index)\n",
    "        \n",
    "        anchor_base[index, 0] = ctr_y - h / 2\n",
    "        anchor_base[index, 1] = ctr_x - w / 2\n",
    "        anchor_base[index, 2] = ctr_y + h / 2\n",
    "        anchor_base[index, 3] = ctr_x + w / 2\n",
    "        \n",
    "anchor_base\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위 작업은 1개의 feature map에 대하여 생성한 anchor box**\n",
    "- image 사이즈에서 벗어나거나 큰 anchor box는 negaitve values로 취급, 나중에 loss계산할 때 빼준다(-1로 바꿔줌)\n",
    "- feature map이 50x50임으로 각 픽셀에 대해 anchor box 생성하면 -> 17500(50x50x9)<br>\n",
    "(1개의 픽셀에 9가지의 anchor box 생성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature map에 있는 모든 pixel에 대하여 anchor box 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 픽셀에 대한 센터값 모음 생성(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:14.957410Z",
     "start_time": "2019-12-17T13:50:14.855469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 2)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 픽셀에 대해 센터값(ctr_x, ctr_y) 생성\n",
    "\n",
    "feature_size = 800//16\n",
    "ctr_x = np.arange(16, (feature_size+1)*16, 16) # image 원본에서의 센터값x\n",
    "ctr_y = np.arange(16, (feature_size+1)*16, 16) # image 원본에서의 센터값y\n",
    "\n",
    "index = 0\n",
    "ctr = np.zeros((len(ctr_x) * len(ctr_y), 2))\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        ctr[index, 1] = ctr_x[x] - 8\n",
    "        ctr[index, 0] = ctr_y[y] - 8\n",
    "        index += 1\n",
    "        \n",
    "ctr.shape # 1개의 image에 대한 모든 anchor box의 중심점의 모음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 센터값에 대당하는 anchor box 생성(위와 다르게 실제로 생성)\n",
    "- 1개의 feature map에 해당하는 모든 anchor box 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:15.300235Z",
     "start_time": "2019-12-17T13:50:14.995390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 4)\n"
     ]
    }
   ],
   "source": [
    "anchors = np.zeros((feature_size * feature_size * 9, 4)) # 각 anchor box에 대한 y1, x1, y2, x2\n",
    "sub_sample = 16\n",
    "index = 0\n",
    "for c in ctr: # y,x\n",
    "    ctr_y, ctr_x = c\n",
    "    for i in range(len(ratio)):\n",
    "        for j in range(len(anchor_scales)):\n",
    "            h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "            w = sub_sample * anchor_scales[j] * np.sqrt(1/ratio[i])\n",
    "            \n",
    "            anchors[index, 0] = ctr_y - h/2 # y1\n",
    "            anchors[index, 1] = ctr_x - w/2 # x1\n",
    "            anchors[index, 2] = ctr_y + h/2 # y2\n",
    "            anchors[index, 3] = ctr_x + w/2 # x2\n",
    "            index += 1\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 Anchor box에 Labels과 location 할당하기\n",
    "**두 종류의 Anchor에는 'Positive label'을 할당**\n",
    "1. 정답(Ground-Truth)과 비교했을 때 IOU(Intersection-over-Union)값이 가장 큰 Anchor/Anchors\n",
    "2. 정답(Ground-Truth)과 비교했을 때 IOU(Intersection-over-Union)값이 **0.7** 이상일 때\n",
    "> **Object가 1개에 대하여 여러 Anchor box에 Positive label을 할당하는 경우가 있다.**\n",
    "\n",
    "**아래와 같은 Anchor에는 'Negative label'을 할당**\n",
    "1. 정답(Ground-Truth)과 비교했을 때 IOU(Intersection-over-Union)값이 **0.3**보다 작을 때\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:15.330199Z",
     "start_time": "2019-12-17T13:50:15.317205Z"
    }
   },
   "outputs": [],
   "source": [
    "# 예시 Ground-Truth값(정답값 2개 objects)\n",
    "bbox = np.asarray([[20, 30, 400, 500], [300, 400, 500, 600]], dtype=np.float32) # y1, x1, y2, x2\n",
    "labels = np.asarray([6, 8], dtype=np.int8) # 0값은 배경을 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유효한(valid) Anchor box의 index 찾기\n",
    "- Anchor box가 image보다 크거나 범위에서 벗어나면 유효하지 않음\n",
    "- 즉, Anchor box의 x1 y1 x2 y2 값들이 모두 0~800 사이에 있어야 유효한 box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:15.365178Z",
     "start_time": "2019-12-17T13:50:15.335194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[ 13.49033201  10.745166   194.50966799 101.254834  ]\n"
     ]
    }
   ],
   "source": [
    "index_inside = np.where((anchors[:,0] >= 0) &\n",
    "                        (anchors[:,1] >= 0) &\n",
    "                        (anchors[:,2] <= 800) &\n",
    "                        (anchors[:,3] <= 800))[0]\n",
    "print(index_inside.shape)\n",
    "print(anchors[index_inside[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label 행렬 만들기\n",
    "- 여기서 label은 물체가 있는지 없는지(objectness)만 판별\n",
    "- 따라서 1또는 -1로 표시(1은 물체가 있고 -1은 background)\n",
    "- 각 anchor box별로 물체 유무에 따라 1 or -1\n",
    "> **유효한 Anchor box 개수 = label 행렬 크기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:15.413150Z",
     "start_time": "2019-12-17T13:50:15.373174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940,)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.empty_like(index_inside)\n",
    "label.fill(-1)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유효한 Anchor box 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:15.438137Z",
     "start_time": "2019-12-17T13:50:15.420148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 4)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_anchor_boxes = anchors[index_inside]\n",
    "valid_anchor_boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU 계산\n",
    "- 위에서 임의로 정의한 bbox를 정답(Ground-Truth)이라고 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.116768Z",
     "start_time": "2019-12-17T13:50:15.460124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 2)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ious = np.zeros((len(valid_anchor_boxes), 2)) # 각 Anchor box와 Ground-Truth와의 IOU 값\n",
    "\n",
    "for num1, i in enumerate(valid_anchor_boxes):\n",
    "    ya1, xa1, ya2, xa2 = i\n",
    "    anchor_area = (ya2-ya1) * (xa2-xa1)\n",
    "    for num2, j in enumerate(bbox):\n",
    "        yb1, xb1, yb2, xb2 = j\n",
    "        box_area = (yb2-yb1) * (xb2-xb1)\n",
    "        \n",
    "        inter_x1 = max([xa1, xb1])\n",
    "        inter_y1 = max([ya1, yb1])\n",
    "        inter_x2 = min([xa2, xb2])\n",
    "        inter_y2 = min([ya2, yb2])\n",
    "        \n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            inter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)\n",
    "            iou = inter_area/(box_area + anchor_area - inter_area) # inter_area가 반복됨으로 한 번 빼준다.\n",
    "            \n",
    "        else:\n",
    "            iou = 0\n",
    "            \n",
    "        ious[num1, num2] = iou # 각각의 Anchor box에 대한 2 objects의 iou 값\n",
    "        \n",
    "ious.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조건에 만족하는 IOU값 및 그 값에 해당하는 Anchor box 선별\n",
    "1. 2개의 Ground-Truth box에 대하여 가장 큰 IOU값과 그 값(2개의 Ground-Truth box)에 해당하는 Anchor box\n",
    "2. 각각의 Anchor box 에서 가장 큰 IOU값과 그 값에 해당하는 Ground-Truth box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 각 Object에 대해 가장 큰 IOU 값과 각 해당하는 Anchor box index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.137757Z",
     "start_time": "2019-12-17T13:50:16.122744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2262, 5620], dtype=int64)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_argmax_ious = ious.argmax(axis = 0)\n",
    "gt_argmax_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.165721Z",
     "start_time": "2019-12-17T13:50:16.142733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68130493, 0.08628624],\n",
       "       [0.10757449, 0.61035156]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ious[gt_argmax_ious]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.184710Z",
     "start_time": "2019-12-17T13:50:16.174715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68130493, 0.61035156])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])] # (0,0) , (1,1)\n",
    "gt_max_ious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  각 Object(2개)에 대한 Anchor box(2개) 중 IOU가 큰 Anchor box(2 중 하나)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.234681Z",
     "start_time": "2019-12-17T13:50:16.197702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "argmax_ious = ious.argmax(axis = 1)\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious) # 2개 중 1개의 index가 나오겟죠? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.254671Z",
     "start_time": "2019-12-17T13:50:16.240677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# index_inside == 유효한 Anchro box의 index\n",
    "max_ious = ious[np.arange(len(index_inside)), argmax_ious] # 유효한 Anchor box 중 IOU 값이 큰 box(2중 더 큰 값)\n",
    "print(max_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가장 큰 IOU값을 가지고 있는 Anchor box 찾기\n",
    "- 저 결과값들은 Anchor box들 중 IOU가 가장 큰 Anchor box들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.277657Z",
     "start_time": "2019-12-17T13:50:16.261665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
      " 6358 6366 6374 6382]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
    "print(gt_argmax_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 우리는 3가지의 결과를 얻었다.\n",
    "1. argmax_ious : 각 Anchor 중 어느 Object에 대한 IOU가 큰 값인지 나타낸 index(0 or 1)\n",
    "2. max_ious : 각 Anchro에 대하여 두 Ojbect 중 IOU가 더 큰 Object에 해당하는 IOU\n",
    "3. gt_argmax_ious : 가장 큰 IOU값을 지니고 있는 Anchor box들의 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.304640Z",
     "start_time": "2019-12-17T13:50:16.283652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.329626Z",
     "start_time": "2019-12-17T13:50:16.310639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06811669, 0.07083762, 0.07083762, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.350614Z",
     "start_time": "2019-12-17T13:50:16.334623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
       "       6120, 6128, 6136, 6358, 6366, 6374, 6382], dtype=int64)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_argmax_ious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임계값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.374600Z",
     "start_time": "2019-12-17T13:50:16.356612Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_iou_threshold = 0.7 # IOU값이 0.7를 넘으면 positive\n",
    "neg_iou_threshold = 0.3 # IOU값이 0.3 아래면 negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.398588Z",
     "start_time": "2019-12-17T13:50:16.381596Z"
    }
   },
   "outputs": [],
   "source": [
    "label[max_ious < neg_iou_threshold] = 0 # Negative label에 0 설정\n",
    "label[gt_argmax_ious] = 1 # Ojbect와 비교했을 때 IOU가 가장 높은 Anchor box에 1 할당\n",
    "label[max_ious >= pos_iou_threshold] = 1 # IOU가 0.7 이상인 Anchor box 1 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPN(Regions Proposal Network) 학습을 위한 Target 만들기\n",
    "각 싱글 이미지로부터 나온 Mini-Batch(pos와 neg anchor를 포함한)를 이용하여 Target읆 만든다.\n",
    "- 256개의 Anchor box를 랜덤하게 샘플링한다 -> mini batch의 Loss를 계산할 때 사용\n",
    "- pos와 neg의 비율은 1:1이다.\n",
    "- **결과로 만들어진 Target이 예측값이고, 정답과 비교해서 loss를 계산한다 <- 학습의 목표**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.416576Z",
     "start_time": "2019-12-17T13:50:16.404584Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_ratio = 0.5\n",
    "n_sample = 256\n",
    "\n",
    "n_pos = pos_ratio * n_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### positive label에서 n_pos 랜덤하게 샘플링\n",
    "- 만약 n_pos개보다 적게 샘플링한다면 negative samples를 랜덤하게 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.443561Z",
     "start_time": "2019-12-17T13:50:16.421576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
       "       6120, 6128, 6136, 6358, 6366, 6374, 6382], dtype=int64)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index = np.where(label == 1)[0]\n",
    "pos_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Positive Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.459552Z",
     "start_time": "2019-12-17T13:50:16.447558Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.516519Z",
     "start_time": "2019-12-17T13:50:16.463552Z"
    }
   },
   "outputs": [],
   "source": [
    "n_neg = n_sample * np.sum(label == 1)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function 정의\n",
    "Bounding-Box Regression을 이용하여 손실함수 정의<br>\n",
    "![사진-벡터로 변환하는](https://i.imgur.com/1jTnrMG.png)\n",
    "- x,y,w,h는 센터(x,y)와  가로, 세로\n",
    "- x_a, y_a, h_a, w_a는 Anchor box의 센터(x,y)와 가로, 세로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.536509Z",
     "start_time": "2019-12-17T13:50:16.525516Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       ...,\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.],\n",
       "       [ 20.,  30., 400., 500.]], dtype=float32)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iou_bbox = bbox[argmax_ious]\n",
    "max_iou_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.559495Z",
     "start_time": "2019-12-17T13:50:16.542506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13.49033201,  10.745166  , 194.50966799, 101.254834  ],\n",
       "       [ 29.49033201,  10.745166  , 210.50966799, 101.254834  ],\n",
       "       [ 45.49033201,  10.745166  , 226.50966799, 101.254834  ],\n",
       "       ...,\n",
       "       [573.49033201, 698.745166  , 754.50966799, 789.254834  ],\n",
       "       [589.49033201, 698.745166  , 770.50966799, 789.254834  ],\n",
       "       [605.49033201, 698.745166  , 786.50966799, 789.254834  ]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_anchor_boxes # y1, x1, y2, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유효한 Anchor box들의 좌표를 '중앙값(x,y)과 가로, 세로'로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.588478Z",
     "start_time": "2019-12-17T13:50:16.563492Z"
    }
   },
   "outputs": [],
   "source": [
    "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:,0] # y2 - y1\n",
    "width = valid_anchor_boxes[:,3] - valid_anchor_boxes[:,1] # x2 - x1\n",
    "ctr_y = valid_anchor_boxes[:, 0] + 0.5*height # y의 중앙값\n",
    "ctr_x = valid_anchor_boxes[:, 1] + 0.5*width # x의 중앙값\n",
    "\n",
    "# 2개의 Object 중 각 Anchor box와의 IOU값이 더 큰 Object의 box == max_iou_bbox\n",
    "base_height = max_iou_bbox[:,2] - max_iou_bbox[:,0]\n",
    "base_width = max_iou_bbox[:,3] - max_iou_bbox[:,1]\n",
    "base_ctr_y = max_iou_bbox[:,0] + 0.5*base_height\n",
    "base_ctr_x = max_iou_bbox[:,1] + 0.5*base_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.610467Z",
     "start_time": "2019-12-17T13:50:16.592477Z"
    }
   },
   "outputs": [],
   "source": [
    "eps = np.finfo(height.dtype).eps # finfo : float에 대한 정보, eps : 표현 가능한 가장 작은 수\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.646446Z",
     "start_time": "2019-12-17T13:50:16.626456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5855728 ,  2.30914558,  0.7415674 ,  1.64727602],\n",
       "       [ 0.49718446,  2.30914558,  0.7415674 ,  1.64727602],\n",
       "       [ 0.40879611,  2.30914558,  0.7415674 ,  1.64727602],\n",
       "       ...,\n",
       "       [-2.50801936, -5.29225232,  0.7415674 ,  1.64727602],\n",
       "       [-2.59640771, -5.29225232,  0.7415674 ,  1.64727602],\n",
       "       [-2.68479606, -5.29225232,  0.7415674 ,  1.64727602]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose() # y, x, h, w\n",
    "anchor_locs # 유효한 Anchors box의 좌료를 중심+가로+세로 좌표로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 Labels\n",
    "1. **index_inside** : IOU상관 없이 object 안에 들어가 있는 Anchor (8940개)\n",
    "\n",
    "\n",
    "2. **anchor_labels** : 만들어진 모든 anchors박스에 대한 label\n",
    " - object 와 하나도 안 겹치는 부분은 배경으로 간주, -1\n",
    " - IOU가 0.3 이하인 Anchor는 -1 \n",
    " - IOU가 0.7 이상이거나 가장 큰 anchor는 1\n",
    " - 둘 다 아닌 anchor는 0 -> 무시\n",
    "\n",
    " \n",
    "3. **anchor_labels[index_inside]** : 1또는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.667432Z",
     "start_time": "2019-12-17T13:50:16.651442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_labels = np.empty((len(anchors)), dtype = label.dtype) # \n",
    "anchor_labels.fill(-1)\n",
    "anchor_labels[index_inside] = label\n",
    "anchor_labels # [22500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 Anchor box의 Location\n",
    "위에 최종 Labels와 비슷한 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.693418Z",
     "start_time": "2019-12-17T13:50:16.671431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_locations = np.empty(anchors.shape, dtype=anchor_locs.dtype)\n",
    "anchor_locations.fill(0)\n",
    "anchor_locations[index_inside, :] = anchor_locs\n",
    "anchor_locations  # [22500, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위에 만들어진 최종 Location과 Labels는 RPN network의 Target으로 쓰인다<br>\n",
    "**Target을 정답과 비교해 알맞게 바꾸는 Transform을 찾아내는 것이 학습의 목표!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Proposal Network 만들기\n",
    "과거의 모델들은 Selective search, CPMC, MCG 등의 알고리즘을 통해 Region Proposal을 생성했다.<br>\n",
    "Faster R-CNN부터는 이 과정을 deep learning으로 만들었다.\n",
    "- Backbone이었던 VGG16모델을 거친 마지막 feature map을 사용(50x50 size)\n",
    "- nxn size의 Fliter가 slide하면서 각 pixel마다 9개의 region proposals을 예측(여기서는 n=3)\n",
    "- 가로:세로 비율이 (0.5:1, 1:1, 1:0.5)\n",
    "- 1:1기준으로 region propsoal의 크기는 16x16\n",
    "- 50x50 size feature map의 1픽셀 당 원본크기는 16x16(원본 800x800에서 50x50으로 작아졌기 때문에 16:1)\n",
    "- 50x50 size feature map은 512 features, RPN의 결과는 256 features\n",
    "- 2개의 Layer로 찢어진다\n",
    " - Box Regression Layer : 박스를 예측하는 layer\n",
    " - Box Classification Layer : 박스 안에 물체가 있는지 없는지(물체인지 배경인지, -1 또는 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide Window, Regression Layer, Classification Layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.780370Z",
     "start_time": "2019-12-17T13:50:16.698415Z"
    }
   },
   "outputs": [],
   "source": [
    "## n=3인 slide window 이용\n",
    "import torch.nn as nn\n",
    "mid_channels = 256\n",
    "in_channels = 512 # vgg16 결과가 512\n",
    "n_anchor = 9 # 각 location마다 생성되는 anchor의 개수\n",
    "conv1 = nn.Conv2d(in_channels, mid_channels, 3, stride = 1, padding = 1)\n",
    "reg_layer = nn.Conv2d(mid_channels, n_anchor * 4, 1, stride = 1, padding = 0) # 1d Conv2d\n",
    "cls_layer = nn.Conv2d(mid_channels, n_anchor * 2, 1, stride = 1, padding = 0) # SoftMax함수를 이용할 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에 의하면 conv레이어의 가중치를 zero mean과 0.01 standard deviation로 했다고 되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:16.847330Z",
     "start_time": "2019-12-17T13:50:16.785366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 512, 3, 3])\n",
      "torch.Size([36, 256, 1, 1])\n",
      "torch.Size([18, 256, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Slide Window layer\n",
    "conv1.weight.data.normal_(0, 0.01)\n",
    "conv1.bias.data.zero_()\n",
    "\n",
    "# Regression layer\n",
    "reg_layer.weight.data.normal_(0, 0.01)\n",
    "reg_layer.bias.data.zero_()\n",
    "\n",
    "# Classification layer\n",
    "cls_layer.weight.data.normal_(0, 0.01)\n",
    "cls_layer.bias.data.zero_()\n",
    "\n",
    "for lay in [conv1, reg_layer, cls_layer]:\n",
    "    print(lay.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vgg16 결과 전달\n",
    "- Backbone의 결과 feature map을 RPN Network로 전달(output_feature)\n",
    "- 이후 각각 reg, cls layer을 거쳐서 box와 objectness 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.077201Z",
     "start_time": "2019-12-17T13:50:16.852328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 50, 50]) torch.Size([1, 18, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(output_feature)\n",
    "pred_anchor_locs = reg_layer(x)\n",
    "pred_cls_scores = cls_layer(x)\n",
    "\n",
    "print(pred_anchor_locs.shape, pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RPN Network & ROI Network\n",
    "1. RPN Network\n",
    " - Pred_cls_scores\n",
    " - Pred_anchor_locs\n",
    "\n",
    "2. ROI Network(Proposal layer)\n",
    " - Pred_cls_scores\n",
    " - objectness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.451985Z",
     "start_time": "2019-12-17T13:50:17.083196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 4])\n",
      "torch.Size([1, 50, 50, 18])\n",
      "torch.Size([1, 22500])\n",
      "torch.Size([1, 22500, 2])\n"
     ]
    }
   ],
   "source": [
    "# contiguous는 텐서를 메모리상에 일렬로 정렬해주는 역할\n",
    "pred_anchor_locs = pred_anchor_locs.permute(0,2,3,1).contiguous().view(1, -1, 4)\n",
    "print(pred_anchor_locs.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.permute(0,2,3,1).contiguous()\n",
    "print(pred_cls_scores.shape)\n",
    "\n",
    "objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:,:,:,:,1].contiguous().view(1, -1)\n",
    "print(objectness_score.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.view(1, -1, 2)\n",
    "print(pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposals 생성하기\n",
    "여러 ratio(0.5:1, 1:1, 1:0.5)로 생성된 proposal들은 겹치는 부분이 많다.<br>\n",
    "따라서 NMS(Non-Maximum Supression)을 이용해 반복되는 proposal을 제거해준다.\n",
    "- cls score을 기준으로 NMS 적용\n",
    "- NMS에서 사용할 IOU의 threshold는 0.7로 고정 -> 1개의 image당 약 2000개의 proposal 생성\n",
    "- NMS의 결과 중 top-N 랭크된 결과들만 detection에 사용한다.\n",
    "- testing을 한 대는 약 300개의 proposal들이 사용된다.(논문에 많은 실험을 통해 저 수치가 적당...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.466977Z",
     "start_time": "2019-12-17T13:50:17.457981Z"
    }
   },
   "outputs": [],
   "source": [
    "nms_thresh = 0.7 # IOU 0.7이상인 것은 제거\n",
    "n_train_pre_nms = 12000\n",
    "n_train_post_nms = 2000\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300\n",
    "min_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposals 만들어지는 과정\n",
    "1. RPN Network의 결과인 predicted box를 bbox(y1, x1, y2, x2)로 변환\n",
    "2. Predicted box를 image에 clip\n",
    " - Clip == limit\n",
    " - image의 크기에서 벗어난 anchor 박스들의 좌표를 Image 안으로 한정하기\n",
    " - 구석탱이에 있는 anchor는 무조건 Image을 벗어날테니 잘리겟지?\n",
    "3. Height또는 Width가 Threshold(min_size, 16)보다 작으면 해당 predicted box 제거\n",
    "4. 모든 (Proposal, score) 쌍을 score을 기준으로 내림차순으로 정렬\n",
    " - 여기서 score는 objectness의 점수\n",
    "5. 상위 N개의 Proposal만 취한다.\n",
    " - Training 시 12000개(n_train_pre_nms)\n",
    " - Testing 시 300개(n_test_post_nms)\n",
    "6. IOU의 threshold(0.7)을 적용\n",
    " - 가장 높은 Score을 가진 Proposal 1개와 나머지 Proposal을 전부 비교\n",
    " - 그 중 IOU값이 0.7이상 나오는 box들은 top score Proposal과 같은 물체로 판단\n",
    " - 따라서 0.7이상 나오는 box들은 전부 제거\n",
    "7. 6번을 통해 나온 결과 중 상위 N개의 Proposal만 취한다.\n",
    " - Training 시 2000개(n_train_post_nms)\n",
    " - Testing 시 300개(n_test_post_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RPN Network의 결과인 Predicted box 변환\n",
    "변환하기 전에 위 식에서 정의한 loss function의 식과 똑같이 변환한 후 좌표 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.487990Z",
     "start_time": "2019-12-17T13:50:17.472973Z"
    }
   },
   "outputs": [],
   "source": [
    "anc_height = anchors[:, 2] - anchors[:, 0]\n",
    "anc_width = anchors[:, 3] - anchors[:, 1]\n",
    "anc_ctr_y = anchors[:, 0] + 0.5*anc_height\n",
    "anc_ctr_x = anchors[:,1] + 0.5*anc_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.514964Z",
     "start_time": "2019-12-17T13:50:17.490962Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_anchor_locs_numpy = pred_anchor_locs[0].data.numpy()\n",
    "objectness_score_numpy = objectness_score[0].data.numpy()\n",
    "\n",
    "dy = pred_anchor_locs_numpy[:,0]\n",
    "dx = pred_anchor_locs_numpy[:,1]\n",
    "dh = pred_anchor_locs_numpy[:,2]\n",
    "dw = pred_anchor_locs_numpy[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.547930Z",
     "start_time": "2019-12-17T13:50:17.518948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,) (22500,)\n"
     ]
    }
   ],
   "source": [
    "ctr_y = dy * anc_height + anc_ctr_y\n",
    "ctr_x = dx * anc_width + anc_ctr_x\n",
    "h = np.exp(dh) * anc_height\n",
    "w = np.exp(dw) * anc_width\n",
    "\n",
    "print(ctr_y.shape, h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 좌표 변환[ctr_x, ctr_y, h, w] -> y1, x1, y2, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.570917Z",
     "start_time": "2019-12-17T13:50:17.554928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -38.2710193 ,  -73.57531498,   52.5982011 ,  105.27967176],\n",
       "       [ -79.21985527, -187.70367429,  101.33234527,  179.27451661],\n",
       "       [-167.98297316, -375.88747416,  185.01891817,  368.40438847],\n",
       "       ...,\n",
       "       [ 700.34234997,  747.58284749,  881.45447646,  836.75479474],\n",
       "       [ 607.72612332,  701.08391619,  972.47138632,  878.94661641],\n",
       "       [ 430.38998576,  612.30075389, 1164.0604865 ,  969.74644708]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi = np.zeros(pred_anchor_locs_numpy.shape)\n",
    "roi[:,0] = ctr_y - 0.5*h\n",
    "roi[:,1] = ctr_x - 0.5*w\n",
    "roi[:,2] = ctr_y + 0.5*h\n",
    "roi[:,3] = ctr_x + 0.5*w\n",
    "\n",
    "roi # y1, x1, y2, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Predicted box를 image에 clip\n",
    "Image의 크기에서 벗어난 Anchor들 자르기\n",
    "- 모든 anchor들은 Image 안의 좌표(y1, x1, y2, x2)로 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.612892Z",
     "start_time": "2019-12-17T13:50:17.575914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,  52.5982011 , 105.27967176],\n",
       "       [  0.        ,   0.        , 101.33234527, 179.27451661],\n",
       "       [  0.        ,   0.        , 185.01891817, 368.40438847],\n",
       "       ...,\n",
       "       [700.34234997, 747.58284749, 800.        , 800.        ],\n",
       "       [607.72612332, 701.08391619, 800.        , 800.        ],\n",
       "       [430.38998576, 612.30075389, 800.        , 800.        ]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = (800, 800)\n",
    "roi[:,slice(0, 4, 2)] = np.clip(roi[:, slice(0,4,2)], 0, img_size[0])\n",
    "roi[:,slice(1, 4, 2)] = np.clip(roi[:, slice(1,4,2)], 0, img_size[1])\n",
    "\n",
    "roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Height또는 Width가 Threshold(min_size, 16)보다 작으면 해당 predicted box 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.636878Z",
     "start_time": "2019-12-17T13:50:17.617891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 22497, 22498, 22499], dtype=int64)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = roi[:, 2] - roi[:, 0] # y2 - y1\n",
    "ws = roi[:, 3] - roi[:, 1] # x2 - x1\n",
    "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.655869Z",
     "start_time": "2019-12-17T13:50:17.641876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,  52.5982011 , 105.27967176],\n",
       "       [  0.        ,   0.        , 101.33234527, 179.27451661],\n",
       "       [  0.        ,   0.        , 185.01891817, 368.40438847],\n",
       "       ...,\n",
       "       [700.34234997, 747.58284749, 800.        , 800.        ],\n",
       "       [607.72612332, 701.08391619, 800.        , 800.        ],\n",
       "       [430.38998576, 612.30075389, 800.        , 800.        ]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi = roi[keep, :]\n",
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.685851Z",
     "start_time": "2019-12-17T13:50:17.665863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500,)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = objectness_score_numpy[keep]\n",
    "\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 모든 (Proposal, score) 쌍을 score을 기준으로 내림차순으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.710836Z",
     "start_time": "2019-12-17T13:50:17.691847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,   431,   908, ...,   463,     0, 21614], dtype=int64)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = score.argsort()[::-1] # argsort()는 작은순으로 정렬\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.727827Z",
     "start_time": "2019-12-17T13:50:17.715833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500,)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 상위 N개의 Proposal만 취한다.\n",
    "12000개(train), 300개(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:17.758811Z",
     "start_time": "2019-12-17T13:50:17.733824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    8,   431,   908, ..., 21702, 21729, 21711], dtype=int64)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = order[:n_train_pre_nms]\n",
    "print(order.shape)\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:50:37.539959Z",
     "start_time": "2019-12-17T13:50:37.525968Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        , 371.19584303, 181.55585067],\n",
       "       [389.95974058,   0.        , 800.        , 184.76240313],\n",
       "       [  0.        ,   0.        , 369.83624251, 223.39984427],\n",
       "       ...,\n",
       "       [120.13881588, 712.93538654, 250.15244198, 800.        ],\n",
       "       [168.13881588, 712.93538654, 298.15244198, 800.        ],\n",
       "       [136.13881588, 712.93538654, 266.15244198, 800.        ]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi = roi[order, :]\n",
    "roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T12:58:02.662582Z",
     "start_time": "2019-12-17T12:58:02.657587Z"
    }
   },
   "source": [
    "#### 6. Non-Maximum Suppression\n",
    "IOU의 threshold(0.7)을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T13:51:45.875929Z",
     "start_time": "2019-12-17T13:51:45.861934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 4)\n",
      "(12000,)\n",
      "22499\n"
     ]
    }
   ],
   "source": [
    "print(roi.shape)\n",
    "print(order.shape)\n",
    "print(order.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T14:22:11.064414Z",
     "start_time": "2019-12-17T14:22:10.849536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3130,)\n",
      "(2492,)\n",
      "(1760,)\n",
      "(352,)\n",
      "(270,)\n",
      "(250,)\n",
      "(237,)\n",
      "(230,)\n",
      "(223,)\n",
      "(216,)\n",
      "(209,)\n",
      "(202,)\n",
      "(195,)\n",
      "(188,)\n",
      "(182,)\n",
      "(176,)\n",
      "(170,)\n",
      "(164,)\n",
      "(158,)\n",
      "(152,)\n",
      "(146,)\n",
      "(140,)\n",
      "(134,)\n",
      "(128,)\n",
      "(122,)\n",
      "(116,)\n",
      "(110,)\n",
      "(104,)\n",
      "(98,)\n",
      "(92,)\n",
      "(86,)\n",
      "(80,)\n",
      "(74,)\n",
      "(68,)\n",
      "(62,)\n",
      "(56,)\n",
      "(50,)\n",
      "(44,)\n",
      "(40,)\n",
      "(37,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "y1 = roi[:, 0]\n",
    "x1 = roi[:, 1]\n",
    "y2 = roi[:, 2]\n",
    "x2 = roi[:, 3]\n",
    "\n",
    "area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "order = np.arange(roi.shape[0])\n",
    "\n",
    "keep = []\n",
    "\n",
    "while order.size > 0:\n",
    "    i = order[0]\n",
    "    # 두 상자의 겹치는 부분의 좌표를 찾아내는 코드\n",
    "    xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "    yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "    xx2 = np.maximum(x2[i], x2[order[1:]])\n",
    "    yy2 = np.maximum(y2[i], y2[order[1:]])\n",
    "    \n",
    "    w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "    inter = w * h\n",
    "    ovr = inter / (area[i] + area[order[1:]] - inter)\n",
    "    \n",
    "    inds = np.where(ovr <= 0.7)[0] # IOU가 0.7보다 작은 anchor의 index\n",
    "    print(inds.shape)\n",
    "    keep.append(i) # i(점수가 가장 높은 상자와의 iou크기가 0.7 이하인 것들)\n",
    "    order = order[inds]\n",
    "    #print(order.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 6번을 통해 나온 결과 중 상위 N개의 Proposal만 취한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "343px",
    "left": "653px",
    "right": "20px",
    "top": "117px",
    "width": "341px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
